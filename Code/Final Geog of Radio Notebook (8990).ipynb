{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Michael Felzan | GIS 8990, University of Minnesota 2021 | \"The Geography of Radio\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ~"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents: \n",
    "\n",
    "\n",
    "   #### A.) Notebook Preparation\n",
    "   \n",
    "         1.) Importing packages\n",
    "         2.) Assigning working directory path / API key inputs\n",
    "         3.) Establishing path to radio station data .CSV (sourced from Radio.Garden)\n",
    "         4.) Assigning path to CSV which is sourced from the 'Master' radio stations .CSV, but only \n",
    "             contains stations FM Stations from the state Washington\n",
    "         5.) Assigning path to a text file which will be the home to URL streams from the above \n",
    "             .CSV which consistently 'error out' or return no results\n",
    "         6.) Function / Class Definitions\n",
    "         \n",
    "   #### B.) Local Directory Setup\n",
    "   \n",
    "         1.) Creating 'list_of_wash_callsigns;' appending all names of Washington callsigns to list\n",
    "         2.) Making folder directories for all Washington callsigns\n",
    "         3.) Creating .txt files for all Washington callsigns in correct format\n",
    "         4.) Retrieving station info from Radio-Locator and creating \"station info\" .txt for \n",
    "             each station (that yields a valid request from Radio-Locator)\n",
    "         5.) Creating a list of callsigns for every station in our sample set\n",
    "         \n",
    "   #### C.) Gathering information about each radio station's powered FM tower\n",
    "    \n",
    "         1.) Creating all individual station info CSVs (involves parsing/cleaning up returned \n",
    "             text from initial Radio-Locator request)\n",
    "         2.) Creating folder that station info tables will be copied into, so that they can \n",
    "             be merged into one file\n",
    "         3.) Copying files to that folder\n",
    "         4.) Concatenating all station info CSV's into one CSV\n",
    "         5.) Viewing what \"Station Info\" CSV looks like\n",
    "    \n",
    "   #### D.) MULTI-PROCESSING\n",
    "    \n",
    "   #### E.) Turning track-play information into usable data that can be imported into ArcGIS\n",
    "    \n",
    "         1.) Creatiing a list of station tuples (callsign + stream URL) in preparation of radio sampling\n",
    "         2.) Iterating over every station URL, sampling audio, routing audio to both ACRCloud and \n",
    "             Discogs APIs, logging associated information in each station's respective text file\n",
    "         3.) Demonstrating what the 'raw text' inside a given station's \"song play log\" looks like\n",
    "             (after the above code block has been run enough times)\n",
    "         4.) Demonstrating the operations involved in parsing this text, in order to put all of the\n",
    "             info neatly into a spreadsheet\n",
    "         5.) Iterating over every station's \"song play log\" .txt file,  parsing/extracting relevant \n",
    "             info (saving to temporary variables), and creating clean song play .CSVs for each station\n",
    "         6.) Demonstrating what one of these song play .CSV's looks like\n",
    "         7.) Creating a folder to store every station's song play log .CSV file in one place\n",
    "         8.) Copying all individual song play .CSVs into new folder\n",
    "         9.) Merging all individual station song play .CSVs into one concatenated 'master' .CSV\n",
    "         \n",
    "   #### F.) Creating statistics based on genres played by each station\n",
    "    \n",
    "         1.) Creating a list of unique styles/genres that appear on the concatenatedsong play log .CSV\n",
    "         2.) Defining, from the above list, which of those genres are \"electronic music\" genres\n",
    "         3.) Iterating over 'master' song play log .CSV, and marking tracks which contain one of\n",
    "             the above 'electronic' genre tags.\n",
    "         4.) Note the 'elec_or_not' column header added to the below spreadsheet\n",
    "         5.) Using Pandas 'GroupBy' to summarize statistics by each radio station (callsign)\n",
    "         6.) Printing summary statistics to .CSV, so this data may be linked with a point-class \n",
    "             shapefile in ArcGIS Pro (allowing for spatial analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A.) Notebook Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.) Importing packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NOTE: in order to import 'acrcloud' properly, user must go to terminal, navigate to base of project folder repo, and and type 'sudo python setup.py install'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import io\n",
    "from io import BytesIO\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "from csv import reader\n",
    "import requests\n",
    "import pycurl\n",
    "import certifi\n",
    "import time\n",
    "from datetime import datetime, date, timedelta\n",
    "from acrcloud.recognizer import ACRCloudRecognizer\n",
    "from acrcloud.recognizer import ACRCloudRecognizeType\n",
    "from bs4 import BeautifulSoup\n",
    "import shutil\n",
    "from shutil import copyfile\n",
    "import pydub\n",
    "from pydub.playback import play\n",
    "from pydub import AudioSegment\n",
    "import ffmpeg\n",
    "from functools import partial\n",
    "from itertools import repeat\n",
    "from itertools import product\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool, freeze_support\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.) Assigning working directory path / API key inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign working directory path:\n",
    "workindir = r'/Users/michaelfelzan/Desktop/Geography-of-Radio/Data'\n",
    "os.chdir(workindir)\n",
    "\n",
    "# ACRCloud key / secret keys:\n",
    "acrcloud_accesskey = '4554490a1c83c19ea6745ed6bfbbea7d'\n",
    "acrcloud_secretkey = 'HcoVKztgUltoNAwlPxpWoIJzt86HoKk9KTiByPTl'\n",
    "\n",
    "acrcloud_config = {\n",
    "    'host':'identify-eu-west-1.acrcloud.com',\n",
    "    'access_key': acrcloud_accesskey,\n",
    "    'access_secret': acrcloud_secretkey,\n",
    "    'recognize_type': ACRCloudRecognizeType.ACR_OPT_REC_AUDIO, # could be 'humming audio' as well\n",
    "    'debug':False,\n",
    "    'timeout':5 # seconds\n",
    "}\n",
    "\n",
    "ACR_recognizer = ACRCloudRecognizer(acrcloud_config)\n",
    "\n",
    "# Discogs key / secret keys:\n",
    "client_key = 'gQylLmyvGPfyGEvmFyRx'\n",
    "client_secret = 'KJnItkPttweOtFSkqwAiTTCWJsOnIobH'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/michaelfelzan/Desktop/Geography-of-Radio/Data'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MASTER_CSV.csv',\n",
       " 'WASH SONG LOGS',\n",
       " 'PLACES_DescendingCountriesCSV.csv',\n",
       " '.DS_Store',\n",
       " 'WashingtonStations_filled.csv',\n",
       " 'sample_mp3_1.mp3',\n",
       " 'sample_mp3_2.mp3',\n",
       " 'WashingtonStations_OnlyFM.csv',\n",
       " 'us_4.csv',\n",
       " 'WASH STATIONS',\n",
       " 'US_STATIONS_3.csv',\n",
       " 'fatal_error_wash.txt',\n",
       " 'US_STATIONS.csv',\n",
       " 'WashStationInfoTables']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.) Establishing path to radio station data .CSV (sourced from Radio.Garden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>CityState</th>\n",
       "      <th>City</th>\n",
       "      <th>StateAbv</th>\n",
       "      <th>StationName</th>\n",
       "      <th>RG_ID</th>\n",
       "      <th>RG_LC</th>\n",
       "      <th>CS</th>\n",
       "      <th>RG_URL</th>\n",
       "      <th>URL</th>\n",
       "      <th>CityCords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>United States</td>\n",
       "      <td>Los Angeles CA</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>CA</td>\n",
       "      <td>101 Smooth Jazz</td>\n",
       "      <td>zFDSxGwY</td>\n",
       "      <td>/listen/-101-smooth-jazz/zFDSxGwY</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>https://radio.garden/api/ara/content/listen/zF...</td>\n",
       "      <td>https://streaming.live365.com/b22139_128mp3</td>\n",
       "      <td>[-118.24368, 34.052235]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>United States</td>\n",
       "      <td>Los Angeles CA</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>CA</td>\n",
       "      <td>113FM</td>\n",
       "      <td>4KJ_uzy0</td>\n",
       "      <td>/listen/radio-113fm/4KJ_uzy0</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>https://radio.garden/api/ara/content/listen/4K...</td>\n",
       "      <td>http://113fm-edge1.cdnstream.com/1730_128</td>\n",
       "      <td>[-118.24368, 34.052235]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>United States</td>\n",
       "      <td>Los Angeles CA</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>CA</td>\n",
       "      <td>88.5 FM KCSN</td>\n",
       "      <td>SsUyqJaN</td>\n",
       "      <td>/listen/kcsn/SsUyqJaN</td>\n",
       "      <td>KCSN</td>\n",
       "      <td>https://radio.garden/api/ara/content/listen/Ss...</td>\n",
       "      <td>http://130.166.82.184:8000/;</td>\n",
       "      <td>[-118.24368, 34.052235]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>United States</td>\n",
       "      <td>Los Angeles CA</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>CA</td>\n",
       "      <td>9128.live</td>\n",
       "      <td>hacyg6SN</td>\n",
       "      <td>/listen/radio-9128-live/hacyg6SN</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>https://radio.garden/api/ara/content/listen/ha...</td>\n",
       "      <td>https://streams.radio.co/s0aa1e6f4a/listen</td>\n",
       "      <td>[-118.24368, 34.052235]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>United States</td>\n",
       "      <td>Los Angeles CA</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>CA</td>\n",
       "      <td>98.5 Flex FM</td>\n",
       "      <td>t4dqOINA</td>\n",
       "      <td>/listen/radio-98-5-flex-fm/t4dqOINA</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>https://radio.garden/api/ara/content/listen/t4...</td>\n",
       "      <td>https://streaming.live365.com/a23768</td>\n",
       "      <td>[-118.24368, 34.052235]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Country       CityState         City StateAbv      StationName  \\\n",
       "0  United States  Los Angeles CA  Los Angeles       CA  101 Smooth Jazz   \n",
       "1  United States  Los Angeles CA  Los Angeles       CA            113FM   \n",
       "2  United States  Los Angeles CA  Los Angeles       CA     88.5 FM KCSN   \n",
       "3  United States  Los Angeles CA  Los Angeles       CA        9128.live   \n",
       "4  United States  Los Angeles CA  Los Angeles       CA     98.5 Flex FM   \n",
       "\n",
       "      RG_ID                                RG_LC    CS  \\\n",
       "0  zFDSxGwY    /listen/-101-smooth-jazz/zFDSxGwY  xxxx   \n",
       "1  4KJ_uzy0         /listen/radio-113fm/4KJ_uzy0  xxxx   \n",
       "2  SsUyqJaN                /listen/kcsn/SsUyqJaN  KCSN   \n",
       "3  hacyg6SN     /listen/radio-9128-live/hacyg6SN  xxxx   \n",
       "4  t4dqOINA  /listen/radio-98-5-flex-fm/t4dqOINA  xxxx   \n",
       "\n",
       "                                              RG_URL  \\\n",
       "0  https://radio.garden/api/ara/content/listen/zF...   \n",
       "1  https://radio.garden/api/ara/content/listen/4K...   \n",
       "2  https://radio.garden/api/ara/content/listen/Ss...   \n",
       "3  https://radio.garden/api/ara/content/listen/ha...   \n",
       "4  https://radio.garden/api/ara/content/listen/t4...   \n",
       "\n",
       "                                           URL                CityCords  \n",
       "0  https://streaming.live365.com/b22139_128mp3  [-118.24368, 34.052235]  \n",
       "1    http://113fm-edge1.cdnstream.com/1730_128  [-118.24368, 34.052235]  \n",
       "2                 http://130.166.82.184:8000/;  [-118.24368, 34.052235]  \n",
       "3   https://streams.radio.co/s0aa1e6f4a/listen  [-118.24368, 34.052235]  \n",
       "4         https://streaming.live365.com/a23768  [-118.24368, 34.052235]  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us4_df = pd.read_csv('us_4.csv')\n",
    "us4_df.head()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.) Assigning path to CSV which is sourced from the 'Master' radio stations .CSV, but only contains stations FM Stations from the state Washington (these were manually looked up/ selected) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>CityState</th>\n",
       "      <th>City</th>\n",
       "      <th>StateAbv</th>\n",
       "      <th>StationName</th>\n",
       "      <th>RG_ID</th>\n",
       "      <th>RG_LC</th>\n",
       "      <th>CS</th>\n",
       "      <th>Type</th>\n",
       "      <th>RG_URL</th>\n",
       "      <th>URL</th>\n",
       "      <th>CityCords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>United States</td>\n",
       "      <td>Spokane WA</td>\n",
       "      <td>Spokane</td>\n",
       "      <td>WA</td>\n",
       "      <td>92.9 ZZU - KZZU-FM</td>\n",
       "      <td>8VcFeepP</td>\n",
       "      <td>/listen/kzzu/8VcFeepP</td>\n",
       "      <td>KZZU</td>\n",
       "      <td>FM</td>\n",
       "      <td>https://radio.garden/api/ara/content/listen/8V...</td>\n",
       "      <td>https://15373.live.streamtheworld.com/KZZUFMAA...</td>\n",
       "      <td>[-117.42605, 47.65878]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>United States</td>\n",
       "      <td>Spokane WA</td>\n",
       "      <td>Spokane</td>\n",
       "      <td>WA</td>\n",
       "      <td>Coyote Country - KEZE</td>\n",
       "      <td>FUCv80QQ</td>\n",
       "      <td>/listen/coyotecountry969/FUCv80QQ</td>\n",
       "      <td>KEZE</td>\n",
       "      <td>FM</td>\n",
       "      <td>https://radio.garden/api/ara/content/listen/FU...</td>\n",
       "      <td>https://17963.live.streamtheworld.com/KEZEFMAA...</td>\n",
       "      <td>[-117.42605, 47.65878]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>United States</td>\n",
       "      <td>Spokane WA</td>\n",
       "      <td>Spokane</td>\n",
       "      <td>WA</td>\n",
       "      <td>KPBX 91.1 Spokane Public Radio</td>\n",
       "      <td>6OP3QxSa</td>\n",
       "      <td>/listen/spokane-public-radio-kpbx-91-1/6OP3QxSa</td>\n",
       "      <td>KPBX</td>\n",
       "      <td>FM</td>\n",
       "      <td>https://radio.garden/api/ara/content/listen/6O...</td>\n",
       "      <td>https://18733.live.streamtheworld.com/KPBX_FM.mp3</td>\n",
       "      <td>[-117.42605, 47.65878]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>United States</td>\n",
       "      <td>Spokane WA</td>\n",
       "      <td>Spokane</td>\n",
       "      <td>WA</td>\n",
       "      <td>KPBZ 90.3 Spokane Public Radio</td>\n",
       "      <td>WDXAsse3</td>\n",
       "      <td>/listen/spokanepublicradio/WDXAsse3</td>\n",
       "      <td>KPBZ</td>\n",
       "      <td>FM</td>\n",
       "      <td>https://radio.garden/api/ara/content/listen/WD...</td>\n",
       "      <td>https://24883.live.streamtheworld.com/KPBZ_FM.mp3</td>\n",
       "      <td>[-117.42605, 47.65878]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>United States</td>\n",
       "      <td>Spokane WA</td>\n",
       "      <td>Spokane</td>\n",
       "      <td>WA</td>\n",
       "      <td>KYRS FM 88.1</td>\n",
       "      <td>ocrbM9-Q</td>\n",
       "      <td>/listen/kyrs-fm-88-1/ocrbM9-Q</td>\n",
       "      <td>KYRS</td>\n",
       "      <td>FM</td>\n",
       "      <td>https://radio.garden/api/ara/content/listen/oc...</td>\n",
       "      <td>https://www.ophanim.net:8444/s/7170</td>\n",
       "      <td>[-117.42605, 47.65878]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Country   CityState     City StateAbv  \\\n",
       "0  United States  Spokane WA  Spokane       WA   \n",
       "1  United States  Spokane WA  Spokane       WA   \n",
       "2  United States  Spokane WA  Spokane       WA   \n",
       "3  United States  Spokane WA  Spokane       WA   \n",
       "4  United States  Spokane WA  Spokane       WA   \n",
       "\n",
       "                      StationName     RG_ID  \\\n",
       "0              92.9 ZZU - KZZU-FM  8VcFeepP   \n",
       "1           Coyote Country - KEZE  FUCv80QQ   \n",
       "2  KPBX 91.1 Spokane Public Radio  6OP3QxSa   \n",
       "3  KPBZ 90.3 Spokane Public Radio  WDXAsse3   \n",
       "4                    KYRS FM 88.1  ocrbM9-Q   \n",
       "\n",
       "                                             RG_LC    CS Type  \\\n",
       "0                            /listen/kzzu/8VcFeepP  KZZU   FM   \n",
       "1                /listen/coyotecountry969/FUCv80QQ  KEZE   FM   \n",
       "2  /listen/spokane-public-radio-kpbx-91-1/6OP3QxSa  KPBX   FM   \n",
       "3              /listen/spokanepublicradio/WDXAsse3  KPBZ   FM   \n",
       "4                    /listen/kyrs-fm-88-1/ocrbM9-Q  KYRS   FM   \n",
       "\n",
       "                                              RG_URL  \\\n",
       "0  https://radio.garden/api/ara/content/listen/8V...   \n",
       "1  https://radio.garden/api/ara/content/listen/FU...   \n",
       "2  https://radio.garden/api/ara/content/listen/6O...   \n",
       "3  https://radio.garden/api/ara/content/listen/WD...   \n",
       "4  https://radio.garden/api/ara/content/listen/oc...   \n",
       "\n",
       "                                                 URL               CityCords  \n",
       "0  https://15373.live.streamtheworld.com/KZZUFMAA...  [-117.42605, 47.65878]  \n",
       "1  https://17963.live.streamtheworld.com/KEZEFMAA...  [-117.42605, 47.65878]  \n",
       "2  https://18733.live.streamtheworld.com/KPBX_FM.mp3  [-117.42605, 47.65878]  \n",
       "3  https://24883.live.streamtheworld.com/KPBZ_FM.mp3  [-117.42605, 47.65878]  \n",
       "4                https://www.ophanim.net:8444/s/7170  [-117.42605, 47.65878]  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WA_FM_CSV = r'/Users/michaelfelzan/Desktop/Geography-of-Radio/Data/WashingtonStations_OnlyFM.csv'\n",
    "\n",
    "# Both variable names are utilized in notebook\n",
    "source_CSV = WA_FM_CSV\n",
    "\n",
    "WA_df = pd.read_csv(WA_FM_CSV)\n",
    "WA_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.) Assigning path to a text file which will be the home to URL streams from the above .CSV which consistently 'error out' or return no results :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_wash_infoget = r'/Users/michaelfelzan/Desktop/GEO FM/FailedWashStationsInfoGetter.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "fails_txt = r'/Users/michaelfelzan/Desktop/GEO FM/FailedWashStationsInfoGetter.txt'\n",
    "fails_list = []\n",
    "\n",
    "with open(fails_txt, \"r\") as a_file:\n",
    "    for line in a_file:\n",
    "        stripped_line = line.strip()\n",
    "        fails_list.append(stripped_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['KOWA', 'KORE', 'KVSH']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fails_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.) Function / Class Definitions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (Run all of the following cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RadioTowerInfoGetter(callsign):\n",
    "    \"\"\"Function that requests the HTML of\n",
    "    the radio-locator.com webpage for whatever \n",
    "    radio station callsign is inputted into the function.\n",
    "    \n",
    "    The function parses the HTML to return a dictionary\n",
    "    containing the radio station's ERP, lat/long,\n",
    "    HAAT, HAGL, and HASL.\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    callsign : str\n",
    "        Name of station callsign (eg. KEXP)\n",
    "    \"\"\"\n",
    "    print(f\"Attempting to gather info from:  {callsign}...\")\n",
    "    \n",
    "    # Request headers\n",
    "    radiolocheaders = {\n",
    "        'sec-ch-ua' : '\"Google Chrome\";v=\"89\", \"Chromium\";v=\"89\", \";Not A Brand\";v=\"99\"',\n",
    "        'sec-ch-ua-mobile' : '?0',\n",
    "        'Upgrade-Insecure-Requests' : '1',\n",
    "        'User-Agent' : 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.114 Safari/537.36'\n",
    "    }\n",
    "    \n",
    "    # There are two different ways to search radio stations using this site/API; \n",
    "    # sometimes the 1st URL yields the results for the station but the 2nd does not,\n",
    "    # and vice versa.\n",
    "    locatorURL_1 = f'https://radio-locator.com/cgi-bin/url?call={callsign}&service=FM'\n",
    "    locatorURL_2 = f'https://radio-locator.com/cgi-bin/finder?call={callsign}&x=0&y=0&sr=Y&s=C'\n",
    "    \n",
    "    # sending request, decoding request, and assessing whether or not req. yielded \n",
    "    # valid results:\n",
    "    radiolocreq = requests.get(locatorURL_1,\n",
    "                               headers=radiolocheaders)\n",
    "    stationHTML = radiolocreq.content.decode('utf-8')\n",
    "    stationsoup = BeautifulSoup(stationHTML)\n",
    "    techvalues = stationsoup.find_all(\"td\",\n",
    "                                      class_='tech_value')\n",
    "    # if no results returned:\n",
    "    if techvalues == []:\n",
    "        print(f\"No radio tower info could be retrieved for station {callsign}\")       \n",
    "        print(\"Trying other request URL...waiting 20 seconds before retry...\")\n",
    "        # API will block IP address from sending requests if too many are sent\n",
    "        # within a certain timeframe\n",
    "        time.sleep(20)\n",
    "        # trying second URL:\n",
    "        radiolocreq = requests.get(locatorURL_2,\n",
    "                                   headers=radiolocheaders)\n",
    "        stationHTML = radiolocreq.content.decode('utf-8')\n",
    "        stationsoup = BeautifulSoup(stationHTML)\n",
    "        techvalues = stationsoup.find_all(\"td\",\n",
    "                                          class_='tech_value')\n",
    "        # if no valid results from second URL:\n",
    "        if techvalues == []:\n",
    "            print(\"Second URL method failed. Stationed logged in 'fails' .txt\")\n",
    "            with open(failed_wash_infoget, \"a+\") as file_object:\n",
    "                file_object.seek(0)\n",
    "                data = file_object.read(100)\n",
    "                if len(data) > 0 :\n",
    "                    file_object.write(\"\\n\")\n",
    "                # Writing station's callsign in 'failed\n",
    "                # Wash stations info' .txt\n",
    "                file_object.write(f\"{callsign}\")\n",
    "                \n",
    "            return False\n",
    "        # if valid results returned for 2nd URL:\n",
    "        # start parsing relevant info from req,\n",
    "        # values mapped to dictionary:\n",
    "        else:\n",
    "            ERP = []\n",
    "            coords = []\n",
    "            heights = []\n",
    "            # Parsing the HTML:\n",
    "            for item in techvalues:\n",
    "                for characters in item:\n",
    "                    for sub in characters:\n",
    "                        if '\" N' in sub:\n",
    "                            coords.append(sub)\n",
    "                if 'Watts' in characters:\n",
    "                    ERP.append(characters)\n",
    "                elif 'meters' in characters:\n",
    "                    heights.append(characters)\n",
    "                else:\n",
    "                    pass\n",
    "    \n",
    "            try:\n",
    "                itercoords = coords[0]\n",
    "            except:\n",
    "                print(\"This station didn't have coords data\")\n",
    "                itercoords = 'no_data'\n",
    "            try:\n",
    "                iterERP = ERP[0]\n",
    "            except:\n",
    "                print(\"This station didn't have ERP data\")\n",
    "                iterERP = 'no_data'\n",
    "            try:\n",
    "                iterHAAT = heights[0]\n",
    "            except:\n",
    "                print(\"This station didn't have HAAT data\")\n",
    "                iterHAAT = 'no_data'\n",
    "            try:\n",
    "                iterHAGL = heights[1]\n",
    "            except:\n",
    "                print(\"This station didn't have HAGL data\")\n",
    "                iterHAGL = 'no_data'\n",
    "            try:\n",
    "                iterHASL = heights[2]\n",
    "            except:\n",
    "                print(\"This station didn't have HASL data\")\n",
    "                iterHASL = 'no_data'\n",
    "    \n",
    "            towerinfo = {\n",
    "                'ERP' : iterERP,\n",
    "                'Coords' : itercoords,\n",
    "                'HAAT' : iterHAAT,\n",
    "                'Height Above Ground Level' : iterHAGL,\n",
    "                'Height Above Sea Level' : iterHASL\n",
    "            }\n",
    "    \n",
    "            return towerinfo\n",
    "    \n",
    "    # if valid results returned for 1st URL:\n",
    "    # start parsing relevant info from req,\n",
    "    # values mapped to dictionary:\n",
    "    else:\n",
    "        ERP = []\n",
    "        coords = []\n",
    "        heights = []\n",
    "        # Parsing the HTML:\n",
    "        for item in techvalues:\n",
    "            for characters in item:\n",
    "                for sub in characters:\n",
    "                    if '\" N' in sub:\n",
    "                        coords.append(sub)\n",
    "            if 'Watts' in characters:\n",
    "                ERP.append(characters)\n",
    "            elif 'meters' in characters:\n",
    "                heights.append(characters)\n",
    "            else:\n",
    "                pass\n",
    "    \n",
    "        try:\n",
    "            itercoords = coords[0]\n",
    "        except:\n",
    "            print(\"This station didn't have coords data\")\n",
    "            itercoords = 'no_data'\n",
    "        try:\n",
    "            iterERP = ERP[0]\n",
    "        except:\n",
    "            print(\"This station didn't have ERP data\")\n",
    "            iterERP = 'no_data'\n",
    "        try:\n",
    "            iterHAAT = heights[0]\n",
    "        except:\n",
    "            print(\"This station didn't have HAAT data\")\n",
    "            iterHAAT = 'no_data'\n",
    "        try:\n",
    "            iterHAGL = heights[1]\n",
    "        except:\n",
    "            print(\"This station didn't have HAGL data\")\n",
    "            iterHAGL = 'no_data'\n",
    "        try:\n",
    "            iterHASL = heights[2]\n",
    "        except:\n",
    "            print(\"This station didn't have HASL data\")\n",
    "            iterHASL = 'no_data'\n",
    "    \n",
    "        towerinfo = {\n",
    "            'ERP' : iterERP,\n",
    "            'Coords' : itercoords,\n",
    "            'HAAT' : iterHAAT,\n",
    "            'Height Above Ground Level' : iterHAGL,\n",
    "            'Height Above Sea Level' : iterHASL\n",
    "        }\n",
    "    \n",
    "        return towerinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StationInfoTxtWriter(stationfolderpath, call_sign):\n",
    "    \"\"\"Function that writes the dictionary return\n",
    "    from RadioTowerInfoGetter() for a station \n",
    "    to a .txt file in that station's corresponding\n",
    "    folder (only if the RadioTowerInfoGetter()\n",
    "    successfully returns tower info).\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    stationfoldername : str\n",
    "        Name of a radio stations folder (eg. CA_KALX)\n",
    "    \"\"\"\n",
    "    towerinfodict = RadioTowerInfoGetter(call_sign)\n",
    "    if towerinfodict == False:\n",
    "        #print(\"yes, it failed\")\n",
    "        pass\n",
    "    else:\n",
    "        infofilename = os.path.join(stationfolderpath,\n",
    "                                    f\"{call_sign}_towerinfo.txt\")\n",
    "        textyfile = open(infofilename,\n",
    "                    \"w+\")\n",
    "        textyfile.write(\"{\\n\")\n",
    "        for k in towerinfodict.keys():\n",
    "            textyfile.write(\"'{}':'{}'\\n\".format(k, towerinfodict[k]))\n",
    "        textyfile.write(\"}\")\n",
    "        textyfile.close()\n",
    "        print(f\"Sucessfully wrote {call_sign}_towerinfo.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dms_to_dd(d, m, s):\n",
    "    \"\"\"Function that converts degrees minutes seconds\n",
    "    into decimal degrees.\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    d : str (tho doesnt matter--converted to float in function)\n",
    "        degree\n",
    "    m : str (tho doesnt matter--converted to float in function)\n",
    "        minutes\n",
    "    s : str (tho doesnt matter--converted to float in function)\n",
    "        seconds\n",
    "    \"\"\"\n",
    "    dd = d + float(m)/60 + float(s)/3600\n",
    "    return round(dd, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DMS_Isolator(dms_string):\n",
    "    \"\"\"function that isolates the degree, minute, and second \n",
    "    components  of the DMS return from the StationInfoTxtWriter(),\n",
    "    so that they may be separately inputted into the\n",
    "    dms_to_dd() function parameters\n",
    "    \"\"\"\n",
    "    degree = dms_string.split(\"°\")[0]\n",
    "    minutefirstsplit = dms_string.split(\"'\")[0]\n",
    "    minute = minutefirstsplit.split(\"° \")[1]\n",
    "    secondfirstsplit = dms_string.split('\"')[0]\n",
    "    second = secondfirstsplit.split(\"' \")[1]\n",
    "    \n",
    "    return [degree,minute,second]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Station:\n",
    "    \"\"\"This class is for operations involving accessing\n",
    "    station info from the source CSV and the methods\n",
    "    associated with recording/sampling radio streams.\n",
    "    \n",
    "    Attributes\n",
    "    ------------\n",
    "        sourceCSV (str): The source CSV which links station\n",
    "           callsigns to their stream URL's, + other info\n",
    "        callsign (str): universal 4-character station signifier\n",
    "           (ex. 'KEXP')\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, sourceCSV, callsign):\n",
    "        self.sourceCSV = sourceCSV\n",
    "        self.callsign = callsign\n",
    "        \n",
    "        with open(sourceCSV, 'r') as read_obj:\n",
    "            csv_reader = reader(read_obj)\n",
    "            header = next(csv_reader)\n",
    "            if header != None:\n",
    "                for row in csv_reader:\n",
    "                    if row[7] == callsign:\n",
    "                        st_country = row[0]\n",
    "                        st_city = row[2]\n",
    "                        st_state = row[3]\n",
    "                        st_url = row[10]\n",
    "                        st_citycords = row[11]\n",
    "                        \n",
    "        self.country = st_country\n",
    "        self.city = st_city\n",
    "        self.state = st_state\n",
    "        self.url = st_url\n",
    "        self.citycords = st_citycords\n",
    "        self.txtpath = os.path.join(r'/Users/michaelfelzan/Desktop/GEO FM/WASH STATIONS',\n",
    "                                    callsign,\n",
    "                                    f'{callsign}.txt')\n",
    "        self.foldpath = os.path.join(r'/Users/michaelfelzan/Desktop/GEO FM/WASH STATIONS',\n",
    "                                     callsign)\n",
    "    \n",
    "    def Sampler(self, url, outpathname):\n",
    "        \"\"\"Function for sampling audio from streams.\n",
    "    \n",
    "        Parameters\n",
    "        ------------\n",
    "        url : str \n",
    "            stream URL\n",
    "        outpathname : str\n",
    "            name//dir path for outputted .mp3 file \n",
    "        \"\"\"\n",
    "        audio_input = ffmpeg.input(url)\n",
    "        audio_output = ffmpeg.output(audio_input,\n",
    "                                     outpathname,\n",
    "                                     **{'b:a': '128k'},\n",
    "                                     ss=35,\n",
    "                                     t=10)\n",
    "        #print(audio_output)\n",
    "        try:\n",
    "            audio_output.run()\n",
    "        except:\n",
    "            print(\"Error - Sampler could not work on URL stream. Skipping station.\")\n",
    "            return False\n",
    "    \n",
    "    def RouteToACRCloud(self, mp3):\n",
    "        \"\"\"Function that routes an mp3 file (path) to the\n",
    "        ACRCloud API, in order to return the song name info.\n",
    "        \n",
    "        Parameters\n",
    "        ------------\n",
    "        mp3 : str\n",
    "            Name of mp3 file (path)\n",
    "            \"\"\"\n",
    "        buf = open(mp3,'rb').read()\n",
    "        # start second will be 0; will record sampled mp3 for 10 seconds\n",
    "        songread_output = ACR_recognizer.recognize_by_filebuffer(buf, 0)\n",
    "        return songread_output\n",
    "    \n",
    "    \n",
    "    def RollRadio(self, url, callsign):\n",
    "        \"\"\"Function for initiating iterating over all station stream URLs,\n",
    "        sampling audio using above \"Sampler\" methtod, routing audio to APIs\n",
    "        (ACRCloud, Discogs), and logging song name/genre information in .txt\n",
    "        file (only if BOTH ACRCloud and Discogs yield valid returns)\n",
    "    \n",
    "        Parameters\n",
    "        ------------\n",
    "        url : str \n",
    "            stream URL\n",
    "        callsign : str\n",
    "            station callsign\n",
    "        \"\"\"\n",
    "        timerightnow = datetime.now()\n",
    "        formattedtime = timerightnow.strftime(\"%Y_%m_%d_T%H_%M_%S\")\n",
    "        \n",
    "        input_stream = url\n",
    "        input_mp3name = f'{callsign}'+f'{formattedtime}'+'.mp3'\n",
    "        itersongpath = os.path.join(r'/Users/michaelfelzan/Desktop/GEO FM',\n",
    "                                    input_mp3name)\n",
    "        \n",
    "        print(f'~~Now recording... {input_stream}')\n",
    "        samplerreturn = self.Sampler(url, itersongpath)\n",
    "        err = True\n",
    "        if samplerreturn == False:\n",
    "            pass\n",
    "        else:\n",
    "            acrcloud_output = self.RouteToACRCloud(itersongpath)\n",
    "            songread_dict = json.loads(acrcloud_output)\n",
    "    \n",
    "            if songread_dict['status']['msg'] == 'No result':\n",
    "                print(f'No ACR return from {input_mp3name}')\n",
    "                pass\n",
    "            elif songread_dict['status']['msg'] == 'May Be Mute':\n",
    "                print(f'No ACR return from {input_mp3name}')\n",
    "                pass\n",
    "            elif songread_dict['status']['msg'] == 'Decode Audio Error':\n",
    "                print(f'No ACR return from {input_mp3name}')\n",
    "                pass\n",
    "            elif songread_dict['status']['msg'] == 'requests limit exceeded, please upgrade your account':\n",
    "                print('ACRCLOUD REQUESTS LIMITS EXCEEDED, STOP PROGRAM')\n",
    "                pass\n",
    "            else:\n",
    "                try:\n",
    "                    songtitle = songread_dict['metadata']['music'][0]['title']\n",
    "                except:\n",
    "                    print(\"Error in 'Title' ACR return metadata...skipping station\")\n",
    "                    err = False\n",
    "                if err == False:\n",
    "                    pass\n",
    "                else:\n",
    "                    try:\n",
    "                        songartist = songread_dict['metadata']['music'][0]['artists'][0]['name']\n",
    "                    except:\n",
    "                        print(\"Error in 'Artist' ACR return metadata...skipping station\")\n",
    "                        err = False\n",
    "                    if err == False:\n",
    "                        pass\n",
    "                    else:\n",
    "                        try:\n",
    "                            songalbum = songread_dict['metadata']['music'][0]['album']['name']\n",
    "                        except:\n",
    "                            print(\"Error in 'Album' ACR return metadata...skipping station\")\n",
    "                            err = False\n",
    "                            pass\n",
    "                if err == False:\n",
    "                    pass\n",
    "                else:\n",
    "                    ACR_return = f'{input_mp3name} ~ song : {songtitle} by {songartist} from album {songalbum}'\n",
    "    \n",
    "                    percent20song = songtitle+'%20'+songartist+'%20'+songalbum\n",
    "                    discogs_input = percent20song.replace(\" \", \"%20\")\n",
    "                    discogs_req = ('https://api.discogs.com/database/search?q=' + \n",
    "                               discogs_input + \n",
    "                               '&key=' + \n",
    "                               client_key + \n",
    "                               '&secret=' +\n",
    "                               client_secret)\n",
    "                    discogs_req_obj = requests.get(discogs_req)\n",
    "                    discogs_songinfo_dict = json.loads(discogs_req_obj.content.decode('utf-8'))\n",
    "        \n",
    "                    if discogs_songinfo_dict['results'] == []:\n",
    "                        print(f'No Discogs return from {input_mp3name}')\n",
    "                        pass\n",
    "                    else:\n",
    "                        try:\n",
    "                            style_list = discogs_songinfo_dict['results'][0]['style']\n",
    "                        except:\n",
    "                            style_list = 'no_data'\n",
    "                        try:\n",
    "                            genre_list = discogs_songinfo_dict['results'][0]['genre']\n",
    "                        except:\n",
    "                            genre_list = 'no_data'\n",
    "                        \n",
    "                        if style_list == 'no_data':\n",
    "                            syleliststring = 'no_data'\n",
    "                        else:\n",
    "                            styleliststring = ','.join(style_list)\n",
    "                        if genre_list == 'no_data':\n",
    "                            genreliststring  = 'no_data'\n",
    "                        else:\n",
    "                            genreliststring = ','.join(genre_list)\n",
    "            \n",
    "                        Discogs_return = f'Discogs returned the genre(s): {styleliststring}'\n",
    "                \n",
    "                        parent_dir = r'/Users/michaelfelzan/Desktop/GEO FM/WASH STATIONS'\n",
    "                \n",
    "                        itertextpath = os.path.join(parent_dir,\n",
    "                                                    callsign,\n",
    "                                                    f'{callsign}.txt')\n",
    "            \n",
    "                        with open(itertextpath, \"a+\") as file_object:\n",
    "                            file_object.seek(0)\n",
    "                            data = file_object.read(100)\n",
    "                            if len(data) > 0 :\n",
    "                                file_object.write(\"\\n\")\n",
    "                            file_object.write((input_mp3name+\n",
    "                                               ','+\n",
    "                                               'song='+songtitle+','+\n",
    "                                               'artist='+songartist+','+\n",
    "                                               'album='+songalbum+','+\n",
    "                                               ####'genres='+genreliststring+','+\n",
    "                                               'styles='+styleliststring))\n",
    "                \n",
    "                        print(f\"Returned:{[ACR_return,Discogs_return]}\")\n",
    "                \n",
    "            os.remove(itersongpath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example outputs of the RadioTowerInfoGetter function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to gather info from:  KMRE...\n",
      "No radio tower info could be retrieved for station KMRE\n",
      "Trying other request URL...waiting 20 seconds before retry...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ERP': '100 Watts',\n",
       " 'Coords': '48° 44\\' 51\" N, 122° 28\\' 45\" W',\n",
       " 'HAAT': '-13.49 meters (-43 feet)',\n",
       " 'Height Above Ground Level': '38.1 meters (125 feet)',\n",
       " 'Height Above Sea Level': '65.1 meters (214 feet)'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kexptower = RadioTowerInfoGetter('KMRE')\n",
    "kexptower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to gather info from:  KKXA...\n",
      "No radio tower info could be retrieved for station KKXA\n",
      "Trying other request URL...waiting 20 seconds before retry...\n",
      "This station didn't have HAAT data\n",
      "This station didn't have HAGL data\n",
      "This station didn't have HASL data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ERP': '50,000 Watts',\n",
       " 'Coords': '47° 52\\' 31\" N, 122° 04\\' 44\" W',\n",
       " 'HAAT': 'no_data',\n",
       " 'Height Above Ground Level': 'no_data',\n",
       " 'Height Above Sea Level': 'no_data'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kkxatower = RadioTowerInfoGetter('KKXA')\n",
    "kkxatower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B.) Local Directory Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.) Creating 'list_of_wash_callsigns;' appending all names of Washington callsigns to list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_wash_callsigns = []\n",
    "\n",
    "with open(source_CSV, 'r') as read_obj:\n",
    "    csv_reader = reader(read_obj)\n",
    "    header = next(csv_reader)\n",
    "    if header != None:\n",
    "        for row in csv_reader:\n",
    "            iter_callsign = row[7]\n",
    "            list_of_wash_callsigns.append(iter_callsign)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.) Making folder directories for all Washington callsigns:\n",
    "##### !!!!!!! ONLY NEEDS TO BE RUN ONE TIME !!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for washcallsign in list_of_wash_callsigns:\n",
    "    iter_station = Station(WA_FM_CSV, washcallsign)\n",
    "    # Directory \n",
    "    directory_name = iter_station.callsign\n",
    "    \n",
    "    # Parent Directory path\n",
    "    parent_dir = r'/Users/michaelfelzan/Desktop/GEO FM/WASH STATIONS'\n",
    "    \n",
    "    # Path \n",
    "    foldpath = os.path.join(parent_dir, directory_name)\n",
    "\n",
    "    # Create the directory \n",
    "    os.mkdir(foldpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.) Creating .txt files for all Washington callsigns in correct format:\n",
    "##### !!!!!!! ONLY NEEDS TO BE RUN ONE TIME !!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for washcallsign in list_of_wash_callsigns:\n",
    "    itertextpath = os.path.join(parent_dir,\n",
    "                               washcallsign,\n",
    "                               f'{washcallsign}.txt')\n",
    "    #print(itertextpath)\n",
    "    \n",
    "    with open(itertextpath, \"w\") as f:\n",
    "        f.write(f'{washcallsign}')\n",
    "    \n",
    "    \n",
    "for washcallsign in list_of_wash_callsigns:\n",
    "    iter_station = Station(WA_FM_CSV,\n",
    "                           washcallsign)\n",
    "    itertextpath = os.path.join(parent_dir,\n",
    "                               washcallsign,\n",
    "                               f'{washcallsign}.txt')\n",
    "    with open(itertextpath, \"a+\") as file_object:\n",
    "        file_object.seek(0)\n",
    "        # If file is not empty then append '\\n'\n",
    "        data = file_object.read(100)\n",
    "        if len(data) > 0 :\n",
    "            file_object.write(\"\\n\")\n",
    "        # Append text at the end of file\n",
    "        file_object.write(f\"stream={iter_station.url}\")\n",
    "        file_object.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.) Retrieving station info from Radio-Locator and creating \"station info\" .txt for each station (that yields a valid request from Radio-Locator)\n",
    "##### !!!!!!! ONLY NEEDS TO BE RUN ONE TIME !!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = r'/Users/michaelfelzan/Desktop/GEO FM/WASH STATIONS'\n",
    "\n",
    "for cs in fails_list:\n",
    "    \n",
    "    iterfoldpathy = os.path.join(parent_dir,\n",
    "                                cs)\n",
    "    # StationInfoTxtWriter(stationfolderpath, call_sign):\n",
    "    StationInfoTxtWriter(iterfoldpathy,\n",
    "                         cs)\n",
    "    time.sleep(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.) Creating a list of callsigns for every station in our sample set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = r'/Users/michaelfelzan/Desktop/GEO FM/WASH STATIONS'\n",
    "os.chdir(parent_dir)\n",
    "wash_callsign_folds = []\n",
    "for thing in os.listdir():\n",
    "    if thing == '.DS_Store':\n",
    "        pass\n",
    "    else:\n",
    "        wash_callsign_folds.append(thing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['KPBX',\n",
       " 'KHUH',\n",
       " 'KACS',\n",
       " 'KYRS',\n",
       " 'KXDD',\n",
       " 'KZAX',\n",
       " 'KMRE',\n",
       " 'KFAE',\n",
       " 'KUKN',\n",
       " 'KOSW',\n",
       " 'KTQA',\n",
       " 'KBCS',\n",
       " 'KZTM',\n",
       " 'KEZE',\n",
       " 'KPLW',\n",
       " 'KROH',\n",
       " 'KGHI',\n",
       " 'KUPS',\n",
       " 'KIEV',\n",
       " 'KSQM',\n",
       " 'KAOS',\n",
       " 'KMIH',\n",
       " 'KPBZ',\n",
       " 'KTAH',\n",
       " 'KEFA',\n",
       " 'KSER',\n",
       " 'KNKX',\n",
       " 'KUOW',\n",
       " 'KIRO',\n",
       " 'KGRG',\n",
       " 'KEWU',\n",
       " 'KDDS',\n",
       " 'KWCW',\n",
       " 'KNHC',\n",
       " 'KEXP',\n",
       " 'KZZU',\n",
       " 'KZQM',\n",
       " 'KUGS',\n",
       " 'KPTZ',\n",
       " 'KBFG',\n",
       " 'KXLY',\n",
       " 'KODX',\n",
       " 'KGHP',\n",
       " 'KING',\n",
       " 'KYYO',\n",
       " 'KEGX',\n",
       " 'KCMS']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wash_callsign_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wash_callsign_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/michaelfelzan/Desktop/GEO FM'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(r'/Users/michaelfelzan/Desktop/GEO FM')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C.) Gathering information about each radio station's powered FM tower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example utilization of \"fezCC.js\" code (This is the Javascript pulled from the FCC FM Propogation Curve Calculator website)  :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'37.699469101964276'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream = os.popen('node fezCC.js 4.7 211 \"250\" \"-\" 60 \"0\"')\n",
    "output = (stream.read()).split('\\n')[0]\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.) Creating all individual station info CSVs (involves parsing/cleaning up returned text from initial Radio-Locator request) :\n",
    "#### !!!!! ONLY NEEDS TO BE RUN ONE TIME !!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cs in wash_callsign_folds:\n",
    "    pathtostationfold = os.path.join(parent_dir,\n",
    "                                    cs)\n",
    "    #itercallsign = station.split(\"_\")[1]\n",
    "    #stateabv = station.split(\"_\")[0]\n",
    "    pathtotowertxt = os.path.join(pathtostationfold,\n",
    "                            f'{cs}_towerinfo.txt')\n",
    "    pathtotxt = os.path.join(pathtostationfold,\n",
    "                             f'{cs}.txt')\n",
    "    newinfocsv = os.path.join(pathtostationfold,\n",
    "                             f'{cs}_INFO.csv')\n",
    "    stationfolditems = os.listdir(pathtostationfold)\n",
    "    fullpathitems = []\n",
    "    for item in stationfolditems:\n",
    "        fullpathitems.append(os.path.join(pathtostationfold,\n",
    "                                         item))\n",
    "    if pathtotowertxt in fullpathitems:\n",
    "        with open(pathtotowertxt) as foo:\n",
    "            txtz = foo.readlines()\n",
    "            for item in txtz:\n",
    "                \n",
    "                if 'ERP' in item:\n",
    "                    wattsfirstsplit = item.split(\":'\")[1]\n",
    "                    watts = wattsfirstsplit.split(\" Watts\")[0]\n",
    "                    kilowatts = (float(watts.replace(',','')))/1000\n",
    "                    \n",
    "                elif 'Coords' in item:\n",
    "                    coordsfirstsplit = item.split(\":'\")[1]\n",
    "                    lat_dms = coordsfirstsplit.split(\",\")[0]\n",
    "                    long_dms = (coordsfirstsplit.split(\", \")[1])[:-2]\n",
    "                    \n",
    "                    lat_dms_list = DMS_Isolator(lat_dms)\n",
    "                    long_dms_list = DMS_Isolator(long_dms)\n",
    "                    \n",
    "                    lat_dd = dms_to_dd(float(lat_dms_list[0]),\n",
    "                                       float(lat_dms_list[1]),\n",
    "                                       float(lat_dms_list[2]))\n",
    "                    long_dd = dms_to_dd(float(long_dms_list[0]),\n",
    "                                        float(long_dms_list[1]),\n",
    "                                        float(long_dms_list[2]))\n",
    "                    negative_longdd = long_dd*-1\n",
    "                    \n",
    "                elif 'HAAT' in item:\n",
    "                    HAATfirstsplit = item.split(\":'\")[1]\n",
    "                    HAAT_clean = HAATfirstsplit.split(\" meters\")[0]\n",
    "                    HAAT_float = float(HAAT_clean)\n",
    "        \n",
    "                    stream_param = f'node fezCC.js {kilowatts} {HAAT_float} \"250\" \"-\" 60 \"0\"'\n",
    "                    stream = os.popen(stream_param)\n",
    "                    BUFF60DIST = (stream.read()).split('\\n')[0]\n",
    "                \n",
    "        with open(newinfocsv,'w',newline='') as csvfile:\n",
    "            fieldnames = ['CALLSIGN',\n",
    "                          'LAT',\n",
    "                          'LONG',\n",
    "                          'ERP',\n",
    "                          'HAAT',\n",
    "                          '60dBu_DIST']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            writer.writerow({\n",
    "                'CALLSIGN': cs,\n",
    "                'LAT' : lat_dd,\n",
    "                'LONG' : negative_longdd,\n",
    "                'ERP' : kilowatts,\n",
    "                'HAAT' : HAAT_clean,\n",
    "                '60dBu_DIST' : BUFF60DIST\n",
    "            })\n",
    "                \n",
    "    else:\n",
    "        print(f'tower info .txt does not exist for {cs}')\n",
    "        pass\n",
    "\n",
    "print(\"\\n     *~*~~~~~**~~~~~~~~~~~~~~**~*~*\\n\"+\n",
    "      \"Successfully wrote all other station tower info CSVs.\"+\n",
    "      \"\\nCSVs outputted to respective station folders.\"\n",
    "      \"\\n   *~*~~~~~**~~~~~~~~~~~~~~**~*~*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.) Creating folder that station info tables will be copied into, so that they can be merged into one file:\n",
    "#### !!!! ONE TIME RUN !!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationinfopath = os.path.join(r'/Users/michaelfelzan/Desktop/GEO FM',\n",
    "                               \"WashStationInfoTables\")\n",
    "os.mkdir(stationinfopath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.) Copying files to that folder:\n",
    "#### !!!! ONE TIME RUN !!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COPYING FILES TO StationInfoTables FOLDER\n",
    "\n",
    "for cs in wash_callsign_folds:\n",
    "    pathtostationfold = os.path.join(parent_dir,\n",
    "                                    cs,)\n",
    "    newinfocsv = os.path.join(pathtostationfold,\n",
    "                             f'{cs}_INFO.csv')\n",
    "    stationfolditems = os.listdir(pathtostationfold)\n",
    "    fullpathitems = []\n",
    "    for item in stationfolditems:\n",
    "        fullpathitems.append(os.path.join(pathtostationfold,\n",
    "                                         item))\n",
    "    if newinfocsv in fullpathitems:\n",
    "        copyfile(newinfocsv,\n",
    "                 os.path.join(r'/Users/michaelfelzan/Desktop/GEO FM',\n",
    "                              \"WashStationInfoTables\",\n",
    "                              f'{cs}_INFO.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.) Concatenating all station info CSV's into one CSV\n",
    "#### !!!!!ONE TIME RUN!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathtofold = r'/Users/michaelfelzan/Desktop/GEO FM/WashStationInfoTables'\n",
    "INFOconcatCSV = os.path.join(pathtofold,\n",
    "                             \"WASHSTATIONINFOconcat.csv\") \n",
    "allFiles = glob.glob(pathtofold + \"/*.csv\")\n",
    "allFiles.sort()\n",
    "with open(INFOconcatCSV, 'wb') as outfile:\n",
    "        for i, fname in enumerate(allFiles):\n",
    "            with open(fname, 'rb') as infile:\n",
    "                if i != 0:\n",
    "                    infile.readline()  # Throw away header on all but first file\n",
    "            # Block copy rest of file from input to output without parsing\n",
    "                shutil.copyfileobj(infile, outfile)\n",
    "\n",
    "print(\"     *~*~~~~~**~~~~~~~~~~~~~~**~*~*\\n\"\n",
    "      \"All station tower info CSVs (that exist) have\"+\n",
    "      \"\\n      been successfully merged together\"\n",
    "      \"\\n  *~*~~~~~**~~~~~~~~~~~~~~**~*~*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.) Viewing what \"Station Info\" CSV looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CALLSIGN</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LONG</th>\n",
       "      <th>ERP</th>\n",
       "      <th>HAAT</th>\n",
       "      <th>60dBu_DIST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>KACS</td>\n",
       "      <td>46.730556</td>\n",
       "      <td>-123.025833</td>\n",
       "      <td>6.000</td>\n",
       "      <td>57.00</td>\n",
       "      <td>21.947963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>KAOS</td>\n",
       "      <td>47.015833</td>\n",
       "      <td>-122.917222</td>\n",
       "      <td>1.250</td>\n",
       "      <td>74.00</td>\n",
       "      <td>16.686530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>KBCS</td>\n",
       "      <td>47.543889</td>\n",
       "      <td>-122.109167</td>\n",
       "      <td>1.800</td>\n",
       "      <td>389.00</td>\n",
       "      <td>40.247137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>KBFG</td>\n",
       "      <td>47.667500</td>\n",
       "      <td>-122.355000</td>\n",
       "      <td>0.009</td>\n",
       "      <td>95.94</td>\n",
       "      <td>5.546802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>KCMS</td>\n",
       "      <td>47.544167</td>\n",
       "      <td>-122.108333</td>\n",
       "      <td>54.000</td>\n",
       "      <td>385.00</td>\n",
       "      <td>72.279685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>KDDS</td>\n",
       "      <td>47.312500</td>\n",
       "      <td>-123.372222</td>\n",
       "      <td>64.000</td>\n",
       "      <td>742.00</td>\n",
       "      <td>92.461470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>KEFA</td>\n",
       "      <td>47.382778</td>\n",
       "      <td>-120.293333</td>\n",
       "      <td>0.100</td>\n",
       "      <td>-71.00</td>\n",
       "      <td>5.636485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>KEGX</td>\n",
       "      <td>46.099167</td>\n",
       "      <td>-119.128889</td>\n",
       "      <td>100.000</td>\n",
       "      <td>424.40</td>\n",
       "      <td>81.532897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>KEWU</td>\n",
       "      <td>47.578611</td>\n",
       "      <td>-117.298333</td>\n",
       "      <td>10.000</td>\n",
       "      <td>429.00</td>\n",
       "      <td>57.879066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>KEXP</td>\n",
       "      <td>47.615833</td>\n",
       "      <td>-122.308889</td>\n",
       "      <td>4.700</td>\n",
       "      <td>211.00</td>\n",
       "      <td>37.699469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>KEZE</td>\n",
       "      <td>47.725833</td>\n",
       "      <td>-117.169444</td>\n",
       "      <td>8.200</td>\n",
       "      <td>365.00</td>\n",
       "      <td>52.411102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>KFAE</td>\n",
       "      <td>46.095000</td>\n",
       "      <td>-119.195833</td>\n",
       "      <td>100.000</td>\n",
       "      <td>350.00</td>\n",
       "      <td>76.082001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>KGHI</td>\n",
       "      <td>46.919444</td>\n",
       "      <td>-123.955278</td>\n",
       "      <td>1.900</td>\n",
       "      <td>18.00</td>\n",
       "      <td>11.860072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>KGHP</td>\n",
       "      <td>47.240556</td>\n",
       "      <td>-122.772222</td>\n",
       "      <td>1.350</td>\n",
       "      <td>61.00</td>\n",
       "      <td>15.402396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>KGRG</td>\n",
       "      <td>47.256111</td>\n",
       "      <td>-122.219722</td>\n",
       "      <td>0.230</td>\n",
       "      <td>116.00</td>\n",
       "      <td>13.549143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>KHUH</td>\n",
       "      <td>47.613056</td>\n",
       "      <td>-122.305000</td>\n",
       "      <td>0.015</td>\n",
       "      <td>78.00</td>\n",
       "      <td>5.677022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>KIEV</td>\n",
       "      <td>45.656111</td>\n",
       "      <td>-122.385556</td>\n",
       "      <td>0.100</td>\n",
       "      <td>30.00</td>\n",
       "      <td>5.636485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>KING</td>\n",
       "      <td>47.503611</td>\n",
       "      <td>-121.975833</td>\n",
       "      <td>66.000</td>\n",
       "      <td>707.00</td>\n",
       "      <td>91.525059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>KIRO</td>\n",
       "      <td>47.503611</td>\n",
       "      <td>-121.975833</td>\n",
       "      <td>52.000</td>\n",
       "      <td>729.00</td>\n",
       "      <td>89.847959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>KMIH</td>\n",
       "      <td>47.572222</td>\n",
       "      <td>-122.219167</td>\n",
       "      <td>0.030</td>\n",
       "      <td>69.00</td>\n",
       "      <td>6.308638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>KMRE</td>\n",
       "      <td>48.747500</td>\n",
       "      <td>-122.479167</td>\n",
       "      <td>0.100</td>\n",
       "      <td>-13.49</td>\n",
       "      <td>5.636485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>KNHC</td>\n",
       "      <td>47.542778</td>\n",
       "      <td>-122.108056</td>\n",
       "      <td>8.500</td>\n",
       "      <td>372.00</td>\n",
       "      <td>53.157927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>KNKX</td>\n",
       "      <td>47.503611</td>\n",
       "      <td>-121.975833</td>\n",
       "      <td>64.000</td>\n",
       "      <td>707.00</td>\n",
       "      <td>91.207351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>KODX</td>\n",
       "      <td>47.659167</td>\n",
       "      <td>-122.312222</td>\n",
       "      <td>0.038</td>\n",
       "      <td>48.50</td>\n",
       "      <td>5.608430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>KOSW</td>\n",
       "      <td>46.984167</td>\n",
       "      <td>-124.153889</td>\n",
       "      <td>0.076</td>\n",
       "      <td>35.23</td>\n",
       "      <td>5.651727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>KPBX</td>\n",
       "      <td>47.570278</td>\n",
       "      <td>-117.084444</td>\n",
       "      <td>56.000</td>\n",
       "      <td>725.00</td>\n",
       "      <td>90.470883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>KPBZ</td>\n",
       "      <td>47.813333</td>\n",
       "      <td>-117.507500</td>\n",
       "      <td>0.550</td>\n",
       "      <td>329.70</td>\n",
       "      <td>28.409386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>KPLW</td>\n",
       "      <td>47.323333</td>\n",
       "      <td>-120.234444</td>\n",
       "      <td>7.000</td>\n",
       "      <td>424.00</td>\n",
       "      <td>54.193125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>KPTZ</td>\n",
       "      <td>48.128056</td>\n",
       "      <td>-122.828889</td>\n",
       "      <td>2.200</td>\n",
       "      <td>102.00</td>\n",
       "      <td>22.779632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>KROH</td>\n",
       "      <td>48.015833</td>\n",
       "      <td>-122.926111</td>\n",
       "      <td>1.150</td>\n",
       "      <td>456.00</td>\n",
       "      <td>39.510279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>KSER</td>\n",
       "      <td>48.024167</td>\n",
       "      <td>-122.112500</td>\n",
       "      <td>5.800</td>\n",
       "      <td>92.00</td>\n",
       "      <td>26.994633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>KSQM</td>\n",
       "      <td>48.083333</td>\n",
       "      <td>-123.267222</td>\n",
       "      <td>2.050</td>\n",
       "      <td>-62.00</td>\n",
       "      <td>12.075181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>KTAH</td>\n",
       "      <td>47.221389</td>\n",
       "      <td>-122.469722</td>\n",
       "      <td>0.016</td>\n",
       "      <td>69.11</td>\n",
       "      <td>5.429665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>KTQA</td>\n",
       "      <td>47.239167</td>\n",
       "      <td>-122.446111</td>\n",
       "      <td>0.019</td>\n",
       "      <td>69.00</td>\n",
       "      <td>5.659309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>KUGS</td>\n",
       "      <td>48.735556</td>\n",
       "      <td>-122.482778</td>\n",
       "      <td>0.810</td>\n",
       "      <td>137.00</td>\n",
       "      <td>20.608062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>KUKN</td>\n",
       "      <td>46.162778</td>\n",
       "      <td>-122.854722</td>\n",
       "      <td>0.700</td>\n",
       "      <td>256.00</td>\n",
       "      <td>26.620990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>KUOW</td>\n",
       "      <td>47.615833</td>\n",
       "      <td>-122.308889</td>\n",
       "      <td>100.000</td>\n",
       "      <td>224.00</td>\n",
       "      <td>66.029465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>KUPS</td>\n",
       "      <td>47.263056</td>\n",
       "      <td>-122.478056</td>\n",
       "      <td>0.100</td>\n",
       "      <td>70.00</td>\n",
       "      <td>8.638738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>KWCW</td>\n",
       "      <td>46.069444</td>\n",
       "      <td>-118.331944</td>\n",
       "      <td>0.160</td>\n",
       "      <td>-16.00</td>\n",
       "      <td>6.340287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>KXDD</td>\n",
       "      <td>46.513056</td>\n",
       "      <td>-120.402500</td>\n",
       "      <td>100.000</td>\n",
       "      <td>245.00</td>\n",
       "      <td>67.828095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>KXLY</td>\n",
       "      <td>47.921667</td>\n",
       "      <td>-117.114444</td>\n",
       "      <td>37.000</td>\n",
       "      <td>914.00</td>\n",
       "      <td>91.897985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>KYRS</td>\n",
       "      <td>48.180556</td>\n",
       "      <td>-117.987500</td>\n",
       "      <td>6.800</td>\n",
       "      <td>876.00</td>\n",
       "      <td>72.624184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>KYYO</td>\n",
       "      <td>47.085556</td>\n",
       "      <td>-123.189444</td>\n",
       "      <td>11.000</td>\n",
       "      <td>321.00</td>\n",
       "      <td>52.353900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>KZAX</td>\n",
       "      <td>48.747500</td>\n",
       "      <td>-122.479167</td>\n",
       "      <td>0.100</td>\n",
       "      <td>-17.49</td>\n",
       "      <td>5.636485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>KZQM</td>\n",
       "      <td>48.125833</td>\n",
       "      <td>-123.117222</td>\n",
       "      <td>6.000</td>\n",
       "      <td>22.00</td>\n",
       "      <td>15.752658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>KZTM</td>\n",
       "      <td>46.975000</td>\n",
       "      <td>-123.140556</td>\n",
       "      <td>70.000</td>\n",
       "      <td>668.00</td>\n",
       "      <td>90.709301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>KZZU</td>\n",
       "      <td>47.595000</td>\n",
       "      <td>-117.299167</td>\n",
       "      <td>81.000</td>\n",
       "      <td>634.00</td>\n",
       "      <td>90.941259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CALLSIGN        LAT        LONG      ERP    HAAT  60dBu_DIST\n",
       "0      KACS  46.730556 -123.025833    6.000   57.00   21.947963\n",
       "1      KAOS  47.015833 -122.917222    1.250   74.00   16.686530\n",
       "2      KBCS  47.543889 -122.109167    1.800  389.00   40.247137\n",
       "3      KBFG  47.667500 -122.355000    0.009   95.94    5.546802\n",
       "4      KCMS  47.544167 -122.108333   54.000  385.00   72.279685\n",
       "5      KDDS  47.312500 -123.372222   64.000  742.00   92.461470\n",
       "6      KEFA  47.382778 -120.293333    0.100  -71.00    5.636485\n",
       "7      KEGX  46.099167 -119.128889  100.000  424.40   81.532897\n",
       "8      KEWU  47.578611 -117.298333   10.000  429.00   57.879066\n",
       "9      KEXP  47.615833 -122.308889    4.700  211.00   37.699469\n",
       "10     KEZE  47.725833 -117.169444    8.200  365.00   52.411102\n",
       "11     KFAE  46.095000 -119.195833  100.000  350.00   76.082001\n",
       "12     KGHI  46.919444 -123.955278    1.900   18.00   11.860072\n",
       "13     KGHP  47.240556 -122.772222    1.350   61.00   15.402396\n",
       "14     KGRG  47.256111 -122.219722    0.230  116.00   13.549143\n",
       "15     KHUH  47.613056 -122.305000    0.015   78.00    5.677022\n",
       "16     KIEV  45.656111 -122.385556    0.100   30.00    5.636485\n",
       "17     KING  47.503611 -121.975833   66.000  707.00   91.525059\n",
       "18     KIRO  47.503611 -121.975833   52.000  729.00   89.847959\n",
       "19     KMIH  47.572222 -122.219167    0.030   69.00    6.308638\n",
       "20     KMRE  48.747500 -122.479167    0.100  -13.49    5.636485\n",
       "21     KNHC  47.542778 -122.108056    8.500  372.00   53.157927\n",
       "22     KNKX  47.503611 -121.975833   64.000  707.00   91.207351\n",
       "23     KODX  47.659167 -122.312222    0.038   48.50    5.608430\n",
       "24     KOSW  46.984167 -124.153889    0.076   35.23    5.651727\n",
       "25     KPBX  47.570278 -117.084444   56.000  725.00   90.470883\n",
       "26     KPBZ  47.813333 -117.507500    0.550  329.70   28.409386\n",
       "27     KPLW  47.323333 -120.234444    7.000  424.00   54.193125\n",
       "28     KPTZ  48.128056 -122.828889    2.200  102.00   22.779632\n",
       "29     KROH  48.015833 -122.926111    1.150  456.00   39.510279\n",
       "30     KSER  48.024167 -122.112500    5.800   92.00   26.994633\n",
       "31     KSQM  48.083333 -123.267222    2.050  -62.00   12.075181\n",
       "32     KTAH  47.221389 -122.469722    0.016   69.11    5.429665\n",
       "33     KTQA  47.239167 -122.446111    0.019   69.00    5.659309\n",
       "34     KUGS  48.735556 -122.482778    0.810  137.00   20.608062\n",
       "35     KUKN  46.162778 -122.854722    0.700  256.00   26.620990\n",
       "36     KUOW  47.615833 -122.308889  100.000  224.00   66.029465\n",
       "37     KUPS  47.263056 -122.478056    0.100   70.00    8.638738\n",
       "38     KWCW  46.069444 -118.331944    0.160  -16.00    6.340287\n",
       "39     KXDD  46.513056 -120.402500  100.000  245.00   67.828095\n",
       "40     KXLY  47.921667 -117.114444   37.000  914.00   91.897985\n",
       "41     KYRS  48.180556 -117.987500    6.800  876.00   72.624184\n",
       "42     KYYO  47.085556 -123.189444   11.000  321.00   52.353900\n",
       "43     KZAX  48.747500 -122.479167    0.100  -17.49    5.636485\n",
       "44     KZQM  48.125833 -123.117222    6.000   22.00   15.752658\n",
       "45     KZTM  46.975000 -123.140556   70.000  668.00   90.709301\n",
       "46     KZZU  47.595000 -117.299167   81.000  634.00   90.941259"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wash_stn_info_concat = os.path.join(r'/Users/michaelfelzan/Desktop/GEO FM',\n",
    "                                    \"WashStationInfoTables\",\n",
    "                                    \"WASHSTATIONINFOconcat.csv\")\n",
    "\n",
    "wash_stn_info_df = pd.read_csv(wash_stn_info_concat)\n",
    "wash_stn_info_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D.) MULTI-PROCESSING:\n",
    "##### Note: although headway was made on the parallelization front, I have not yet figured out a way to use the Python starmap() function in tandem with a back-end, command-line program like FFMPEG.\n",
    "#### Feel free to skip all of this content until the 'END OF MULTI-PROCESSING' message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "wash_url_cs_tuples = []\n",
    "\n",
    "for cs in wash_callsign_folds:\n",
    "    globals()[f'{cs}'] = Station(WA_FM_CSV, cs)\n",
    "    wash_url_cs_tuples.append( ( globals()[f'{cs}'].url,\n",
    "                                globals()[f'{cs}'].callsign) )\n",
    "\n",
    "#wash_url_cs_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~Now recording... https://18733.live.streamtheworld.com/KPBX_FM.mp3\n",
      "~~Now recording... http://centova.rockhost.com:8001/stream\n",
      "~~Now recording... https://ic2.sslstream.com/kacs-fm\n",
      "~~Now recording... https://usa17.fastcast4u.com/proxy/kievradio?mp=/1\n"
     ]
    }
   ],
   "source": [
    "def multi_run_wrapper(args):\n",
    "    return RadioRoller(*args)\n",
    "def RadioRoller(url, callsign):\n",
    "    return (globals()[f'{callsign}']).RollRadio(globals()[f'{callsign}'].url,\n",
    "                                               globals()[f'{callsign}'].callsign)\n",
    "if __name__ == \"__main__\":\n",
    "    #multiprocessing.set_start_method('spawn')\n",
    "    pool = multiprocessing.Pool(processes=3, maxtasksperchild=1)\n",
    "    startcycletime = datetime.time(datetime.now())\n",
    "    timecounter = 0\n",
    "    while timecounter < 899:\n",
    "        pool.map(multi_run_wrapper,\n",
    "                 wash_url_cs_tuples,\n",
    "                chunksize=1)\n",
    "        endcycletime = datetime.time(datetime.now())\n",
    "        runduration = datetime.combine(date.today(), endcycletime) - datetime.combine(date.today(), startcycletime)\n",
    "        rundur_sec = runduration.seconds\n",
    "        if rundur_sec < 300:\n",
    "            print(f'finished sampling batch of stations...waiting {300-rundur_sec} seconds...')\n",
    "            time.sleep(300 - rundur_sec)\n",
    "            timecounter += 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package multiprocessing:\n",
      "\n",
      "NAME\n",
      "    multiprocessing\n",
      "\n",
      "MODULE REFERENCE\n",
      "    https://docs.python.org/3.7/library/multiprocessing\n",
      "    \n",
      "    The following documentation is automatically generated from the Python\n",
      "    source files.  It may be incomplete, incorrect or include features that\n",
      "    are considered implementation detail and may vary between Python\n",
      "    implementations.  When in doubt, consult the module reference at the\n",
      "    location listed above.\n",
      "\n",
      "DESCRIPTION\n",
      "    # Package analogous to 'threading.py' but using processes\n",
      "    #\n",
      "    # multiprocessing/__init__.py\n",
      "    #\n",
      "    # This package is intended to duplicate the functionality (and much of\n",
      "    # the API) of threading.py but uses processes instead of threads.  A\n",
      "    # subpackage 'multiprocessing.dummy' has the same API but is a simple\n",
      "    # wrapper for 'threading'.\n",
      "    #\n",
      "    # Copyright (c) 2006-2008, R Oudkerk\n",
      "    # Licensed to PSF under a Contributor Agreement.\n",
      "    #\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    connection\n",
      "    context\n",
      "    dummy (package)\n",
      "    forkserver\n",
      "    heap\n",
      "    managers\n",
      "    pool\n",
      "    popen_fork\n",
      "    popen_forkserver\n",
      "    popen_spawn_posix\n",
      "    popen_spawn_win32\n",
      "    process\n",
      "    queues\n",
      "    reduction\n",
      "    resource_sharer\n",
      "    semaphore_tracker\n",
      "    sharedctypes\n",
      "    spawn\n",
      "    synchronize\n",
      "    util\n",
      "\n",
      "SUBMODULES\n",
      "    reducer\n",
      "\n",
      "CLASSES\n",
      "    builtins.Exception(builtins.BaseException)\n",
      "        multiprocessing.context.ProcessError\n",
      "            multiprocessing.context.AuthenticationError\n",
      "            multiprocessing.context.BufferTooShort\n",
      "            multiprocessing.context.TimeoutError\n",
      "    multiprocessing.process.BaseProcess(builtins.object)\n",
      "        multiprocessing.context.Process\n",
      "    \n",
      "    class AuthenticationError(ProcessError)\n",
      "     |  Common base class for all non-exit exceptions.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      AuthenticationError\n",
      "     |      ProcessError\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors inherited from ProcessError:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.Exception:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.Exception:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "    \n",
      "    class BufferTooShort(ProcessError)\n",
      "     |  Common base class for all non-exit exceptions.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      BufferTooShort\n",
      "     |      ProcessError\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors inherited from ProcessError:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.Exception:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.Exception:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "    \n",
      "    class Process(multiprocessing.process.BaseProcess)\n",
      "     |  Process(group=None, target=None, name=None, args=(), kwargs={}, *, daemon=None)\n",
      "     |  \n",
      "     |  Process objects represent activity that is run in a separate process\n",
      "     |  \n",
      "     |  The class is analogous to `threading.Thread`\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Process\n",
      "     |      multiprocessing.process.BaseProcess\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods inherited from multiprocessing.process.BaseProcess:\n",
      "     |  \n",
      "     |  __init__(self, group=None, target=None, name=None, args=(), kwargs={}, *, daemon=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  close(self)\n",
      "     |      Close the Process object.\n",
      "     |      \n",
      "     |      This method releases resources held by the Process object.  It is\n",
      "     |      an error to call this method if the child process is still running.\n",
      "     |  \n",
      "     |  is_alive(self)\n",
      "     |      Return whether process is alive\n",
      "     |  \n",
      "     |  join(self, timeout=None)\n",
      "     |      Wait until child process terminates\n",
      "     |  \n",
      "     |  kill(self)\n",
      "     |      Terminate process; sends SIGKILL signal or uses TerminateProcess()\n",
      "     |  \n",
      "     |  run(self)\n",
      "     |      Method to be run in sub-process; can be overridden in sub-class\n",
      "     |  \n",
      "     |  start(self)\n",
      "     |      Start child process\n",
      "     |  \n",
      "     |  terminate(self)\n",
      "     |      Terminate process; sends SIGTERM signal or uses TerminateProcess()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from multiprocessing.process.BaseProcess:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  authkey\n",
      "     |  \n",
      "     |  daemon\n",
      "     |      Return whether process is a daemon\n",
      "     |  \n",
      "     |  exitcode\n",
      "     |      Return exit code of process or `None` if it has yet to stop\n",
      "     |  \n",
      "     |  ident\n",
      "     |      Return identifier (PID) of process or `None` if it has yet to start\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  pid\n",
      "     |      Return identifier (PID) of process or `None` if it has yet to start\n",
      "     |  \n",
      "     |  sentinel\n",
      "     |      Return a file descriptor (Unix) or handle (Windows) suitable for\n",
      "     |      waiting for process termination.\n",
      "    \n",
      "    class ProcessError(builtins.Exception)\n",
      "     |  Common base class for all non-exit exceptions.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ProcessError\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.Exception:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.Exception:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "    \n",
      "    class TimeoutError(ProcessError)\n",
      "     |  Common base class for all non-exit exceptions.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TimeoutError\n",
      "     |      ProcessError\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors inherited from ProcessError:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.Exception:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.Exception:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "\n",
      "FUNCTIONS\n",
      "    Array(typecode_or_type, size_or_initializer, *, lock=True) method of multiprocessing.context.DefaultContext instance\n",
      "        Returns a synchronized shared array\n",
      "    \n",
      "    Barrier(parties, action=None, timeout=None) method of multiprocessing.context.DefaultContext instance\n",
      "        Returns a barrier object\n",
      "    \n",
      "    BoundedSemaphore(value=1) method of multiprocessing.context.DefaultContext instance\n",
      "        Returns a bounded semaphore object\n",
      "    \n",
      "    Condition(lock=None) method of multiprocessing.context.DefaultContext instance\n",
      "        Returns a condition object\n",
      "    \n",
      "    Event() method of multiprocessing.context.DefaultContext instance\n",
      "        Returns an event object\n",
      "    \n",
      "    JoinableQueue(maxsize=0) method of multiprocessing.context.DefaultContext instance\n",
      "        Returns a queue object\n",
      "    \n",
      "    Lock() method of multiprocessing.context.DefaultContext instance\n",
      "        Returns a non-recursive lock object\n",
      "    \n",
      "    Manager() method of multiprocessing.context.DefaultContext instance\n",
      "        Returns a manager associated with a running server process\n",
      "        \n",
      "        The managers methods such as `Lock()`, `Condition()` and `Queue()`\n",
      "        can be used to create shared objects.\n",
      "    \n",
      "    Pipe(duplex=True) method of multiprocessing.context.DefaultContext instance\n",
      "        Returns two connection object connected by a pipe\n",
      "    \n",
      "    Pool(processes=None, initializer=None, initargs=(), maxtasksperchild=None) method of multiprocessing.context.DefaultContext instance\n",
      "        Returns a process pool object\n",
      "    \n",
      "    Queue(maxsize=0) method of multiprocessing.context.DefaultContext instance\n",
      "        Returns a queue object\n",
      "    \n",
      "    RLock() method of multiprocessing.context.DefaultContext instance\n",
      "        Returns a recursive lock object\n",
      "    \n",
      "    RawArray(typecode_or_type, size_or_initializer) method of multiprocessing.context.DefaultContext instance\n",
      "        Returns a shared array\n",
      "    \n",
      "    RawValue(typecode_or_type, *args) method of multiprocessing.context.DefaultContext instance\n",
      "        Returns a shared object\n",
      "    \n",
      "    Semaphore(value=1) method of multiprocessing.context.DefaultContext instance\n",
      "        Returns a semaphore object\n",
      "    \n",
      "    SimpleQueue() method of multiprocessing.context.DefaultContext instance\n",
      "        Returns a queue object\n",
      "    \n",
      "    Value(typecode_or_type, *args, lock=True) method of multiprocessing.context.DefaultContext instance\n",
      "        Returns a synchronized shared object\n",
      "    \n",
      "    active_children()\n",
      "        Return list of process objects corresponding to live child processes\n",
      "    \n",
      "    allow_connection_pickling() method of multiprocessing.context.DefaultContext instance\n",
      "        Install support for sending connections and sockets\n",
      "        between processes\n",
      "    \n",
      "    cpu_count() method of multiprocessing.context.DefaultContext instance\n",
      "        Returns the number of CPUs in the system\n",
      "    \n",
      "    current_process()\n",
      "        Return process object representing the current process\n",
      "    \n",
      "    freeze_support() method of multiprocessing.context.DefaultContext instance\n",
      "        Check whether this is a fake forked process in a frozen executable.\n",
      "        If so then run code specified by commandline and exit.\n",
      "    \n",
      "    get_all_start_methods() method of multiprocessing.context.DefaultContext instance\n",
      "    \n",
      "    get_context(method=None) method of multiprocessing.context.DefaultContext instance\n",
      "    \n",
      "    get_logger() method of multiprocessing.context.DefaultContext instance\n",
      "        Return package logger -- if it does not already exist then\n",
      "        it is created.\n",
      "    \n",
      "    get_start_method(allow_none=False) method of multiprocessing.context.DefaultContext instance\n",
      "    \n",
      "    log_to_stderr(level=None) method of multiprocessing.context.DefaultContext instance\n",
      "        Turn on logging and add a handler which prints to stderr\n",
      "    \n",
      "    set_executable(executable) method of multiprocessing.context.DefaultContext instance\n",
      "        Sets the path to a python.exe or pythonw.exe binary used to run\n",
      "        child processes instead of sys.executable when using the 'spawn'\n",
      "        start method.  Useful for people embedding Python.\n",
      "    \n",
      "    set_forkserver_preload(module_names) method of multiprocessing.context.DefaultContext instance\n",
      "        Set list of module names to try to load in forkserver process.\n",
      "        This is really just a hint.\n",
      "    \n",
      "    set_start_method(method, force=False) method of multiprocessing.context.DefaultContext instance\n",
      "\n",
      "DATA\n",
      "    __all__ = ['Array', 'AuthenticationError', 'Barrier', 'BoundedSemaphor...\n",
      "\n",
      "FILE\n",
      "    /opt/anaconda3/lib/python3.7/multiprocessing/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(multiprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  (( END MULTI-PROCESSING ))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E.) Turning track-play information into usable data that can be imported into ArcGIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.) Creatiing a list of station tuples (callsign + stream URL) in preparation of radio sampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KPBX https://18733.live.streamtheworld.com/KPBX_FM.mp3\n",
      "KHUH http://centova.rockhost.com:8001/stream\n",
      "KACS https://ic2.sslstream.com/kacs-fm\n",
      "KYRS https://www.ophanim.net:8444/s/7170\n",
      "KXDD https://ice7.securenetsystems.net/KXDD\n",
      "KZAX http://199.180.75.2:9395/stream/;\n",
      "KMRE http://199.180.75.2:9391/;\n",
      "KFAE http://134.121.234.129:8000/NWPRCLASSICAL\n",
      "KUKN http://www.streamcontrol.net:11060/;\n",
      "KOSW http://ophanim.net:7040/;\n",
      "KTQA https://stream.ktqa.org/ktqa.mp3\n",
      "KBCS http://www.ophanim.net:7720/stream\n",
      "KZTM http://bustosradio.com:8039/kztm\n",
      "KEZE https://17963.live.streamtheworld.com/KEZEFMAAC.aac\n",
      "KPLW https://ice10.securenetsystems.net/PLR\n",
      "KROH https://ice10.securenetsystems.net/KROH\n",
      "KGHI http://173.193.205.96:7341/stream\n",
      "KUPS https://streamingv2.shoutcast.com/kupsfm\n",
      "KIEV https://usa17.fastcast4u.com/proxy/kievradio?mp=/1\n",
      "KSQM https://video1.getstreamhosting.com:8182/stream\n",
      "KAOS http://205.134.192.90:8930/;\n",
      "KMIH https://www.streamvortex.com:8444/s/11390\n",
      "KPBZ https://24883.live.streamtheworld.com/KPBZ_FM.mp3\n",
      "KTAH https://stream.radiotacoma.org/ktah.mp3\n",
      "KEFA https://www.streamvortex.com:8444/s/11160\n",
      "KSER http://jade.streamguys1.com:4050/live\n",
      "KNKX https://live.wostreaming.net/direct/ppm-knkxfmaac256-ibc1\n",
      "KUOW https://15363.live.streamtheworld.com/KUOWFM_HIGH_MP3.mp3\n",
      "KIRO https://playerservices.streamtheworld.com/api/livestream-redirect/KIROFM.mp3\n",
      "KGRG http://204.141.167.19:7090/stream?1573141452215.mp3\n",
      "KEWU https://kewuradio.ewu.edu/KEWU_Jazz_89.5\n",
      "KDDS http://bustosradio.com:8031/kdds\n",
      "KWCW http://shoutcast.whitman.edu:8000/;\n",
      "KNHC http://knhc-ice.streamguys1.com/live\n",
      "KEXP https://kexp-mp3-128.streamguys1.com/kexp128.mp3\n",
      "KZZU https://15373.live.streamtheworld.com/KZZUFMAAC_SC\n",
      "KZQM https://crystalout.surfernetwork.com:8001/KZQM-FM_MP3\n",
      "KUGS http://peridot.streamguys.com:7170/kugs-mp3\n",
      "KPTZ https://kptz.streamguys1.com/live-mp3\n",
      "KBFG http://192.81.134.38:8001/kbfg-2\n",
      "KXLY https://13693.live.streamtheworld.com/KXLYFMAAC.aac\n",
      "KODX https://stream.pacificaservice.org:9000/kodx\n",
      "KGHP https://ic1.mainstreamnetwork.com/kghp-fm\n",
      "KING https://classicalking.streamguys1.com/king-fm-aac-128k\n",
      "KYYO http://stream1.noctel.com:7003/969kayo\n",
      "KEGX https://ice5.securenetsystems.net/KEGX\n",
      "KCMS https://crista-kcms.streamguys1.com/kcmsmp3\n"
     ]
    }
   ],
   "source": [
    "for tup in wash_url_cs_tuples:\n",
    "    print(tup[1], tup[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.) Iterating over every station URL, sampling audio, routing audio to both ACRCloud and Discogs APIs, logging associated information in each station's respective text file\n",
    "### Note: because the functionality could not be set up to 'multi-thread' this operation, code-blocks like the one below were run multiple times in order to build a working dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~Now recording... https://18733.live.streamtheworld.com/KPBX_FM.mp3\n",
      "No Discogs return from KPBX2021_12_16_T13_22_07.mp3\n",
      "~~Now recording... http://centova.rockhost.com:8001/stream\n",
      "Returned:[\"KHUH2021_12_16_T13_22_44.mp3 ~ song : Just Got Paid by Whitey Morgan And The 78's from album Hard Times and White Lines\", 'Discogs returned the genre(s): Country,Honky Tonk']\n",
      "~~Now recording... https://ic2.sslstream.com/kacs-fm\n",
      "Returned:['KACS2021_12_16_T13_23_27.mp3 ~ song : You Meet The Nicest People by Andy Williams from album Christmas Treasures', 'Discogs returned the genre(s): Vocal']\n",
      "~~Now recording... https://www.ophanim.net:8444/s/7170\n",
      "Error - Sampler could not work on URL stream. Skipping station.\n",
      "~~Now recording... https://ice7.securenetsystems.net/KXDD\n",
      "No ACR return from KXDD2021_12_16_T13_23_58.mp3\n",
      "~~Now recording... http://199.180.75.2:9395/stream/;\n",
      "No ACR return from KZAX2021_12_16_T13_24_29.mp3\n",
      "~~Now recording... http://199.180.75.2:9391/;\n",
      "No ACR return from KMRE2021_12_16_T13_24_57.mp3\n",
      "~~Now recording... http://134.121.234.129:8000/NWPRCLASSICAL\n",
      "No Discogs return from KFAE2021_12_16_T13_25_28.mp3\n",
      "~~Now recording... http://www.streamcontrol.net:11060/;\n",
      "No ACR return from KUKN2021_12_16_T13_26_11.mp3\n",
      "~~Now recording... http://ophanim.net:7040/;\n",
      "Returned:['KOSW2021_12_16_T13_26_41.mp3 ~ song : Hot Texas Christmas Day by Dale Watson from album Christmas Time in Texas', 'Discogs returned the genre(s): Country']\n",
      "~~Now recording... https://stream.ktqa.org/ktqa.mp3\n",
      "No ACR return from KTQA2021_12_16_T13_27_12.mp3\n",
      "~~Now recording... http://www.ophanim.net:7720/stream\n",
      "No ACR return from KBCS2021_12_16_T13_27_48.mp3\n",
      "~~Now recording... http://bustosradio.com:8039/kztm\n",
      "No Discogs return from KZTM2021_12_16_T13_28_04.mp3\n",
      "~~Now recording... https://17963.live.streamtheworld.com/KEZEFMAAC.aac\n",
      "Returned:['KEZE2021_12_16_T13_28_46.mp3 ~ song : For Tonight by Giveon from album For Tonight', 'Discogs returned the genre(s): Acid Jazz,Downtempo,Easy Listening,Trip Hop,Vocal']\n",
      "~~Now recording... https://ice10.securenetsystems.net/PLR\n",
      "Returned:['KPLW2021_12_16_T13_29_23.mp3 ~ song : O Come, O Come Emmanuel by Needtobreathe;For King & Country from album A Drummer Boy Christmas', 'Discogs returned the genre(s): ']\n",
      "~~Now recording... https://ice10.securenetsystems.net/KROH\n",
      "No ACR return from KROH2021_12_16_T13_30_00.mp3\n",
      "~~Now recording... http://173.193.205.96:7341/stream\n",
      "No Discogs return from KGHI2021_12_16_T13_30_39.mp3\n",
      "~~Now recording... https://streamingv2.shoutcast.com/kupsfm\n",
      "No ACR return from KUPS2021_12_16_T13_31_07.mp3\n",
      "~~Now recording... https://usa17.fastcast4u.com/proxy/kievradio?mp=/1\n",
      "No ACR return from KIEV2021_12_16_T13_31_50.mp3\n",
      "~~Now recording... https://video1.getstreamhosting.com:8182/stream\n",
      "Returned:[\"KSQM2021_12_16_T13_32_30.mp3 ~ song : I'll Be Home For Christmas by Trisha Yearwood from album Christmas\", 'Discogs returned the genre(s): Country']\n",
      "~~Now recording... http://205.134.192.90:8930/;\n",
      "Returned:[\"KAOS2021_12_16_T13_33_11.mp3 ~ song : I Believe in Music by Meschiya Lake and The Little Big Horns from album Foolers' Gold\", 'Discogs returned the genre(s): ']\n",
      "~~Now recording... https://www.streamvortex.com:8444/s/11390\n",
      "Returned:['KMIH2021_12_16_T13_33_44.mp3 ~ song : Sleigh Ride by TLC from album A Laface Family Christmas', 'Discogs returned the genre(s): RnB/Swing']\n",
      "~~Now recording... https://24883.live.streamtheworld.com/KPBZ_FM.mp3\n",
      "No ACR return from KPBZ2021_12_16_T13_34_14.mp3\n",
      "~~Now recording... https://stream.radiotacoma.org/ktah.mp3\n",
      "No ACR return from KTAH2021_12_16_T13_34_51.mp3\n",
      "~~Now recording... https://www.streamvortex.com:8444/s/11160\n",
      "No ACR return from KEFA2021_12_16_T13_35_27.mp3\n",
      "~~Now recording... http://jade.streamguys1.com:4050/live\n",
      "No Discogs return from KSER2021_12_16_T13_35_57.mp3\n",
      "~~Now recording... https://live.wostreaming.net/direct/ppm-knkxfmaac256-ibc1\n",
      "Returned:['KNKX2021_12_16_T13_36_35.mp3 ~ song : Cold Breeze by Art Farmer from album Modern Art', 'Discogs returned the genre(s): Bop,Post Bop,Hard Bop']\n",
      "~~Now recording... https://15363.live.streamtheworld.com/KUOWFM_HIGH_MP3.mp3\n",
      "No ACR return from KUOW2021_12_16_T13_37_15.mp3\n",
      "~~Now recording... https://playerservices.streamtheworld.com/api/livestream-redirect/KIROFM.mp3\n",
      "No ACR return from KIRO2021_12_16_T13_37_52.mp3\n",
      "~~Now recording... http://204.141.167.19:7090/stream?1573141452215.mp3\n",
      "Returned:['KGRG2021_12_16_T13_38_29.mp3 ~ song : Shame by Emery from album Eve', 'Discogs returned the genre(s): ']\n",
      "~~Now recording... https://kewuradio.ewu.edu/KEWU_Jazz_89.5\n",
      "Returned:['KEWU2021_12_16_T13_38_59.mp3 ~ song : Black-Eyed Susan by Corey Christiansen from album Dusk', 'Discogs returned the genre(s): ']\n",
      "~~Now recording... http://bustosradio.com:8031/kdds\n",
      "No Discogs return from KDDS2021_12_16_T13_39_44.mp3\n",
      "~~Now recording... http://shoutcast.whitman.edu:8000/;\n",
      "No ACR return from KWCW2021_12_16_T13_40_26.mp3\n",
      "~~Now recording... http://knhc-ice.streamguys1.com/live\n",
      "No Discogs return from KNHC2021_12_16_T13_40_51.mp3\n",
      "~~Now recording... https://kexp-mp3-128.streamguys1.com/kexp128.mp3\n",
      "Returned:['KEXP2021_12_16_T13_40_57.mp3 ~ song : Freak Like Me by Adina Howard from album Do You Wanna Ride? (US Release)', 'Discogs returned the genre(s): RnB/Swing']\n",
      "~~Now recording... https://15373.live.streamtheworld.com/KZZUFMAAC_SC\n",
      "Returned:['KZZU2021_12_16_T13_41_32.mp3 ~ song : Shivers by Ed Sheeran from album Shivers', 'Discogs returned the genre(s): Dance-pop']\n",
      "~~Now recording... https://crystalout.surfernetwork.com:8001/KZQM-FM_MP3\n",
      "No ACR return from KZQM2021_12_16_T13_42_14.mp3\n",
      "~~Now recording... http://peridot.streamguys.com:7170/kugs-mp3\n",
      "Returned:['KUGS2021_12_16_T13_42_16.mp3 ~ song : PENNSYLVANIA FURNACE by Lingua Ignota from album PENNSYLVANIA FURNACE', 'Discogs returned the genre(s): Industrial,Classical,Folk,Noise']\n",
      "~~Now recording... https://kptz.streamguys1.com/live-mp3\n",
      "No ACR return from KPTZ2021_12_16_T13_42_58.mp3\n",
      "~~Now recording... http://192.81.134.38:8001/kbfg-2\n",
      "No ACR return from KBFG2021_12_16_T13_43_41.mp3\n",
      "~~Now recording... https://13693.live.streamtheworld.com/KXLYFMAAC.aac\n",
      "No Discogs return from KXLY2021_12_16_T13_44_20.mp3\n",
      "~~Now recording... https://stream.pacificaservice.org:9000/kodx\n",
      "No ACR return from KODX2021_12_16_T13_44_57.mp3\n",
      "~~Now recording... https://ic1.mainstreamnetwork.com/kghp-fm\n",
      "No Discogs return from KGHP2021_12_16_T13_45_35.mp3\n",
      "~~Now recording... https://classicalking.streamguys1.com/king-fm-aac-128k\n",
      "No ACR return from KING2021_12_16_T13_46_14.mp3\n",
      "~~Now recording... http://stream1.noctel.com:7003/969kayo\n",
      "No ACR return from KYYO2021_12_16_T13_46_57.mp3\n",
      "~~Now recording... https://ice5.securenetsystems.net/KEGX\n",
      "No ACR return from KEGX2021_12_16_T13_47_36.mp3\n",
      "~~Now recording... https://crista-kcms.streamguys1.com/kcmsmp3\n",
      "Returned:['KCMS2021_12_16_T13_48_07.mp3 ~ song : Celebrate Me Home by CAIN from album Celebrate Me Home', 'Discogs returned the genre(s): Vocal,Swing,Ballad,Soft Rock,Soul,Salsa,Country Rock,Bolero']\n"
     ]
    }
   ],
   "source": [
    "for tup in wash_url_cs_tuples:\n",
    "    it_staysh = Station(WA_FM_CSV, tup[1])\n",
    "    it_staysh.RollRadio(it_staysh.url, it_staysh.callsign)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.) Demonstrating what the 'raw text' inside a given station's \"song play log\" looks like (after the above code block has been run enough times):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KEXP2021_10_25_T19_59_19.mp3,song=Friends,artist=Big Gigantic,album=Free Your Mind,styles=Hip Hop\n",
      "\n",
      "KEXP2021_10_26_T11_12_56.mp3,song=holy calamafuck,artist=Run The Jewels,album=holy calamafuck,styles=\n",
      "\n",
      "KEXP2021_10_26_T12_19_42.mp3,song=The Joke,artist=Brandi Carlile,album=The Joke,styles=Pop Rock,Rock & Roll,Country Rock,Country\n",
      "\n",
      "KEXP2021_10_26_T12_50_29.mp3,song=The Beachland Ballroom,artist=IDLES,album=The Beachland Ballroom,styles=\n",
      "\n",
      "KEXP2021_10_27_T10_19_23.mp3,song=Velouria,artist=Pixies,album=Bossanova,styles=Indie Rock\n",
      "\n",
      "KEXP2021_10_27_T10_37_45.mp3,song=Clean Air,artist=Hand Habits,album=Fun House,styles=\n",
      "\n",
      "KEXP2021_10_27_T11_31_40.mp3,song=Sunrise,artist=Explosions In The Sky,album=Big Bend (An Original Soundtrack for Public Television),styles=Post Rock,Soundtrack\n",
      "\n",
      "KEXP2021_10_27_T12_05_38.mp3,song=Marching Bands of Manhattan,artist=Death Cab for Cutie,album=Marching Bands of Manhattan,styles=Indie Rock\n",
      "\n",
      "KEXP2021_10_27_T12_28_13.mp3,song=Nighttime Drive,artist=Jay Som,album=Anak Ko,styles=Indie Rock,Lo-Fi,Indie Pop\n",
      "\n",
      "KEXP2021_10_27_T12_31_57.mp3,song=Come Around,artist=Breeze,album=Only Up,styles=Post-Punk,Brit Pop,Alternative Rock,Dream Pop\n",
      "\n",
      "KEXP2021_10_27_T12_38_08.mp3,song=Less Yes's, More No's,artist=Busdriver,album=RoadKill Overcoat,styles=Abstract\n",
      "\n",
      "KEXP2021_11_03_T10_47_40.mp3,song=Goodbye,artist=The Sundays,album=Blind,styles=Indie Rock\n",
      "\n",
      "KEXP2021_11_03_T11_23_07.mp3,song=Unbelievable,artist=EMF,album=Le 100 Sexy Hit,styles=Alternative Rock,Ballad,Brit Pop,Hip Hop,House,Pop Rap,Pop Rock,RnB/Swing,Synth-pop,UK Garage\n",
      "\n",
      "KEXP2021_11_03_T11_52_22.mp3,song=The Rat,artist=The Walkmen,album=Bows + Arrows,styles=Indie Rock\n",
      "\n",
      "KEXP2021_11_03_T14_51_08.mp3,song=You Dropped A Bomb On Me,artist=The Gap Band,album=Gap Gold - Best Of The Gap Band,styles=Funk\n"
     ]
    }
   ],
   "source": [
    "KEXP = Station(WA_FM_CSV, 'KEXP')\n",
    "\n",
    "with open(KEXP.txtpath, \"r\") as file_object:\n",
    "    Lines = file_object.readlines()\n",
    "    cleanLines = []\n",
    "    txtheader = [0,1,2]\n",
    "    for i in range(len(Lines)):\n",
    "        if i not in txtheader:\n",
    "            cleanLines.append(Lines[i])\n",
    "    \n",
    "for line in cleanLines:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.) Demonstrating the operations involved in parsing this text, in order to put all of the info neatly into a spreadsheet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pop Rock']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genresplit1 = cleanLines[0].split(\"styles=\")[1]\n",
    "genrecomma = genresplit1.split('\\n')[0]\n",
    "genrelist = genrecomma.split(',')\n",
    "genrelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Let It Be (Remastered)'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stuffbeforegenre = cleanLines[0].split(\",styles\")[0]\n",
    "albumparse = stuffbeforegenre.split('album=')[1]\n",
    "albumparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Beatles'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stuffbeforealbum = stuffbeforegenre.split(\",album=\")[0]\n",
    "artistparse = stuffbeforealbum.split(\",artist=\")[1]\n",
    "artistparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Let It Be (Remaster)'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stuffbeforeartist = stuffbeforealbum.split(\",artist=\")[0]\n",
    "songparse = stuffbeforeartist.split(\",song=\")[1]\n",
    "songparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'KPBX2021_11_03_T15_32_34.mp3'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp3filename = stuffbeforeartist.split(\",song=\")[0]\n",
    "mp3filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['KPBX2021', '11', '03', 'T15', '32', '34']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp3_components = mp3filename.split('_')\n",
    "mp3_components[-1] = mp3_components[-1].split('.mp3')[0]\n",
    "mp3_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'KPBX2021'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stateabrev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'KPBX2021'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "radiocallsgn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATE : WA\n",
      "SONG NAME : Let It Be (Remaster)\n",
      "ARTIST NAME : The Beatles\n",
      "ALBUM NAME : Let It Be (Remastered)\n",
      "STYLES : Pop Rock\n",
      "YEAR OF CAPTURE : 2021\n",
      "MONTH OF CAPTURE: 11\n",
      "DAY OF CAPTURE : 03\n",
      "HOUR OF CAPTURE : 15\n",
      "MINUTE OF CAPTURE : 32\n",
      "SECOND OF CAPTURE : 34\n"
     ]
    }
   ],
   "source": [
    "#radiocallsgn = mp3_components[0]\n",
    "\n",
    "stateabrev = 'WA'\n",
    "captureyear = mp3_components[0].split('KPBX')[1] # ENTER IN ITERSTAYSH.CALLSIGN\n",
    "capturemonth = mp3_components[1]\n",
    "captureday = mp3_components[2]\n",
    "capturehour = mp3_components[3].split('T')[1]\n",
    "captureminute = mp3_components[4]\n",
    "capturesecond = mp3_components[5]\n",
    "                                     \n",
    "print('STATE :',stateabrev)   # THIS IS GONNA NEED TO BE CODED PROPERLY EVENTUALLY\n",
    "#print('CALLSIGN :',radiocallsgn)  # JUST ACCESS THRU STATION.CALLSIGN\n",
    "print('SONG NAME :',songparse)\n",
    "print('ARTIST NAME :',artistparse)\n",
    "print('ALBUM NAME :',albumparse)\n",
    "print('STYLES :',genrecomma)\n",
    "print('YEAR OF CAPTURE :',captureyear)\n",
    "print('MONTH OF CAPTURE:',capturemonth)\n",
    "print('DAY OF CAPTURE :',captureday)\n",
    "print('HOUR OF CAPTURE :',capturehour)\n",
    "print('MINUTE OF CAPTURE :',captureminute)\n",
    "print('SECOND OF CAPTURE :',capturesecond)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.) Iterating over every station's \"song play log\" .txt file,  parsing/extracting relevant info (saving to temporary variables), and creating clean song play .CSVs for each station:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*~*~~~~~**~~~~~~~~~~~~~~**~*~*\n",
      "Sucessfully printed track play log CSVs for all stations.\n",
      "All CSVs outputted to respective station folders.\n",
      "This batch of CSVs have the extension: 2021_11_03.csv\n",
      "*~*~~~~~**~~~~~~~~~~~~~~**~*~*\n"
     ]
    }
   ],
   "source": [
    "TrackPlayLogDict = {}\n",
    "\n",
    "for station in wash_callsign_folds:\n",
    "    \n",
    "    iterstaysh = Station(WA_FM_CSV, station)\n",
    "    timerightnow = datetime.now()\n",
    "    YMD_rightnow = timerightnow.strftime(\"%Y_%m_%d\")\n",
    "    \n",
    "    TrackPlayLogDict[station] = {}\n",
    "    tracklogCSVpath = os.path.join(iterstaysh.foldpath,\n",
    "                                   f'{station}_TrackLog_{YMD_rightnow}.csv')\n",
    "    \n",
    "    with open(iterstaysh.txtpath, \"r\") as file_object:\n",
    "        Lines = file_object.readlines()\n",
    "        cleanLines = []\n",
    "        txtheader = [0,1,2]\n",
    "        for i in range(len(Lines)):\n",
    "            if i not in txtheader:\n",
    "                cleanLines.append(Lines[i])\n",
    "        \n",
    "    with open(tracklogCSVpath,'w',newline='') as csvfile:\n",
    "        fieldnames = ['stateabrev',\n",
    "                      'radiocallsgn',\n",
    "                      'trackname',\n",
    "                      'trackartist',\n",
    "                      'trackalbum',\n",
    "                      'trackstyles',\n",
    "                      'trackmp3filename',\n",
    "                      'captureyear',\n",
    "                      'capturemonth',\n",
    "                      'captureday',\n",
    "                      'capturehour',\n",
    "                      'captureminute',\n",
    "                      'capturesecond']\n",
    "        \n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        \n",
    "        for trackplaystring in cleanLines:\n",
    "            \n",
    "            genresplit1 = trackplaystring.split(\"styles=\")[1]\n",
    "            genrecomma = genresplit1.split('\\n')[0]\n",
    "            genrelist = genrecomma.split(',')\n",
    "            genrecommastr = \",\".join(genrelist)\n",
    "            \n",
    "            stuffbeforegenre = trackplaystring.split(\",styles\")[0]\n",
    "            albumparse = stuffbeforegenre.split('album=')[1]\n",
    "            \n",
    "            stuffbeforealbum = stuffbeforegenre.split(\",album=\")[0]\n",
    "            artistparse = stuffbeforealbum.split(\",artist=\")[1]\n",
    "\n",
    "            stuffbeforeartist = stuffbeforealbum.split(\",artist=\")[0]\n",
    "            songparse = stuffbeforeartist.split(\",song=\")[1]\n",
    "            \n",
    "            mp3filename = stuffbeforeartist.split(\",song=\")[0]\n",
    "            \n",
    "            mp3_components = mp3filename.split('_')\n",
    "            mp3_components[-1] = mp3_components[-1].split('.mp3')[0]\n",
    "            \n",
    "            stateabrev = 'WA' # THIS IS GONNA NEED TO BE CODED PROPERLY EVENTUALLY\n",
    "            radiocallsgn = station\n",
    "            captureyear = mp3_components[0].split(station)[1]\n",
    "            capturemonth = mp3_components[1]\n",
    "            captureday = mp3_components[2]\n",
    "            capturehour = mp3_components[3].split('T')[1]\n",
    "            captureminute = mp3_components[4]\n",
    "            capturesecond = mp3_components[5]\n",
    "            \n",
    "            writer.writerow({\n",
    "                'stateabrev' : stateabrev,\n",
    "                'radiocallsgn' : radiocallsgn,\n",
    "                'trackname' : songparse,\n",
    "                'trackartist' : artistparse,\n",
    "                'trackalbum' : albumparse,\n",
    "                'trackstyles' : genrecommastr,\n",
    "                'trackmp3filename' : mp3filename,\n",
    "                'captureyear' : captureyear,\n",
    "                'capturemonth' : capturemonth,\n",
    "                'captureday' : captureday,\n",
    "                'capturehour' : capturehour,\n",
    "                'captureminute' : captureminute,\n",
    "                'capturesecond' : capturesecond\n",
    "            })\n",
    "print(\"*~*~~~~~**~~~~~~~~~~~~~~**~*~*\\n\"\n",
    "      \"Sucessfully printed track play log CSVs for all stations.\"+\n",
    "      \"\\nAll CSVs outputted to respective station folders.\"+\n",
    "      f\"\\nThis batch of CSVs have the extension: {YMD_rightnow}.csv\"+\n",
    "      \"\\n*~*~~~~~**~~~~~~~~~~~~~~**~*~*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.) Demonstrating what one of these song play .CSV's looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stateabrev</th>\n",
       "      <th>radiocallsgn</th>\n",
       "      <th>trackname</th>\n",
       "      <th>trackartist</th>\n",
       "      <th>trackalbum</th>\n",
       "      <th>trackstyles</th>\n",
       "      <th>trackmp3filename</th>\n",
       "      <th>captureyear</th>\n",
       "      <th>capturemonth</th>\n",
       "      <th>captureday</th>\n",
       "      <th>capturehour</th>\n",
       "      <th>captureminute</th>\n",
       "      <th>capturesecond</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>WA</td>\n",
       "      <td>KEXP</td>\n",
       "      <td>Friends</td>\n",
       "      <td>Big Gigantic</td>\n",
       "      <td>Free Your Mind</td>\n",
       "      <td>Hip Hop</td>\n",
       "      <td>KEXP2021_10_25_T19_59_19.mp3</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>19</td>\n",
       "      <td>59</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>WA</td>\n",
       "      <td>KEXP</td>\n",
       "      <td>holy calamafuck</td>\n",
       "      <td>Run The Jewels</td>\n",
       "      <td>holy calamafuck</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KEXP2021_10_26_T11_12_56.mp3</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>WA</td>\n",
       "      <td>KEXP</td>\n",
       "      <td>The Joke</td>\n",
       "      <td>Brandi Carlile</td>\n",
       "      <td>The Joke</td>\n",
       "      <td>Pop Rock,Rock &amp; Roll,Country Rock,Country</td>\n",
       "      <td>KEXP2021_10_26_T12_19_42.mp3</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>WA</td>\n",
       "      <td>KEXP</td>\n",
       "      <td>The Beachland Ballroom</td>\n",
       "      <td>IDLES</td>\n",
       "      <td>The Beachland Ballroom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KEXP2021_10_26_T12_50_29.mp3</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>WA</td>\n",
       "      <td>KEXP</td>\n",
       "      <td>Velouria</td>\n",
       "      <td>Pixies</td>\n",
       "      <td>Bossanova</td>\n",
       "      <td>Indie Rock</td>\n",
       "      <td>KEXP2021_10_27_T10_19_23.mp3</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>WA</td>\n",
       "      <td>KEXP</td>\n",
       "      <td>Clean Air</td>\n",
       "      <td>Hand Habits</td>\n",
       "      <td>Fun House</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KEXP2021_10_27_T10_37_45.mp3</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>10</td>\n",
       "      <td>37</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>WA</td>\n",
       "      <td>KEXP</td>\n",
       "      <td>Sunrise</td>\n",
       "      <td>Explosions In The Sky</td>\n",
       "      <td>Big Bend (An Original Soundtrack for Public Te...</td>\n",
       "      <td>Post Rock,Soundtrack</td>\n",
       "      <td>KEXP2021_10_27_T11_31_40.mp3</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>31</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>WA</td>\n",
       "      <td>KEXP</td>\n",
       "      <td>Marching Bands of Manhattan</td>\n",
       "      <td>Death Cab for Cutie</td>\n",
       "      <td>Marching Bands of Manhattan</td>\n",
       "      <td>Indie Rock</td>\n",
       "      <td>KEXP2021_10_27_T12_05_38.mp3</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>WA</td>\n",
       "      <td>KEXP</td>\n",
       "      <td>Nighttime Drive</td>\n",
       "      <td>Jay Som</td>\n",
       "      <td>Anak Ko</td>\n",
       "      <td>Indie Rock,Lo-Fi,Indie Pop</td>\n",
       "      <td>KEXP2021_10_27_T12_28_13.mp3</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>WA</td>\n",
       "      <td>KEXP</td>\n",
       "      <td>Come Around</td>\n",
       "      <td>Breeze</td>\n",
       "      <td>Only Up</td>\n",
       "      <td>Post-Punk,Brit Pop,Alternative Rock,Dream Pop</td>\n",
       "      <td>KEXP2021_10_27_T12_31_57.mp3</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>WA</td>\n",
       "      <td>KEXP</td>\n",
       "      <td>Less Yes's, More No's</td>\n",
       "      <td>Busdriver</td>\n",
       "      <td>RoadKill Overcoat</td>\n",
       "      <td>Abstract</td>\n",
       "      <td>KEXP2021_10_27_T12_38_08.mp3</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>12</td>\n",
       "      <td>38</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>WA</td>\n",
       "      <td>KEXP</td>\n",
       "      <td>Goodbye</td>\n",
       "      <td>The Sundays</td>\n",
       "      <td>Blind</td>\n",
       "      <td>Indie Rock</td>\n",
       "      <td>KEXP2021_11_03_T10_47_40.mp3</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>47</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>WA</td>\n",
       "      <td>KEXP</td>\n",
       "      <td>Unbelievable</td>\n",
       "      <td>EMF</td>\n",
       "      <td>Le 100 Sexy Hit</td>\n",
       "      <td>Alternative Rock,Ballad,Brit Pop,Hip Hop,House...</td>\n",
       "      <td>KEXP2021_11_03_T11_23_07.mp3</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>WA</td>\n",
       "      <td>KEXP</td>\n",
       "      <td>The Rat</td>\n",
       "      <td>The Walkmen</td>\n",
       "      <td>Bows + Arrows</td>\n",
       "      <td>Indie Rock</td>\n",
       "      <td>KEXP2021_11_03_T11_52_22.mp3</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>52</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>WA</td>\n",
       "      <td>KEXP</td>\n",
       "      <td>You Dropped A Bomb On Me</td>\n",
       "      <td>The Gap Band</td>\n",
       "      <td>Gap Gold - Best Of The Gap Band</td>\n",
       "      <td>Funk</td>\n",
       "      <td>KEXP2021_11_03_T14_51_08.mp3</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>51</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stateabrev radiocallsgn                    trackname  \\\n",
       "0          WA         KEXP                      Friends   \n",
       "1          WA         KEXP              holy calamafuck   \n",
       "2          WA         KEXP                     The Joke   \n",
       "3          WA         KEXP       The Beachland Ballroom   \n",
       "4          WA         KEXP                     Velouria   \n",
       "5          WA         KEXP                    Clean Air   \n",
       "6          WA         KEXP                      Sunrise   \n",
       "7          WA         KEXP  Marching Bands of Manhattan   \n",
       "8          WA         KEXP              Nighttime Drive   \n",
       "9          WA         KEXP                  Come Around   \n",
       "10         WA         KEXP        Less Yes's, More No's   \n",
       "11         WA         KEXP                      Goodbye   \n",
       "12         WA         KEXP                 Unbelievable   \n",
       "13         WA         KEXP                      The Rat   \n",
       "14         WA         KEXP     You Dropped A Bomb On Me   \n",
       "\n",
       "              trackartist                                         trackalbum  \\\n",
       "0            Big Gigantic                                     Free Your Mind   \n",
       "1          Run The Jewels                                    holy calamafuck   \n",
       "2          Brandi Carlile                                           The Joke   \n",
       "3                   IDLES                             The Beachland Ballroom   \n",
       "4                  Pixies                                          Bossanova   \n",
       "5             Hand Habits                                          Fun House   \n",
       "6   Explosions In The Sky  Big Bend (An Original Soundtrack for Public Te...   \n",
       "7     Death Cab for Cutie                        Marching Bands of Manhattan   \n",
       "8                 Jay Som                                            Anak Ko   \n",
       "9                  Breeze                                            Only Up   \n",
       "10              Busdriver                                  RoadKill Overcoat   \n",
       "11            The Sundays                                              Blind   \n",
       "12                    EMF                                    Le 100 Sexy Hit   \n",
       "13            The Walkmen                                      Bows + Arrows   \n",
       "14           The Gap Band                    Gap Gold - Best Of The Gap Band   \n",
       "\n",
       "                                          trackstyles  \\\n",
       "0                                             Hip Hop   \n",
       "1                                                 NaN   \n",
       "2           Pop Rock,Rock & Roll,Country Rock,Country   \n",
       "3                                                 NaN   \n",
       "4                                          Indie Rock   \n",
       "5                                                 NaN   \n",
       "6                                Post Rock,Soundtrack   \n",
       "7                                          Indie Rock   \n",
       "8                          Indie Rock,Lo-Fi,Indie Pop   \n",
       "9       Post-Punk,Brit Pop,Alternative Rock,Dream Pop   \n",
       "10                                           Abstract   \n",
       "11                                         Indie Rock   \n",
       "12  Alternative Rock,Ballad,Brit Pop,Hip Hop,House...   \n",
       "13                                         Indie Rock   \n",
       "14                                               Funk   \n",
       "\n",
       "                trackmp3filename  captureyear  capturemonth  captureday  \\\n",
       "0   KEXP2021_10_25_T19_59_19.mp3         2021            10          25   \n",
       "1   KEXP2021_10_26_T11_12_56.mp3         2021            10          26   \n",
       "2   KEXP2021_10_26_T12_19_42.mp3         2021            10          26   \n",
       "3   KEXP2021_10_26_T12_50_29.mp3         2021            10          26   \n",
       "4   KEXP2021_10_27_T10_19_23.mp3         2021            10          27   \n",
       "5   KEXP2021_10_27_T10_37_45.mp3         2021            10          27   \n",
       "6   KEXP2021_10_27_T11_31_40.mp3         2021            10          27   \n",
       "7   KEXP2021_10_27_T12_05_38.mp3         2021            10          27   \n",
       "8   KEXP2021_10_27_T12_28_13.mp3         2021            10          27   \n",
       "9   KEXP2021_10_27_T12_31_57.mp3         2021            10          27   \n",
       "10  KEXP2021_10_27_T12_38_08.mp3         2021            10          27   \n",
       "11  KEXP2021_11_03_T10_47_40.mp3         2021            11           3   \n",
       "12  KEXP2021_11_03_T11_23_07.mp3         2021            11           3   \n",
       "13  KEXP2021_11_03_T11_52_22.mp3         2021            11           3   \n",
       "14  KEXP2021_11_03_T14_51_08.mp3         2021            11           3   \n",
       "\n",
       "    capturehour  captureminute  capturesecond  \n",
       "0            19             59             19  \n",
       "1            11             12             56  \n",
       "2            12             19             42  \n",
       "3            12             50             29  \n",
       "4            10             19             23  \n",
       "5            10             37             45  \n",
       "6            11             31             40  \n",
       "7            12              5             38  \n",
       "8            12             28             13  \n",
       "9            12             31             57  \n",
       "10           12             38              8  \n",
       "11           10             47             40  \n",
       "12           11             23              7  \n",
       "13           11             52             22  \n",
       "14           14             51              8  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KEXP_tracklog = r'/Users/michaelfelzan/Desktop/GEO FM/WASH STATIONS/KEXP/KEXP_TrackLog_2021_11_03.csv'\n",
    "KEXP_track_df = pd.read_csv(KEXP_tracklog)\n",
    "KEXP_track_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.) Creating a folder to store every station's song play log .CSV file in one place:\n",
    "##### !!! Only needs to be run one time !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_csv_fold = os.path.join(workindir, 'WASH SONG LOGS')\n",
    "os.mkdir(song_csv_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.) Copying all individual song play .CSVs into new folder:\n",
    "##### (one-time run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station in wash_callsign_folds:\n",
    "    pathtostationfold = os.path.join(workindir,\n",
    "                                    \"WASH STATIONS\",\n",
    "                                     station)\n",
    "    newsongcsv = os.path.join(pathtostationfold,\n",
    "                             f'{station}_TrackLog_2021_11_03.csv')\n",
    "    stationfolditems = os.listdir(pathtostationfold)\n",
    "    fullpathitems = []\n",
    "    for item in stationfolditems:\n",
    "        fullpathitems.append(os.path.join(pathtostationfold,\n",
    "                                         item))\n",
    "    if newsongcsv in fullpathitems:\n",
    "        copyfile(newsongcsv,\n",
    "                 os.path.join(workindir,\n",
    "                              \"WASH SONG LOGS\",\n",
    "                              f'{station}_TrackLog_2021_11_03.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/michaelfelzan/Desktop/GEO FM/WASH STATIONS/KCMS/KCMS_SONGLOG.csv'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsongcsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.) Merging all individual station song play .CSVs into one concatenated 'master' .CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     *~*~~~~~**~~~~~~~~~~~~~~**~*~*\n",
      "All SONG PLAY LOG CSVs (that exist) have\n",
      "      been successfully merged together\n",
      "  *~*~~~~~**~~~~~~~~~~~~~~**~*~*\n"
     ]
    }
   ],
   "source": [
    "for station in wash_callsign_folds:\n",
    "    pathtofold = os.path.join(workindir,\n",
    "                              'WASH SONG LOGS')\n",
    "SONGconcatCSV = os.path.join(pathtofold,\n",
    "                            \"CONCAT_TRACKLOG_2021_11_03.csv\") \n",
    "allFiles = glob.glob(pathtofold + \"/*.csv\")\n",
    "allFiles.sort()\n",
    "with open(SONGconcatCSV, 'wb') as outfile:\n",
    "        for i, fname in enumerate(allFiles):\n",
    "            with open(fname, 'rb') as infile:\n",
    "                if i != 0:\n",
    "                    infile.readline()  # Throw away header on all but first file\n",
    "            # Block copy rest of file from input to output without parsing\n",
    "                shutil.copyfileobj(infile, outfile)\n",
    "\n",
    "print(\"     *~*~~~~~**~~~~~~~~~~~~~~**~*~*\\n\"\n",
    "      \"All SONG PLAY LOG CSVs (that exist) have\"+\n",
    "      \"\\n      been successfully merged together\"\n",
    "      \"\\n  *~*~~~~~**~~~~~~~~~~~~~~**~*~*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_tracklog = r'/Users/michaelfelzan/Desktop/GEO FM/WASH SONG LOGS/CONCAT_TRACKLOG_2021_11_03.csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F.) Creating statistics based on genres played by each station"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.) Creating a list of unique styles/genres that appear on the concatenated song play log .CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_styles = []\n",
    "\n",
    "with open(concat_tracklog, 'r') as read_obj:\n",
    "    csv_reader = reader(read_obj)\n",
    "    header = next(csv_reader)\n",
    "    if header != None:\n",
    "        for row in csv_reader:\n",
    "            initvalue = row[5]\n",
    "            splitinit = initvalue.split(',')\n",
    "            for item in splitinit:\n",
    "                if item not in unique_styles:\n",
    "                    unique_styles.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gospel',\n",
       " 'Country',\n",
       " 'Country Rock',\n",
       " 'Religious',\n",
       " 'Easy Listening',\n",
       " '',\n",
       " 'Blues Rock',\n",
       " 'Stoner Rock',\n",
       " 'Psychedelic Rock',\n",
       " 'Indie Rock',\n",
       " 'No Wave',\n",
       " 'Surf',\n",
       " 'Norteño',\n",
       " 'Son',\n",
       " 'Ranchera',\n",
       " 'Mariachi',\n",
       " 'Vocal',\n",
       " 'Corrido',\n",
       " 'Cumbia',\n",
       " 'Tejano',\n",
       " 'Rock & Roll',\n",
       " 'Southern Rock',\n",
       " 'Hard Rock',\n",
       " 'Classic Rock',\n",
       " 'Prog Rock',\n",
       " 'Soft Rock',\n",
       " 'Pop Rock',\n",
       " 'Heavy Metal',\n",
       " 'Post Bop',\n",
       " 'Latin Jazz',\n",
       " 'Bop',\n",
       " 'Hard Bop',\n",
       " 'Contemporary Jazz',\n",
       " 'Hip Hop',\n",
       " 'Post Rock',\n",
       " 'Soundtrack',\n",
       " 'Lo-Fi',\n",
       " 'Indie Pop',\n",
       " 'Post-Punk',\n",
       " 'Brit Pop',\n",
       " 'Alternative Rock',\n",
       " 'Dream Pop',\n",
       " 'Abstract',\n",
       " 'Ballad',\n",
       " 'House',\n",
       " 'Pop Rap',\n",
       " 'RnB/Swing',\n",
       " 'Synth-pop',\n",
       " 'UK Garage',\n",
       " 'Funk',\n",
       " 'Art Rock',\n",
       " 'Baroque',\n",
       " 'Classical',\n",
       " 'Romantic',\n",
       " 'Neo-Classical',\n",
       " 'Modern',\n",
       " 'Folk Rock',\n",
       " 'Emo',\n",
       " 'Pop Punk',\n",
       " 'Post-Hardcore',\n",
       " 'Metalcore',\n",
       " 'Score',\n",
       " 'Downtempo',\n",
       " 'Ambient',\n",
       " 'Drone',\n",
       " 'Experimental',\n",
       " 'New Age',\n",
       " 'Power Pop',\n",
       " 'Acoustic',\n",
       " 'Dance-pop',\n",
       " 'Soul',\n",
       " 'Electro',\n",
       " 'Europop',\n",
       " 'Progressive House',\n",
       " 'Soul-Jazz',\n",
       " 'Music Hall',\n",
       " 'Novelty',\n",
       " 'Comedy',\n",
       " 'Psychedelic',\n",
       " 'Big Band',\n",
       " 'Smooth Jazz',\n",
       " 'Hi NRG',\n",
       " 'Happy Hardcore',\n",
       " 'Disco',\n",
       " 'Ragga HipHop',\n",
       " 'Techno',\n",
       " 'Euro House',\n",
       " 'Italodance',\n",
       " 'Swing',\n",
       " 'African',\n",
       " 'Leftfield',\n",
       " 'Afrobeat',\n",
       " 'Jazz-Funk',\n",
       " 'Bossanova',\n",
       " 'Western Swing',\n",
       " 'Honky Tonk',\n",
       " 'Broken Beat',\n",
       " 'Deep House',\n",
       " 'Musical',\n",
       " 'Conscious',\n",
       " 'Contemporary R&B',\n",
       " 'Tropical House',\n",
       " 'Electro House',\n",
       " 'Grime']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_styles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.) Defining, from the above list, which of those genres are \"electronic music\" genres (this was subjective/ based on my own knowledge/interpretation of music genres, though my decisions were corroborated by Wikipedia's definitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "electronic_music_genres = ['House',\n",
    "                          'RnB/Swing',\n",
    "                          'Synth-pop',\n",
    "                          'UK Garage',\n",
    "                          'Downtempo',\n",
    "                          'Ambient',\n",
    "                          'Drone',\n",
    "                          'New Age',\n",
    "                          'Dance-pop',\n",
    "                          'Electro',\n",
    "                          'Europop',\n",
    "                          'Progressive House',\n",
    "                          'Hi NRG',\n",
    "                          'Happy Hardcore',\n",
    "                          'Techno',\n",
    "                          'Euro House',\n",
    "                          'Italodance',\n",
    "                          'Broken Beat',\n",
    "                          'Deep House',\n",
    "                          'Contemporary R&B',\n",
    "                          'Tropical House',\n",
    "                          'Electro House',\n",
    "                          'Grime']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.) Iterating over 'master' song play log .CSV, and marking tracks which contain one of the above 'electronic' genre tags. In doing this, a proportion of 'electronic songs played' by 'total songs played' for each radio station may be created :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "electronic_11_3_path = r'/Users/michaelfelzan/Desktop/GEO FM/WASH SONG LOGS/ELECTRONIC_11_03.csv'\n",
    "        \n",
    "with open(electronic_11_3_path,'w',newline='') as csvfile:\n",
    "    fieldnames = ['stateabrev',\n",
    "                  'radiocallsgn',\n",
    "                  'trackname',\n",
    "                  'trackartist',\n",
    "                  'trackalbum',\n",
    "                  'trackstyles',\n",
    "                  'trackmp3filename',\n",
    "                  'captureyear',\n",
    "                  'capturemonth',\n",
    "                  'captureday',\n",
    "                  'capturehour',\n",
    "                  'captureminute',\n",
    "                  'capturesecond',\n",
    "                  'elec_or_not'\n",
    "                 ]\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    \n",
    "    with open(concat_tracklog, 'r') as read_obj:\n",
    "        csv_reader = reader(read_obj)\n",
    "        header = next(csv_reader)\n",
    "        if header != None:\n",
    "            for row in csv_reader:\n",
    "                if row[5] == \"\":\n",
    "                    pass\n",
    "                else:    \n",
    "                    if any(x in row[5] for x in electronic_music_genres):\n",
    "                        #print(row[5], \"Duplicates found.\")\n",
    "                        elecornot = 'yes'\n",
    "                    else:\n",
    "                        #print(row[5], \"No duplicates found.\")\n",
    "                        elecornot = 'no'\n",
    "            \n",
    "                    writer.writerow({\n",
    "                        'stateabrev' : row[0],\n",
    "                        'radiocallsgn' : row[1],\n",
    "                        'trackname' : row[2],\n",
    "                        'trackartist' : row[3],\n",
    "                        'trackalbum' : row[4],\n",
    "                        'trackstyles' : row[5],\n",
    "                        'trackmp3filename' : row[6],\n",
    "                        'captureyear' : row[7],\n",
    "                        'capturemonth' : row[8],\n",
    "                        'captureday' : row[9],\n",
    "                        'capturehour' : row[10],\n",
    "                        'captureminute' : row[11],\n",
    "                        'capturesecond' : row[12],\n",
    "                        'elec_or_not' : elecornot\n",
    "                    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.) Note the 'elec_or_not' column header added to the below spreadsheet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stateabrev</th>\n",
       "      <th>radiocallsgn</th>\n",
       "      <th>trackname</th>\n",
       "      <th>trackartist</th>\n",
       "      <th>trackalbum</th>\n",
       "      <th>trackstyles</th>\n",
       "      <th>trackmp3filename</th>\n",
       "      <th>captureyear</th>\n",
       "      <th>capturemonth</th>\n",
       "      <th>captureday</th>\n",
       "      <th>capturehour</th>\n",
       "      <th>captureminute</th>\n",
       "      <th>capturesecond</th>\n",
       "      <th>elec_or_not</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>WA</td>\n",
       "      <td>KACS</td>\n",
       "      <td>Less Like Me</td>\n",
       "      <td>Zach Williams</td>\n",
       "      <td>Rescue Story</td>\n",
       "      <td>Gospel,Country,Country Rock</td>\n",
       "      <td>KACS2021_10_26_T12_00_26.mp3</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>WA</td>\n",
       "      <td>KACS</td>\n",
       "      <td>Heaven Is The Face</td>\n",
       "      <td>Steven Curtis Chapman</td>\n",
       "      <td>Beauty Will Rise</td>\n",
       "      <td>Gospel,Religious</td>\n",
       "      <td>KACS2021_10_27_T11_28_52.mp3</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>28</td>\n",
       "      <td>52</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>WA</td>\n",
       "      <td>KACS</td>\n",
       "      <td>Bloodwashed Pilgrim</td>\n",
       "      <td>Crystal Lewis</td>\n",
       "      <td>(Hymns) My Life</td>\n",
       "      <td>Gospel,Easy Listening</td>\n",
       "      <td>KACS2021_10_27_T12_31_59.mp3</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>59</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>WA</td>\n",
       "      <td>KACS</td>\n",
       "      <td>Christ In You [Instrumental]</td>\n",
       "      <td>Integrity Music</td>\n",
       "      <td>Experience Hope [Instrumental]</td>\n",
       "      <td>Religious</td>\n",
       "      <td>KACS2021_11_03_T14_33_11.mp3</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>33</td>\n",
       "      <td>11</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>WA</td>\n",
       "      <td>KACS</td>\n",
       "      <td>My Jesus</td>\n",
       "      <td>Anne Wilson</td>\n",
       "      <td>My Jesus</td>\n",
       "      <td>Gospel</td>\n",
       "      <td>KACS2021_11_03_T15_33_54.mp3</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>33</td>\n",
       "      <td>54</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>WA</td>\n",
       "      <td>KZTM</td>\n",
       "      <td>Cómo Te Olvido</td>\n",
       "      <td>La Arrolladora Banda El Limón De René Camacho</td>\n",
       "      <td>Cómo Te Olvido</td>\n",
       "      <td>Norteño,Corrido,Cumbia,Tejano</td>\n",
       "      <td>KZTM2021_10_26_T12_03_49.mp3</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>WA</td>\n",
       "      <td>KZZU</td>\n",
       "      <td>Love Again</td>\n",
       "      <td>Dua Lipa</td>\n",
       "      <td>Love Again</td>\n",
       "      <td>Dance-pop,Synth-pop,Disco,Funk</td>\n",
       "      <td>KZZU2021_10_26_T12_11_38.mp3</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>38</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>WA</td>\n",
       "      <td>KZZU</td>\n",
       "      <td>Shivers</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>Shivers</td>\n",
       "      <td>Dance-pop</td>\n",
       "      <td>KZZU2021_10_27_T12_05_38.mp3</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>38</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>WA</td>\n",
       "      <td>KZZU</td>\n",
       "      <td>One Call Away</td>\n",
       "      <td>Charlie Puth</td>\n",
       "      <td>Nine Track Mind Deluxe</td>\n",
       "      <td>Ballad,Contemporary R&amp;B,Soul,Tropical House</td>\n",
       "      <td>KZZU2021_10_27_T12_31_57.mp3</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>57</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>WA</td>\n",
       "      <td>KZZU</td>\n",
       "      <td>Angel Baby</td>\n",
       "      <td>Troye Sivan</td>\n",
       "      <td>Angel Baby</td>\n",
       "      <td>House,Dance-pop,Vocal,Electro House,Grime,Coun...</td>\n",
       "      <td>KZZU2021_11_03_T15_52_17.mp3</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>52</td>\n",
       "      <td>17</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    stateabrev radiocallsgn                     trackname  \\\n",
       "0           WA         KACS                  Less Like Me   \n",
       "1           WA         KACS            Heaven Is The Face   \n",
       "2           WA         KACS           Bloodwashed Pilgrim   \n",
       "3           WA         KACS  Christ In You [Instrumental]   \n",
       "4           WA         KACS                      My Jesus   \n",
       "..         ...          ...                           ...   \n",
       "103         WA         KZTM                Cómo Te Olvido   \n",
       "104         WA         KZZU                    Love Again   \n",
       "105         WA         KZZU                       Shivers   \n",
       "106         WA         KZZU                 One Call Away   \n",
       "107         WA         KZZU                    Angel Baby   \n",
       "\n",
       "                                       trackartist  \\\n",
       "0                                    Zach Williams   \n",
       "1                            Steven Curtis Chapman   \n",
       "2                                    Crystal Lewis   \n",
       "3                                  Integrity Music   \n",
       "4                                      Anne Wilson   \n",
       "..                                             ...   \n",
       "103  La Arrolladora Banda El Limón De René Camacho   \n",
       "104                                       Dua Lipa   \n",
       "105                                     Ed Sheeran   \n",
       "106                                   Charlie Puth   \n",
       "107                                    Troye Sivan   \n",
       "\n",
       "                         trackalbum  \\\n",
       "0                      Rescue Story   \n",
       "1                  Beauty Will Rise   \n",
       "2                   (Hymns) My Life   \n",
       "3    Experience Hope [Instrumental]   \n",
       "4                          My Jesus   \n",
       "..                              ...   \n",
       "103                  Cómo Te Olvido   \n",
       "104                      Love Again   \n",
       "105                         Shivers   \n",
       "106          Nine Track Mind Deluxe   \n",
       "107                      Angel Baby   \n",
       "\n",
       "                                           trackstyles  \\\n",
       "0                          Gospel,Country,Country Rock   \n",
       "1                                     Gospel,Religious   \n",
       "2                                Gospel,Easy Listening   \n",
       "3                                            Religious   \n",
       "4                                               Gospel   \n",
       "..                                                 ...   \n",
       "103                      Norteño,Corrido,Cumbia,Tejano   \n",
       "104                     Dance-pop,Synth-pop,Disco,Funk   \n",
       "105                                          Dance-pop   \n",
       "106        Ballad,Contemporary R&B,Soul,Tropical House   \n",
       "107  House,Dance-pop,Vocal,Electro House,Grime,Coun...   \n",
       "\n",
       "                 trackmp3filename  captureyear  capturemonth  captureday  \\\n",
       "0    KACS2021_10_26_T12_00_26.mp3         2021            10          26   \n",
       "1    KACS2021_10_27_T11_28_52.mp3         2021            10          27   \n",
       "2    KACS2021_10_27_T12_31_59.mp3         2021            10          27   \n",
       "3    KACS2021_11_03_T14_33_11.mp3         2021            11           3   \n",
       "4    KACS2021_11_03_T15_33_54.mp3         2021            11           3   \n",
       "..                            ...          ...           ...         ...   \n",
       "103  KZTM2021_10_26_T12_03_49.mp3         2021            10          26   \n",
       "104  KZZU2021_10_26_T12_11_38.mp3         2021            10          26   \n",
       "105  KZZU2021_10_27_T12_05_38.mp3         2021            10          27   \n",
       "106  KZZU2021_10_27_T12_31_57.mp3         2021            10          27   \n",
       "107  KZZU2021_11_03_T15_52_17.mp3         2021            11           3   \n",
       "\n",
       "     capturehour  captureminute  capturesecond elec_or_not  \n",
       "0             12              0             26          no  \n",
       "1             11             28             52          no  \n",
       "2             12             31             59          no  \n",
       "3             14             33             11          no  \n",
       "4             15             33             54          no  \n",
       "..           ...            ...            ...         ...  \n",
       "103           12              3             49          no  \n",
       "104           12             11             38         yes  \n",
       "105           12              5             38         yes  \n",
       "106           12             31             57         yes  \n",
       "107           15             52             17         yes  \n",
       "\n",
       "[108 rows x 14 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elec_df_11_3 = pd.read_csv(electronic_11_3_path)\n",
    "elec_df_11_3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.) Using Pandas 'GroupBy' to summarize statistics by each radio station (callsign):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elec_or_not</th>\n",
       "      <th>no</th>\n",
       "      <th>yes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radiocallsgn</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>KACS</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>KAOS</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>KBFG</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>KCMS</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>KDDS</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>KEGX</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>KEWU</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>KEXP</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>KEZE</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>KFAE</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>KGHP</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>KGRG</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>KHUH</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>KIEV</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>KMIH</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>KMRE</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>KNHC</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>KNKX</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>KOSW</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>KPBX</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>KPLW</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>KPTZ</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>KSER</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>KSQM</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>KTAH</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>KUGS</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>KUKN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>KUPS</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>KWCW</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>KXLY</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>KZAX</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>KZQM</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>KZTM</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>KZZU</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count    \n",
       "elec_or_not     no yes\n",
       "radiocallsgn          \n",
       "KACS             5   0\n",
       "KAOS             2   0\n",
       "KBFG             2   0\n",
       "KCMS             1   0\n",
       "KDDS             2   0\n",
       "KEGX             6   0\n",
       "KEWU             4   0\n",
       "KEXP            11   1\n",
       "KEZE             2   0\n",
       "KFAE             2   0\n",
       "KGHP             1   0\n",
       "KGRG             2   0\n",
       "KHUH             2   3\n",
       "KIEV             5   0\n",
       "KMIH             4   1\n",
       "KMRE             2   0\n",
       "KNHC             0   5\n",
       "KNKX             2   0\n",
       "KOSW             2   0\n",
       "KPBX             1   0\n",
       "KPLW             0   1\n",
       "KPTZ             1   0\n",
       "KSER             1   0\n",
       "KSQM             5   1\n",
       "KTAH             1   1\n",
       "KUGS             4   0\n",
       "KUKN             3   0\n",
       "KUPS             1   0\n",
       "KWCW             6   1\n",
       "KXLY             3   0\n",
       "KZAX             2   0\n",
       "KZQM             3   1\n",
       "KZTM             1   0\n",
       "KZZU             0   4"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupby_elec11_3 = pd.DataFrame({'count' : elec_df_11_3.groupby( [ \"radiocallsgn\", \"elec_or_not\"] ).size()}).unstack(fill_value=0)\n",
    "\n",
    "groupby_elec11_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.) Printing summary statistics to .CSV, so this data may be linked with a point-class shapefile in ArcGIS Pro (allowing for spatial analysis) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_elec11_3.to_csv(r'/Users/michaelfelzan/Desktop/GEO FM/WASH SONG LOGS/11_3_electronic_yesno.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
