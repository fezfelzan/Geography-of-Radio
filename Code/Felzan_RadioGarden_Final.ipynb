{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Michael Felzan\n",
    "\n",
    "### GIS 5572 -- Final Project\n",
    "\n",
    "### Real-time Radio Station Audio Sampling, Processing, and Logging as a Proxy for Spatiotemporal Popular Music Trends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ ð“€‚ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NOTE: in order to import 'acrcloud' properly, user must go to terminal, navigate to base of project folder repo, and and type 'sudo python setup.py install'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import vlc\n",
    "import requests\n",
    "import urllib.parse\n",
    "from urllib.parse import parse_qs\n",
    "import os\n",
    "import csv\n",
    "import shutil\n",
    "from shutil import copyfile\n",
    "import sys\n",
    "import json\n",
    "import glob\n",
    "from acrcloud.recognizer import ACRCloudRecognizer\n",
    "from acrcloud.recognizer import ACRCloudRecognizeType\n",
    "from itertools import islice\n",
    "from bs4 import BeautifulSoup\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "\n",
    "# The following packages were not used in this code, but\n",
    "# if the program was to be expanded, using OAuth1 / \n",
    "# Discog's more advanced API might be required... \n",
    "\n",
    "    #from requests_oauthlib import OAuth1\n",
    "    #from requests_oauthlib import OAuth1Session\n",
    "    #from flask import Flask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Inputs -- Working Directory Path / API Key Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Path to base of user's working folder/ repo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "workindir = r'/Users/michaelfelzan/Desktop/RadioTestRun'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### User must input their personal ACR Cloud Access and Secret keys here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "acrcloud_accesskey = '4554490a1c83c19ea6745ed6bfbbea7d'\n",
    "acrcloud_secretkey = 'HcoVKztgUltoNAwlPxpWoIJzt86HoKk9KTiByPTl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### User must input their personal Discogs Access and Secret keys here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_key = 'gQylLmyvGPfyGEvmFyRx'\n",
    "client_secret = 'KJnItkPttweOtFSkqwAiTTCWJsOnIobH'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ âˆ¿ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# { { { { { { { {   {  { { { { { {  { { {  { { { { { {_  Section A.   _} } } } } } } } } }  } } }  } } } } } } } } } } } }   }   }    } "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up radio station dictonary structure,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with each radio station's folder name (within the 'STATIONS' folder) as a key, and the value being a nested dictonary, containing: the dir path to that folder, the path to that folder's '.txt' file, and the online radio stream URL (contained within the .txt file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### creating list of station (folder) names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MN_KCMP', 'MN_KQRS', 'MN_KSTP', 'MN_KUOM', 'MN_KXXR']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(os.path.join(workindir,\"FiveStations\"))\n",
    "\n",
    "stationfolders_wdsstore = os.listdir()\n",
    "\n",
    "# making sure the '.DS_Store' file isnt included\n",
    "stationfolders = []\n",
    "for item in stationfolders_wdsstore:\n",
    "    if item=='.DS_Store':\n",
    "        pass\n",
    "    else:\n",
    "        stationfolders.append(item)\n",
    "sortedstations = sorted(stationfolders)\n",
    "sortedstations[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### creating list of the pathes to each station folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/michaelfelzan/Desktop/RadioTestRun/FiveStations/MN_KCMP',\n",
       " '/Users/michaelfelzan/Desktop/RadioTestRun/FiveStations/MN_KQRS',\n",
       " '/Users/michaelfelzan/Desktop/RadioTestRun/FiveStations/MN_KSTP',\n",
       " '/Users/michaelfelzan/Desktop/RadioTestRun/FiveStations/MN_KUOM',\n",
       " '/Users/michaelfelzan/Desktop/RadioTestRun/FiveStations/MN_KXXR']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathes_to_folders = []\n",
    "pathes_to_txts = []\n",
    "\n",
    "for foldername in sortedstations:\n",
    "    iter_path_to_folder = os.path.join(workindir,'FiveStations',foldername)\n",
    "    iter_path_to_txts = os.path.join(iter_path_to_folder,(foldername+'.txt'))\n",
    "    pathes_to_folders.append(iter_path_to_folder)\n",
    "    pathes_to_txts.append(iter_path_to_txts)\n",
    "pathes_to_folders[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### creating list of the pathes to each station's respective .txt file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/michaelfelzan/Desktop/RadioTestRun/FiveStations/MN_KCMP/MN_KCMP.txt',\n",
       " '/Users/michaelfelzan/Desktop/RadioTestRun/FiveStations/MN_KQRS/MN_KQRS.txt',\n",
       " '/Users/michaelfelzan/Desktop/RadioTestRun/FiveStations/MN_KSTP/MN_KSTP.txt',\n",
       " '/Users/michaelfelzan/Desktop/RadioTestRun/FiveStations/MN_KUOM/MN_KUOM.txt',\n",
       " '/Users/michaelfelzan/Desktop/RadioTestRun/FiveStations/MN_KXXR/MN_KXXR.txt']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathes_to_txts[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### creating dictionary structure, where each station (folder) name is the key, and the value is a nested dictionary, which contains key/value pairs for each station's folder pathname, path to .txt file, and radio station URL stream (accessed from .txt file):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_dict = {}\n",
    "\n",
    "for foldername in sortedstations:\n",
    "    iter_path_to_folder = os.path.join(workindir,\n",
    "                                       'FiveStations',\n",
    "                                       foldername)\n",
    "    iter_path_to_txts = os.path.join(iter_path_to_folder,\n",
    "                                     (foldername+'.txt'))\n",
    "    station_dict[foldername] = {}\n",
    "    station_dict[foldername]['folderpath'] = iter_path_to_folder\n",
    "    station_dict[foldername]['txtpath'] = iter_path_to_txts\n",
    "    \n",
    "    with open(iter_path_to_txts) as f:\n",
    "        txtcontents = f.readlines()\n",
    "        # isolating just the stream URL link\n",
    "        splitafterstream = txtcontents[1].split('stream=')\n",
    "        splitonnewline = splitafterstream[1].split('\\n')\n",
    "        isoed_streamlink = splitonnewline[0]\n",
    "        station_dict[foldername]['streamlink'] = isoed_streamlink"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Demonstration of how info may be retrieved from 'station_dict'  for a given station:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://radio.garden/api/ara/content/listen/LOYtZb13/channel.mp3?1624605094130'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_dict['MN_KXXR']['streamlink']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/michaelfelzan/Desktop/RadioTestRun/FiveStations/MN_KCMP'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_dict['MN_KCMP']['folderpath']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/michaelfelzan/Desktop/RadioTestRun/FiveStations/MN_KCMP/MN_KCMP.txt'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_dict['MN_KCMP']['txtpath']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# { { { { { { { {   {  { { { { { {  { { {  { { { { { {_  Section B.   _} } } } } } } } } }  } } }  } } } } } } } } } } } }   }   }    } "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating designated folders within each station folder to contain mp3 recordings and 'cue files':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station in sortedstations:\n",
    "    iterfoldpath = station_dict[station]['folderpath']\n",
    "    mp3foldpath = os.path.join(iterfoldpath, \"mp3_recordings\")\n",
    "    # 'cue' files are necessary for VLC module to run....i think\n",
    "    cuefoldpath = os.path.join(iterfoldpath, \"cue_files\")\n",
    "    \n",
    "    # These are commented out b/c I already made the directories;\n",
    "    # Uncomment the following two lines if youd like to create these\n",
    "    # directories.\n",
    "    \n",
    "    #os.mkdir(mp3foldpath)\n",
    "    #os.mkdir(cuefoldpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up function which uses the VLC module to record 12 second mp3 clips from a radio station, saves mp3s to disc:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Functions which initialize VLC instance/player:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InitializeVLCCue(name,instream,audiofile):\n",
    "    \"\"\"Initializes the VLC cue file.\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    name : str\n",
    "        Name of cue file. Should be formatted like:\n",
    "        <stationname>_<formattedtime>_CUE  (no extension)\n",
    "    instream : str\n",
    "        URL link to radio station stream.\n",
    "    audiofile : str\n",
    "        Name of mp3 file. Should be formatted like:\n",
    "        <stationname>_<formattedtime>_.mp3\n",
    "        \"\"\"\n",
    "    cueout = '%s.cue'%(name)\n",
    "    with open(cueout, 'w') as outf_writer:\n",
    "        outf_writer.write('PERFORMER \"%s\"\\n'%(instream))\n",
    "        outf_writer.write('TITLE \"%s\"\\n' %(name))\n",
    "        outf_writer.write('FILE \"%s\" WAVE\\n' %(audiofile))\n",
    "\n",
    "        \n",
    "def InitializeVLCPlayer(instream, audiofile):\n",
    "    \"\"\"Initializes a VLC player which plays \n",
    "    locally and saves to an mp3file.\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    instream : str\n",
    "        URL link to radio station stream.\n",
    "    audiofile : str\n",
    "        Name of mp3 file. Should be formatted like:\n",
    "        <stationname>_<formattedtime>_.mp3\n",
    "        \"\"\"\n",
    "    inst = vlc.Instance()   \n",
    "    p = inst.media_player_new()\n",
    "    \n",
    "    # default stream output chain\n",
    "    cmd1 = \"sout=#duplicate{dst=file{dst=%s},dst=display}\" %(audiofile)\n",
    "    # stream output\n",
    "    cmd2 =\"no-sout-rtp-sap\"\n",
    "    # filename for stream\n",
    "    cmd3 = \"no-sout-standard-sap\"\n",
    "    # play locally while streaming it\n",
    "    cmd4 =\"sout-keep\"\n",
    "    # https://wiki.videolan.org/VLC_command-line_help\n",
    "    \n",
    "    med=inst.media_new(instream,cmd1,cmd2,cmd3,cmd4) \n",
    "    # get media resource locator\n",
    "    med.get_mrl()\n",
    "    med.add_option('start-time=0.0')\n",
    "    p.set_media(med)\n",
    "    \n",
    "    return p, med"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Building function which utilizes above functions, to record 12 second mp3 clip from an inputted radio stream:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RadioMP3Recorder(cuename, instream, audiofile):\n",
    "    \"\"\"Function that utilizes the InitializeVLCCue() and\n",
    "    InitializeVLCPlayer() functions, in order to sample\n",
    "    a 12-second mp3 clip from an inputted radio stream.\n",
    "    Parameters are the same as above two functions:\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    cuename : str\n",
    "        Name of cue file. Should be formatted like:\n",
    "        <stationname>_<formattedtime>_CUE  (no extension)\n",
    "    instream : str\n",
    "        URL link to radio station stream.\n",
    "    audiofile : str\n",
    "        Name of mp3 file. Should be formatted like:\n",
    "        <stationname>_<formattedtime>_.mp3\n",
    "        \"\"\"\n",
    "    InitializeVLCCue(cuename, instream, audiofile)\n",
    "    p,med = InitializeVLCPlayer(instream, audiofile)\n",
    "    p.play()\n",
    "    # 30 second sleep period between playing stream and\n",
    "    # stopping is needed needed because function must wait\n",
    "    # ~15 seconds before recording, in order to bypass \n",
    "    # possible ads, and return a long enough (~12sec) clip.\n",
    "    time.sleep(40)\n",
    "    p.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACRCloud API Route Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Configuring ACR Cloud song recognizer function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "acrcloud_config = {\n",
    "    'host':'identify-eu-west-1.acrcloud.com',\n",
    "    'access_key': acrcloud_accesskey,\n",
    "    'access_secret': acrcloud_secretkey,\n",
    "    'recognize_type': ACRCloudRecognizeType.ACR_OPT_REC_AUDIO, # could be 'humming audio' as well\n",
    "    'debug':False,\n",
    "    'timeout':5 # seconds\n",
    "}\n",
    "\n",
    "# ACRCloudRecognizer was an imported at the start of notebook\n",
    "ACR_recognizer = ACRCloudRecognizer(acrcloud_config)\n",
    "\n",
    "\n",
    "def RouteToACRCloud(mp3):\n",
    "    \"\"\"Function that routes an mp3 file (path) to the\n",
    "    ACRCloud API, in order to return the song name info.\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    mp3 : str\n",
    "        Name of mp3 file (path)\n",
    "        \"\"\"\n",
    "    buf = open(mp3,'rb').read()\n",
    "    # start second will be 0; will record sampled mp3 for 10 seconds\n",
    "    songread_output = ACR_recognizer.recognize_by_filebuffer(buf, 30)\n",
    "    return songread_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://radio.garden/api/ara/content/listen/3WobtoSX/channel.mp3?1624605251991\n",
      "<class 'str'>\n",
      "MN_KCMP_2021_06_25_T02_35_13_CUE\n",
      "<class 'str'>\n",
      "MN_KCMP_2021_06_25_T02_35_13.mp3\n",
      "<class 'str'>\n",
      "https://radio.garden/api/ara/content/listen/bTYyl91D/channel.mp3?1624605308486\n",
      "<class 'str'>\n",
      "MN_KQRS_2021_06_25_T02_35_13_CUE\n",
      "<class 'str'>\n",
      "MN_KQRS_2021_06_25_T02_35_13.mp3\n",
      "<class 'str'>\n",
      "http://18253.live.streamtheworld.com/KSTPFMAAC.aac?dist=hubbard&source=hubbard-web&ttag=web&gdpr=0\n",
      "<class 'str'>\n",
      "MN_KSTP_2021_06_25_T02_35_13_CUE\n",
      "<class 'str'>\n",
      "MN_KSTP_2021_06_25_T02_35_13.mp3\n",
      "<class 'str'>\n",
      "http://radio.garden/api/ara/content/listen/gs47Xnpy/channel.mp3?1618447430795\n",
      "<class 'str'>\n",
      "MN_KUOM_2021_06_25_T02_35_13_CUE\n",
      "<class 'str'>\n",
      "MN_KUOM_2021_06_25_T02_35_13.mp3\n",
      "<class 'str'>\n",
      "https://radio.garden/api/ara/content/listen/LOYtZb13/channel.mp3?1624605094130\n",
      "<class 'str'>\n",
      "MN_KXXR_2021_06_25_T02_35_13_CUE\n",
      "<class 'str'>\n",
      "MN_KXXR_2021_06_25_T02_35_13.mp3\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "for station in station_dict:\n",
    "    timerightnow = datetime.datetime.now()\n",
    "    #print(timerightnow)\n",
    "    formattedtime = timerightnow.strftime(\"%Y_%m_%d_T%H_%M_%S\")\n",
    "    #print(formattedtime)\n",
    "    \n",
    "    input_stream = station_dict[station]['streamlink']\n",
    "    print(input_stream)\n",
    "    print(type(input_stream))\n",
    "    input_cuename = station+'_'+formattedtime+'_CUE'\n",
    "    print(input_cuename)\n",
    "    print(type(input_cuename))\n",
    "    input_mp3name = station+'_'+formattedtime+'.mp3'\n",
    "    print(input_mp3name)\n",
    "    print(type(input_mp3name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# { { { { { { { {   {  { { { { { {  { { {  { { { { { {_  Section C.   _} } } } } } } } } }  } } }  } } } } } } } } } } } }   }   }    } "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating function which cycles through every radio station, records 12 second .mp3 audio clip, routes audio clip to ACR Cloud's song identifier API, and then routes the song name to the Discogs API, to retrieve the genre information for that song. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Each mp3 recording is named based on the station name and the time the mp3 was recorded. Once the .mp3 has been recorded/outputted, it is shuttled into each station's respective folder's \"mp3_recordings\" folder. \n",
    "\n",
    "### If ACR Cloud was able to ID the song, and the Discogs API was able to retrieve song genre information for that song name, the mp3 filename (which includes the time it was recorded), the song name, artist, album, and genre(s) are appended to that stations .txt file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RadioStationCycler():\n",
    "    \"\"\"Function that utilizes the previously created\n",
    "    RadioMP3Recorder() function, to sample ~12 second\n",
    "    mp3 audio clips from every radio station in the\n",
    "    radio stations list. The mp3 clip on a given iteration\n",
    "    (for a given station) is routed to ACRCloud to return\n",
    "    the track name, artist, and album. If nothing is returned,\n",
    "    the function prints a message (\"No ACRCloud return\"), and\n",
    "    then skips to the next station. If there is a valid ACRcloud\n",
    "    return, the track info is then routed to the Discogs API\n",
    "    to return genre/style information. If there is a valid\n",
    "    return from the Discogs API, the genre info is printed\n",
    "    on the console, but more importantly, it is written in\n",
    "    that given staton's .txt file. Because the mp3 recording\n",
    "    names include the date/time they were recorded, this\n",
    "    info is stored alongside the track info in the .txt.\n",
    "    \n",
    "    NOTE: Right now, the function is set to iterate through\n",
    "    all of the stations in the stations list, and does not\n",
    "    stop until every station stream has been recorded. If\n",
    "    the 'Interrupt Kernel' button is pressed, the last radio\n",
    "    stream the function left off on will continue to play\n",
    "    until the terminal running the notebook is shut down (lol)\n",
    "    \"\"\"\n",
    "    for station in station_dict:\n",
    "        timerightnow = datetime.datetime.now()\n",
    "        formattedtime = timerightnow.strftime(\"%Y_%m_%d_T%H_%M_%S\")\n",
    "    \n",
    "        input_stream = station_dict[station]['streamlink']\n",
    "        input_cuename = station+'_'+formattedtime+'_CUE'\n",
    "        input_mp3name = station+'_'+formattedtime+'.mp3'\n",
    "    \n",
    "        print(f'~~Now playing... {station}~~')\n",
    "        RadioMP3Recorder(input_cuename,\n",
    "                         input_stream,\n",
    "                         input_mp3name)\n",
    "    \n",
    "        pathtocue = os.path.join(workindir,(input_cuename+'.cue'))\n",
    "        pathtomp3 = os.path.join(workindir,input_mp3name)\n",
    "        pathtocuedest = os.path.join(workindir,'FiveStations',station,'cue_files')\n",
    "        pathtomp3dest = os.path.join(workindir,'FiveStations',station,'mp3_recordings')\n",
    "    \n",
    "        shutil.move(pathtocue, pathtocuedest)\n",
    "        shutil.move(pathtomp3, pathtomp3dest)\n",
    "    \n",
    "        itersongpath = pathtomp3dest + '/' + input_mp3name\n",
    "        acrcloud_output = RouteToACRCloud(itersongpath)\n",
    "        songread_dict = json.loads(acrcloud_output)\n",
    "    \n",
    "        if songread_dict['status']['msg'] == 'No result':\n",
    "            print(f'No ACRCloud return from {input_mp3name}, skipping to next station')\n",
    "            pass\n",
    "        elif songread_dict['status']['msg'] == 'May Be Mute':\n",
    "            print(f'No ACRCloud return from {input_mp3name}, skipping to next station')\n",
    "            pass\n",
    "        elif songread_dict['status']['msg'] == 'Decode Audio Error':\n",
    "            print(f'No ACRCloud return from {input_mp3name}, skipping to next station')\n",
    "            pass\n",
    "        else:\n",
    "            songtitle = songread_dict['metadata']['music'][0]['title']\n",
    "            songartist = songread_dict['metadata']['music'][0]['artists'][0]['name']\n",
    "            songalbum = songread_dict['metadata']['music'][0]['album']['name']\n",
    "            print(f'{input_mp3name} is the song {songtitle} by {songartist} from the album {songalbum}')\n",
    "        \n",
    "            percent20song = songtitle+'%20'+songartist+'%20'+songalbum\n",
    "            discogs_input = percent20song.replace(\" \", \"%20\")\n",
    "            discogs_req = ('https://api.discogs.com/database/search?q=' + \n",
    "                           discogs_input + \n",
    "                           '&key=' + \n",
    "                           client_key + \n",
    "                           '&secret=' +\n",
    "                           client_secret)\n",
    "            discogs_req_obj = requests.get(discogs_req)\n",
    "            discogs_songinfo_dict = json.loads(discogs_req_obj.content.decode('utf-8'))\n",
    "        \n",
    "            if discogs_songinfo_dict['results'] == []:\n",
    "                print(f'No Discogs return from {input_mp3name}, skipping to next station')\n",
    "                pass\n",
    "            else:\n",
    "                style_list = discogs_songinfo_dict['results'][0]['style']\n",
    "                genre_list = discogs_songinfo_dict['results'][0]['genre']\n",
    "                styleliststring = ','.join(style_list)\n",
    "                genreliststring = ','.join(genre_list)\n",
    "            \n",
    "                with open(station_dict[station]['txtpath'], \"a+\") as file_object:\n",
    "                    file_object.seek(0)\n",
    "                    data = file_object.read(100)\n",
    "                    if len(data) > 0 :\n",
    "                        file_object.write(\"\\n\")\n",
    "                    file_object.write((input_mp3name+\n",
    "                                       ','+\n",
    "                                       'song='+songtitle+','+\n",
    "                                       'artist='+songartist+','+\n",
    "                                       'album='+songalbum+','+\n",
    "                                       #'genres='+genreliststring+','+\n",
    "                                       'styles='+styleliststring))\n",
    "                print(f'Discogs returned the genre(s): {styleliststring} for this track.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~Now playing... MN_KCMP~~\n",
      "/Users/michaelfelzan/Desktop/RadioTestRun/MN_KCMP_2021_06_25_T02_25_00_CUE.cue\n",
      "/Users/michaelfelzan/Desktop/RadioTestRun/MN_KCMP_2021_06_25_T02_25_00.mp3\n",
      "/Users/michaelfelzan/Desktop/RadioTestRun/FiveStations/MN_KCMP/cue_files\n",
      "~~Now playing... MN_KQRS~~\n",
      "/Users/michaelfelzan/Desktop/RadioTestRun/MN_KQRS_2021_06_25_T02_25_40_CUE.cue\n",
      "/Users/michaelfelzan/Desktop/RadioTestRun/MN_KQRS_2021_06_25_T02_25_40.mp3\n",
      "/Users/michaelfelzan/Desktop/RadioTestRun/FiveStations/MN_KQRS/cue_files\n",
      "~~Now playing... MN_KSTP~~\n",
      "/Users/michaelfelzan/Desktop/RadioTestRun/MN_KSTP_2021_06_25_T02_26_20_CUE.cue\n",
      "/Users/michaelfelzan/Desktop/RadioTestRun/MN_KSTP_2021_06_25_T02_26_20.mp3\n",
      "/Users/michaelfelzan/Desktop/RadioTestRun/FiveStations/MN_KSTP/cue_files\n",
      "~~Now playing... MN_KUOM~~\n",
      "/Users/michaelfelzan/Desktop/RadioTestRun/MN_KUOM_2021_06_25_T02_27_00_CUE.cue\n",
      "/Users/michaelfelzan/Desktop/RadioTestRun/MN_KUOM_2021_06_25_T02_27_00.mp3\n",
      "/Users/michaelfelzan/Desktop/RadioTestRun/FiveStations/MN_KUOM/cue_files\n",
      "~~Now playing... MN_KXXR~~\n",
      "/Users/michaelfelzan/Desktop/RadioTestRun/MN_KXXR_2021_06_25_T02_27_40_CUE.cue\n",
      "/Users/michaelfelzan/Desktop/RadioTestRun/MN_KXXR_2021_06_25_T02_27_40.mp3\n",
      "/Users/michaelfelzan/Desktop/RadioTestRun/FiveStations/MN_KXXR/cue_files\n"
     ]
    }
   ],
   "source": [
    "for station in station_dict:\n",
    "    timerightnow = datetime.datetime.now()\n",
    "    formattedtime = timerightnow.strftime(\"%Y_%m_%d_T%H_%M_%S\")\n",
    "    \n",
    "    input_stream = station_dict[station]['streamlink']\n",
    "    input_cuename = station+'_'+formattedtime+'_CUE'\n",
    "    input_mp3name = station+'_'+formattedtime+'.mp3'\n",
    "    \n",
    "    print(f'~~Now playing... {station}~~')\n",
    "    RadioMP3Recorder(input_cuename,\n",
    "                     input_stream,\n",
    "                     input_mp3name)\n",
    "    \n",
    "    pathtocue = os.path.join(workindir,(input_cuename+'.cue'))\n",
    "    pathtomp3 = os.path.join(workindir,input_mp3name)\n",
    "    pathtocuedest = os.path.join(workindir,'FiveStations',station,'cue_files')\n",
    "    \n",
    "    print(pathtocue)\n",
    "    print(pathtomp3)\n",
    "    print(pathtocuedest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### !! Working directory must be at the base of users working folder in order for RadioStationCycler() function to operate properly !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/michaelfelzan/Desktop/RadioTestRun'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(workindir)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running function // printing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~Now playing... MN_KCMP~~\n",
      "No ACRCloud return from MN_KCMP_2021_06_25_T02_19_20.mp3, skipping to next station\n",
      "~~Now playing... MN_KQRS~~\n",
      "No ACRCloud return from MN_KQRS_2021_06_25_T02_20_00.mp3, skipping to next station\n",
      "~~Now playing... MN_KSTP~~\n",
      "No ACRCloud return from MN_KSTP_2021_06_25_T02_20_40.mp3, skipping to next station\n",
      "~~Now playing... MN_KUOM~~\n",
      "MN_KUOM_2021_06_25_T02_21_20.mp3 is the song The Chalice by Nicole Mitchell from the album Mandorla Awakening II: Emerging Worlds\n",
      "Discogs returned the genre(s): Post Bop,Avant-garde Jazz,Free Improvisation for this track.\n",
      "~~Now playing... MN_KXXR~~\n",
      "No ACRCloud return from MN_KXXR_2021_06_25_T02_22_01.mp3, skipping to next station\n"
     ]
    }
   ],
   "source": [
    "RadioStationCycler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# { { { { { { { {   {  { { { { { {  { { {  { { { { { {_  Section D.   _} } } } } } } } } }  } } }  } } } } } } } } } } } }   }   }    } "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up function which requests a given station's ERP, HAAT, and lat/long using 'get' requests on radio-locator.com :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RadioTowerInfoGetter(callsign):\n",
    "    \"\"\"Function that requests the HTML of\n",
    "    the radio-locator.com webpage for whatever \n",
    "    radio station callsign is inputted into the function.\n",
    "    \n",
    "    The function parses the HTML to return a dictionary\n",
    "    containing the radio stations ERP, lat/long,\n",
    "    HAAT, HAGL, and HASL.\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    callsign : str\n",
    "        Name of station callsign (eg. KEXP)\n",
    "    \"\"\"\n",
    "    radiolocheaders = {\n",
    "        'sec-ch-ua' : '\"Google Chrome\";v=\"89\", \"Chromium\";v=\"89\", \";Not A Brand\";v=\"99\"',\n",
    "        'sec-ch-ua-mobile' : '?0',\n",
    "        'Upgrade-Insecure-Requests' : '1',\n",
    "        'User-Agent' : 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.114 Safari/537.36'\n",
    "    }\n",
    "    locatorURL = f'https://radio-locator.com/cgi-bin/finder?call={callsign}&x=0&y=0&sr=Y&s=C'\n",
    "    \n",
    "    radiolocreq = requests.get(locatorURL,\n",
    "                               headers=radiolocheaders)\n",
    "    stationHTML = radiolocreq.content.decode('utf-8')\n",
    "    stationsoup = BeautifulSoup(stationHTML)\n",
    "    techvalues = stationsoup.find_all(\"td\",\n",
    "                                      class_='tech_value')\n",
    "    \n",
    "    if techvalues == []:\n",
    "        print(f\"No radio tower info could be retrieved for station {callsign}\")\n",
    "        return False\n",
    "    else:\n",
    "        ERP = []\n",
    "        coords = []\n",
    "        heights = []\n",
    "        # Parsing the HTML:\n",
    "        for item in techvalues:\n",
    "            for characters in item:\n",
    "                for sub in characters:\n",
    "                    if '\" N' in sub:\n",
    "                        coords.append(sub)\n",
    "            if 'Watts' in characters:\n",
    "                ERP.append(characters)\n",
    "            elif 'meters' in characters:\n",
    "                heights.append(characters)\n",
    "            else:\n",
    "                pass\n",
    "    \n",
    "        itercoords = coords[0]\n",
    "        iterERP = ERP[0]\n",
    "        iterHAAT = heights[0]\n",
    "        iterHAGL = heights[1]\n",
    "        iterHASL = heights[2]\n",
    "    \n",
    "        towerinfo = {\n",
    "            'ERP' : iterERP,\n",
    "            'Coords' : itercoords,\n",
    "            'HAAT' : iterHAAT,\n",
    "            'Height Above Ground Level' : iterHAGL,\n",
    "            'Height Above Sea Level' : iterHASL\n",
    "        }\n",
    "    \n",
    "        return towerinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example returns from RadioTowerInfoGetter() on a station callsign:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ERP': '4700 Watts',\n",
       " 'Coords': '47Â° 36\\' 57\" N, 122Â° 18\\' 32\" W',\n",
       " 'HAAT': '211 meters (692 feet)',\n",
       " 'Height Above Ground Level': '122 meters (400 feet)',\n",
       " 'Height Above Sea Level': '247 meters (810 feet)'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kexptower = RadioTowerInfoGetter('KEXP')\n",
    "kexptower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ERP': '500 Watts',\n",
       " 'Coords': '37Â° 52\\' 40\" N, 122Â° 14\\' 48\" W',\n",
       " 'HAAT': '238 meters (781 feet)',\n",
       " 'Height Above Ground Level': '18 meters (59 feet)',\n",
       " 'Height Above Sea Level': '350 meters (1148 feet)'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kalxtower = RadioTowerInfoGetter('KALX')\n",
    "kalxtower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up function which writes the dictionary return from RadioTowerInfoGetter() function to a .txt file in a given station's folder :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StationInfoTxtWriter(stationfoldername):\n",
    "    \"\"\"Function that writes the dictionary return\n",
    "    from RadioTowerInfoGetter() for a station \n",
    "    to a .txt file in that station's corresponding\n",
    "    folder (only if the RadioTowerInfoGetter()\n",
    "    successfully returns tower info).\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    stationfoldername : str\n",
    "        Name of a radio stations folder (eg. CA_KALX)\n",
    "    \"\"\"\n",
    "    call_sign = stationfoldername.split(\"_\")[1]\n",
    "    towerinfodict = RadioTowerInfoGetter(call_sign)\n",
    "    if towerinfodict == False:\n",
    "        print(\"yes, it failed\")\n",
    "        pass\n",
    "    else:\n",
    "        infofilename = os.path.join(workindir,\n",
    "                                    \"STATIONS\",\n",
    "                                    stationfoldername,\n",
    "                                    f\"{call_sign}_towerinfo.txt\")\n",
    "        textyfile = open(infofilename,\n",
    "                    \"w+\")\n",
    "        textyfile.write(\"{\\n\")\n",
    "        for k in towerinfodict.keys():\n",
    "            textyfile.write(\"'{}':'{}'\\n\".format(k, towerinfodict[k]))\n",
    "        textyfile.write(\"}\")\n",
    "        textyfile.close()\n",
    "        print(f\"Sucessfully wrote {call_sign}_towerinfo.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the StationInfoTxtWriter() function on all stations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucessfully wrote KALX_towerinfo.txt\n",
      "No radio tower info could be retrieved for station KLDBLP\n",
      "yes, it failed\n",
      "Sucessfully wrote KXSC_towerinfo.txt\n",
      "Sucessfully wrote WREK_towerinfo.txt\n",
      "Sucessfully wrote WUOG_towerinfo.txt\n",
      "Sucessfully wrote WEIU_towerinfo.txt\n",
      "No radio tower info could be retrieved for station WCRD\n",
      "yes, it failed\n",
      "Sucessfully wrote WGRE_towerinfo.txt\n",
      "Sucessfully wrote WERS_towerinfo.txt\n",
      "Sucessfully wrote WMBR_towerinfo.txt\n",
      "Sucessfully wrote WZBC_towerinfo.txt\n",
      "Sucessfully wrote WMUC_towerinfo.txt\n",
      "No radio tower info could be retrieved for station WCBN\n",
      "yes, it failed\n",
      "No radio tower info could be retrieved for station KUOM\n",
      "yes, it failed\n",
      "Sucessfully wrote WKNC_towerinfo.txt\n",
      "Sucessfully wrote WSOU_towerinfo.txt\n",
      "Sucessfully wrote WICB_towerinfo.txt\n",
      "Sucessfully wrote WRHU_towerinfo.txt\n",
      "Sucessfully wrote WSBU_towerinfo.txt\n",
      "Sucessfully wrote WVKR_towerinfo.txt\n",
      "Sucessfully wrote WCSB_towerinfo.txt\n",
      "Sucessfully wrote KPSU_towerinfo.txt\n",
      "Sucessfully wrote KWVA_towerinfo.txt\n",
      "Sucessfully wrote WESS_towerinfo.txt\n",
      "Sucessfully wrote WKDU_towerinfo.txt\n",
      "Sucessfully wrote WWNW_towerinfo.txt\n",
      "Sucessfully wrote WUTK_towerinfo.txt\n",
      "Sucessfully wrote KTSW_towerinfo.txt\n",
      "Sucessfully wrote KEXP_towerinfo.txt\n",
      "Sucessfully wrote KUPS_towerinfo.txt\n",
      "Sucessfully wrote KXSU_towerinfo.txt\n",
      "Sucessfully wrote WSUM_towerinfo.txt\n"
     ]
    }
   ],
   "source": [
    "for station in sortedstations:\n",
    "    StationInfoTxtWriter(station)\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# { { { { { { { {   {  { { { { { {  { { {  { { { { { {_  Section E.   _} } } } } } } } } }  } } }  } } } } } } } } } } } }   }   }    } "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The following cell opens a javascript file, using the os.popen() function. The file is called 'FezCC.js' (my nickname is Fez; FCC pun) and it was ripped from the FCC's 'FM and TV curve propagation calculator' webpage ( https://www.fcc.gov/sites/default/files/fm-and-tv-propagation-curves.html ). The script was saved into a new file and re-parameterized so that the user can enter in first the ERP (kW), the HAAT (meters), **then '250' and '-' are just givens,** the signal strength (dBu) at which you'd like to predict the distance you'd be from that station, and then \"0\" is just another given.\n",
    "\n",
    "## The output of this script is the distance you'd be from a given radio station in order to be at 60dBu ('local' resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'37.699469101964276'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream = os.popen('node fezCC.js 4.7 211 \"250\" \"-\" 60 \"0\"')\n",
    "output = (stream.read()).split('\\n')[0]\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up a function that converts degrees minutes seconds lat/long into decimal degrees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dms_to_dd(d, m, s):\n",
    "    \"\"\"Function that converts degrees minutes seconds\n",
    "    into decimal degrees.\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    d : str (tho doesnt matter--converted to float in function)\n",
    "        degree\n",
    "    m : str (tho doesnt matter--converted to float in function)\n",
    "        minutes\n",
    "    s : str (tho doesnt matter--converted to float in function)\n",
    "        seconds\n",
    "    \"\"\"\n",
    "    dd = d + float(m)/60 + float(s)/3600\n",
    "    return round(dd, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up a function that isolates the degree, minute, and second components of the DMS return from the StationInfoTxtWriter(), so that they may be separately inputted into the dms_to_dd() function parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DMS_Isolator(dms_string):\n",
    "    \"\"\"function that isolates the degree, minute, and second \n",
    "    components  of the DMS return from the StationInfoTxtWriter(),\n",
    "    so that they may be separately inputted into the\n",
    "    dms_to_dd() function parameters\n",
    "    \"\"\"\n",
    "    degree = dms_string.split(\"Â°\")[0]\n",
    "    minutefirstsplit = dms_string.split(\"'\")[0]\n",
    "    minute = minutefirstsplit.split(\"Â° \")[1]\n",
    "    secondfirstsplit = dms_string.split('\"')[0]\n",
    "    second = secondfirstsplit.split(\"' \")[1]\n",
    "    \n",
    "    return [degree,minute,second]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating over every station in the radio stations list, extracting the ERP, lat/long, and HAAT from that stations TowerInfo.txt file (if one exists), converts the lat/long into decimal degrees, and also calculates the broadcast distance (at 60dBu) for each station, given their HAAT and ERP. \n",
    "\n",
    "## All of this information is then neatly written to a CSV file in that station's folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tower info .txt does not exist for CA_KLDBLP\n",
      "tower info .txt does not exist for IN_WCRD\n",
      "tower info .txt does not exist for MI_WCBN\n",
      "tower info .txt does not exist for MN_KUOM\n",
      "\n",
      "     *~*~~~~~**~~~~~~~~~~~~~~**~*~*\n",
      "Successfully wrote all other station tower info CSVs.\n",
      "CSVs outputted to respective station folders.\n",
      "   *~*~~~~~**~~~~~~~~~~~~~~**~*~*\n"
     ]
    }
   ],
   "source": [
    "for station in sortedstations:\n",
    "    pathtostationfold = os.path.join(workindir,\n",
    "                                    \"STATIONS\",\n",
    "                                    station)\n",
    "    itercallsign = station.split(\"_\")[1]\n",
    "    stateabv = station.split(\"_\")[0]\n",
    "    pathtotowertxt = os.path.join(pathtostationfold,\n",
    "                            f'{itercallsign}_towerinfo.txt')\n",
    "    pathtotxt = os.path.join(pathtostationfold,\n",
    "                             f'{station}.txt')\n",
    "    newinfocsv = os.path.join(pathtostationfold,\n",
    "                             f'{station}_INFO.csv')\n",
    "    stationfolditems = os.listdir(pathtostationfold)\n",
    "    fullpathitems = []\n",
    "    for item in stationfolditems:\n",
    "        fullpathitems.append(os.path.join(pathtostationfold,\n",
    "                                         item))\n",
    "    if pathtotowertxt in fullpathitems:\n",
    "        with open(pathtotowertxt) as foo:\n",
    "            txtz = foo.readlines()\n",
    "            for item in txtz:\n",
    "                \n",
    "                if 'ERP' in item:\n",
    "                    wattsfirstsplit = item.split(\":'\")[1]\n",
    "                    watts = wattsfirstsplit.split(\" Watts\")[0]\n",
    "                    kilowatts = (float(watts.replace(',','')))/1000\n",
    "                    \n",
    "                elif 'Coords' in item:\n",
    "                    coordsfirstsplit = item.split(\":'\")[1]\n",
    "                    lat_dms = coordsfirstsplit.split(\",\")[0]\n",
    "                    long_dms = (coordsfirstsplit.split(\", \")[1])[:-2]\n",
    "                    \n",
    "                    lat_dms_list = DMS_Isolator(lat_dms)\n",
    "                    long_dms_list = DMS_Isolator(long_dms)\n",
    "                    \n",
    "                    lat_dd = dms_to_dd(float(lat_dms_list[0]),\n",
    "                                       float(lat_dms_list[1]),\n",
    "                                       float(lat_dms_list[2]))\n",
    "                    long_dd = dms_to_dd(float(long_dms_list[0]),\n",
    "                                        float(long_dms_list[1]),\n",
    "                                        float(long_dms_list[2]))\n",
    "                    negative_longdd = long_dd*-1\n",
    "                    \n",
    "                elif 'HAAT' in item:\n",
    "                    HAATfirstsplit = item.split(\":'\")[1]\n",
    "                    HAAT_clean = HAATfirstsplit.split(\" meters\")[0]\n",
    "                    HAAT_float = float(HAAT_clean)\n",
    "        \n",
    "                    stream_param = f'node fezCC.js {kilowatts} {HAAT_float} \"250\" \"-\" 60 \"0\"'\n",
    "                    stream = os.popen(stream_param)\n",
    "                    BUFF60DIST = (stream.read()).split('\\n')[0]\n",
    "                \n",
    "        with open(newinfocsv,'w',newline='') as csvfile:\n",
    "            fieldnames = ['StateABV',\n",
    "                          'CALLSIGN',\n",
    "                          'LAT',\n",
    "                          'LONG',\n",
    "                          'ERP',\n",
    "                          'HAAT',\n",
    "                          '60dBu_DIST']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            writer.writerow({\n",
    "                'StateABV': stateabv,\n",
    "                'CALLSIGN': itercallsign,\n",
    "                'LAT' : lat_dd,\n",
    "                'LONG' : negative_longdd,\n",
    "                'ERP' : kilowatts,\n",
    "                'HAAT' : HAAT_clean,\n",
    "                '60dBu_DIST' : BUFF60DIST\n",
    "            })\n",
    "                \n",
    "    else:\n",
    "        print(f'tower info .txt does not exist for {station}')\n",
    "        pass\n",
    "\n",
    "print(\"\\n     *~*~~~~~**~~~~~~~~~~~~~~**~*~*\\n\"+\n",
    "      \"Successfully wrote all other station tower info CSVs.\"+\n",
    "      \"\\nCSVs outputted to respective station folders.\"\n",
    "      \"\\n   *~*~~~~~**~~~~~~~~~~~~~~**~*~*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# { { { { { { { {   {  { { {  {  { { {  { { { { { {_  Section F. (pt1)   _} } } } } } } } } }  } } }  } } } } } } } } } } } }   }       } "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (Creating new folder, \"StationInfoTables\" :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationinfopath = os.path.join(workindir, \"StationInfoTables\")\n",
    "os.mkdir(stationinfopath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COPYING each stations TowerInfo CSV to the StationInfoTables folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COPYING FILES TO StationInfoTables FOLDER\n",
    "\n",
    "for station in sortedstations:\n",
    "    pathtostationfold = os.path.join(workindir,\n",
    "                                    \"STATIONS\",\n",
    "                                    station)\n",
    "    newinfocsv = os.path.join(pathtostationfold,\n",
    "                             f'{station}_INFO.csv')\n",
    "    stationfolditems = os.listdir(pathtostationfold)\n",
    "    fullpathitems = []\n",
    "    for item in stationfolditems:\n",
    "        fullpathitems.append(os.path.join(pathtostationfold,\n",
    "                                         item))\n",
    "    if newinfocsv in fullpathitems:\n",
    "        copyfile(newinfocsv,\n",
    "                 os.path.join(workindir,\n",
    "                              \"StationInfoTables\",\n",
    "                              f'{station}_INFO.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating over all of the station folders, and merging each station's TowerInfo CSV contents into one 'master' TowerInfo CSV. This CSV includes every radio station's ERP, HAAT, lat/long, 60 dBu distance, callsign and state abreviation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     *~*~~~~~**~~~~~~~~~~~~~~**~*~*\n",
      "All station tower info CSVs (that exist) have\n",
      "      been successfully merged together\n",
      "  *~*~~~~~**~~~~~~~~~~~~~~**~*~*\n"
     ]
    }
   ],
   "source": [
    "for station in sortedstations:\n",
    "    pathtofold = os.path.join(workindir,\n",
    "                              \"StationInfoTables\")\n",
    "INFOconcatCSV = os.path.join(pathtofold,\n",
    "                            \"STATIONINFOconcat.csv\") \n",
    "allFiles = glob.glob(pathtofold + \"/*.csv\")\n",
    "allFiles.sort()\n",
    "with open(INFOconcatCSV, 'wb') as outfile:\n",
    "        for i, fname in enumerate(allFiles):\n",
    "            with open(fname, 'rb') as infile:\n",
    "                if i != 0:\n",
    "                    infile.readline()  # Throw away header on all but first file\n",
    "            # Block copy rest of file from input to output without parsing\n",
    "                shutil.copyfileobj(infile, outfile)\n",
    "\n",
    "print(\"     *~*~~~~~**~~~~~~~~~~~~~~**~*~*\\n\"\n",
    "      \"All station tower info CSVs (that exist) have\"+\n",
    "      \"\\n      been successfully merged together\"\n",
    "      \"\\n  *~*~~~~~**~~~~~~~~~~~~~~**~*~*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrating what the 'master' Station Info CSV looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StateABV</th>\n",
       "      <th>CALLSIGN</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LONG</th>\n",
       "      <th>ERP</th>\n",
       "      <th>HAAT</th>\n",
       "      <th>60dBu_DIST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>CA</td>\n",
       "      <td>KALX</td>\n",
       "      <td>37.877778</td>\n",
       "      <td>-122.246667</td>\n",
       "      <td>0.500</td>\n",
       "      <td>238.00</td>\n",
       "      <td>23.813202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "      <td>KXSC</td>\n",
       "      <td>37.322778</td>\n",
       "      <td>-121.755278</td>\n",
       "      <td>6.000</td>\n",
       "      <td>-47.00</td>\n",
       "      <td>15.752658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>GA</td>\n",
       "      <td>WREK</td>\n",
       "      <td>33.778056</td>\n",
       "      <td>-84.406111</td>\n",
       "      <td>100.000</td>\n",
       "      <td>102.00</td>\n",
       "      <td>51.246887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>GA</td>\n",
       "      <td>WUOG</td>\n",
       "      <td>33.949722</td>\n",
       "      <td>-83.382778</td>\n",
       "      <td>26.000</td>\n",
       "      <td>55.00</td>\n",
       "      <td>30.117545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>IL</td>\n",
       "      <td>WEIU</td>\n",
       "      <td>39.478611</td>\n",
       "      <td>-88.172500</td>\n",
       "      <td>4.000</td>\n",
       "      <td>51.00</td>\n",
       "      <td>18.795361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>IN</td>\n",
       "      <td>WGRE</td>\n",
       "      <td>39.638611</td>\n",
       "      <td>-86.863611</td>\n",
       "      <td>0.800</td>\n",
       "      <td>54.00</td>\n",
       "      <td>12.783182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>MA</td>\n",
       "      <td>WERS</td>\n",
       "      <td>42.352222</td>\n",
       "      <td>-71.056389</td>\n",
       "      <td>4.000</td>\n",
       "      <td>186.00</td>\n",
       "      <td>34.379047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>MA</td>\n",
       "      <td>WMBR</td>\n",
       "      <td>42.361667</td>\n",
       "      <td>-71.083611</td>\n",
       "      <td>0.720</td>\n",
       "      <td>90.00</td>\n",
       "      <td>15.980103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>MA</td>\n",
       "      <td>WZBC</td>\n",
       "      <td>42.334722</td>\n",
       "      <td>-71.174722</td>\n",
       "      <td>1.000</td>\n",
       "      <td>67.00</td>\n",
       "      <td>14.891976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>MD</td>\n",
       "      <td>WMUC</td>\n",
       "      <td>38.983056</td>\n",
       "      <td>-76.943333</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.151873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>NC</td>\n",
       "      <td>WKNC</td>\n",
       "      <td>35.787778</td>\n",
       "      <td>-78.670278</td>\n",
       "      <td>25.000</td>\n",
       "      <td>80.00</td>\n",
       "      <td>35.396449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>NJ</td>\n",
       "      <td>WSOU</td>\n",
       "      <td>40.741111</td>\n",
       "      <td>-74.244722</td>\n",
       "      <td>2.400</td>\n",
       "      <td>95.00</td>\n",
       "      <td>22.447808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>NY</td>\n",
       "      <td>WICB</td>\n",
       "      <td>42.418611</td>\n",
       "      <td>-76.493889</td>\n",
       "      <td>4.100</td>\n",
       "      <td>41.30</td>\n",
       "      <td>16.720630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>NY</td>\n",
       "      <td>WRHU</td>\n",
       "      <td>40.717500</td>\n",
       "      <td>-73.602778</td>\n",
       "      <td>0.470</td>\n",
       "      <td>55.00</td>\n",
       "      <td>11.378105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>NY</td>\n",
       "      <td>WSBU</td>\n",
       "      <td>42.079167</td>\n",
       "      <td>-78.485000</td>\n",
       "      <td>0.165</td>\n",
       "      <td>-78.00</td>\n",
       "      <td>6.388703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>NY</td>\n",
       "      <td>WVKR</td>\n",
       "      <td>41.640278</td>\n",
       "      <td>-74.020833</td>\n",
       "      <td>3.700</td>\n",
       "      <td>250.00</td>\n",
       "      <td>38.462304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>OH</td>\n",
       "      <td>WCSB</td>\n",
       "      <td>41.503333</td>\n",
       "      <td>-81.674722</td>\n",
       "      <td>0.630</td>\n",
       "      <td>62.00</td>\n",
       "      <td>12.860827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>OR</td>\n",
       "      <td>KPSU</td>\n",
       "      <td>36.594722</td>\n",
       "      <td>-101.636667</td>\n",
       "      <td>0.380</td>\n",
       "      <td>37.00</td>\n",
       "      <td>8.763770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>OR</td>\n",
       "      <td>KWVA</td>\n",
       "      <td>44.081667</td>\n",
       "      <td>-123.110556</td>\n",
       "      <td>1.000</td>\n",
       "      <td>54.00</td>\n",
       "      <td>13.474437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>PA</td>\n",
       "      <td>WESS</td>\n",
       "      <td>40.998611</td>\n",
       "      <td>-75.172222</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-42.00</td>\n",
       "      <td>10.160668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>PA</td>\n",
       "      <td>WKDU</td>\n",
       "      <td>39.960000</td>\n",
       "      <td>-75.190556</td>\n",
       "      <td>0.800</td>\n",
       "      <td>47.00</td>\n",
       "      <td>11.924478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>PA</td>\n",
       "      <td>WWNW</td>\n",
       "      <td>41.111389</td>\n",
       "      <td>-80.338889</td>\n",
       "      <td>0.250</td>\n",
       "      <td>33.00</td>\n",
       "      <td>7.393445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>TN</td>\n",
       "      <td>WUTK</td>\n",
       "      <td>35.952500</td>\n",
       "      <td>-83.926111</td>\n",
       "      <td>0.800</td>\n",
       "      <td>21.00</td>\n",
       "      <td>9.610350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>TX</td>\n",
       "      <td>KTSW</td>\n",
       "      <td>29.655833</td>\n",
       "      <td>-98.132500</td>\n",
       "      <td>16.000</td>\n",
       "      <td>94.00</td>\n",
       "      <td>34.527956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>WA</td>\n",
       "      <td>KEXP</td>\n",
       "      <td>47.615833</td>\n",
       "      <td>-122.308889</td>\n",
       "      <td>4.700</td>\n",
       "      <td>211.00</td>\n",
       "      <td>37.699469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>WA</td>\n",
       "      <td>KUPS</td>\n",
       "      <td>47.263056</td>\n",
       "      <td>-122.478056</td>\n",
       "      <td>0.100</td>\n",
       "      <td>70.00</td>\n",
       "      <td>8.638738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>WA</td>\n",
       "      <td>KXSU</td>\n",
       "      <td>47.606667</td>\n",
       "      <td>-122.319722</td>\n",
       "      <td>0.007</td>\n",
       "      <td>106.02</td>\n",
       "      <td>5.512431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>WI</td>\n",
       "      <td>WSUM</td>\n",
       "      <td>42.904444</td>\n",
       "      <td>-89.555833</td>\n",
       "      <td>5.500</td>\n",
       "      <td>103.00</td>\n",
       "      <td>28.132982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   StateABV CALLSIGN        LAT        LONG      ERP    HAAT  60dBu_DIST\n",
       "0        CA     KALX  37.877778 -122.246667    0.500  238.00   23.813202\n",
       "1        CA     KXSC  37.322778 -121.755278    6.000  -47.00   15.752658\n",
       "2        GA     WREK  33.778056  -84.406111  100.000  102.00   51.246887\n",
       "3        GA     WUOG  33.949722  -83.382778   26.000   55.00   30.117545\n",
       "4        IL     WEIU  39.478611  -88.172500    4.000   51.00   18.795361\n",
       "5        IN     WGRE  39.638611  -86.863611    0.800   54.00   12.783182\n",
       "6        MA     WERS  42.352222  -71.056389    4.000  186.00   34.379047\n",
       "7        MA     WMBR  42.361667  -71.083611    0.720   90.00   15.980103\n",
       "8        MA     WZBC  42.334722  -71.174722    1.000   67.00   14.891976\n",
       "9        MD     WMUC  38.983056  -76.943333    0.010    1.00    3.151873\n",
       "10       NC     WKNC  35.787778  -78.670278   25.000   80.00   35.396449\n",
       "11       NJ     WSOU  40.741111  -74.244722    2.400   95.00   22.447808\n",
       "12       NY     WICB  42.418611  -76.493889    4.100   41.30   16.720630\n",
       "13       NY     WRHU  40.717500  -73.602778    0.470   55.00   11.378105\n",
       "14       NY     WSBU  42.079167  -78.485000    0.165  -78.00    6.388703\n",
       "15       NY     WVKR  41.640278  -74.020833    3.700  250.00   38.462304\n",
       "16       OH     WCSB  41.503333  -81.674722    0.630   62.00   12.860827\n",
       "17       OR     KPSU  36.594722 -101.636667    0.380   37.00    8.763770\n",
       "18       OR     KWVA  44.081667 -123.110556    1.000   54.00   13.474437\n",
       "19       PA     WESS  40.998611  -75.172222    1.000  -42.00   10.160668\n",
       "20       PA     WKDU  39.960000  -75.190556    0.800   47.00   11.924478\n",
       "21       PA     WWNW  41.111389  -80.338889    0.250   33.00    7.393445\n",
       "22       TN     WUTK  35.952500  -83.926111    0.800   21.00    9.610350\n",
       "23       TX     KTSW  29.655833  -98.132500   16.000   94.00   34.527956\n",
       "24       WA     KEXP  47.615833 -122.308889    4.700  211.00   37.699469\n",
       "25       WA     KUPS  47.263056 -122.478056    0.100   70.00    8.638738\n",
       "26       WA     KXSU  47.606667 -122.319722    0.007  106.02    5.512431\n",
       "27       WI     WSUM  42.904444  -89.555833    5.500  103.00   28.132982"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stninfoconcat = os.path.join(workindir,\n",
    "                             \"StationInfoTables\",\n",
    "                             \"STATIONINFOconcat.csv\")\n",
    "\n",
    "\n",
    "stninfo_df = pd.read_csv(stninfoconcat)\n",
    "stninfo_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE: Section F Pt. 2 is in a different notebook, because Arcpy was needed (and I didn't want to configure all of the packages on this notebook with Esri's python environment.\n",
    "\n",
    "### This notebook is titled _____ in the github repo.\n",
    "\n",
    "### F pt 2 runs through the process of importing this table into ArcGIS, and creating a feature class out of the table using XYTTabletoPoint. The point feature class that is created from the above CSV contains all of the fields of that CSV as attributes. Because of this, a different buffer is able to be created for each individual point representing the broadcast reach. Also, because the station callsigns are included in the attribute table, the radio song play logs are able to be joined on this field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# { { { { { { { {   {  { { { { { {  { { {  { { { { { {_  Section G.   _} } } } } } } } } }  } } }  } } } } } } } } } } } }   }   }    } "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Re-demonstrating how to access a given station's own '.txt' file using the station_dict :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/michaelfelzan/Desktop/5572 RADIO GARDEN/RadioTestRun/STATIONS/WI_WSUM/WI_WSUM.txt'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_dict['WI_WSUM']['txtpath']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Demonstrating how to open one of these files, and access only the lines of the .txt file that are not a part of the 'header' :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WI_WSUM_2021_04_15_T00_33_04.mp3,song=Dunkirk,artist=Silverbacks,album=Pink Tide,styles=Indie Rock,Post-Punk\n",
      "\n",
      "WI_WSUM_2021_04_15_T01_11_40.mp3,song=Press Play,artist=Alex Ebert,album=I vs I,styles=\n",
      "\n",
      "WI_WSUM_2021_04_15_T01_33_41.mp3,song=Keep On Loving Me,artist=Onra,album=Keep On Loving Me (Edit),styles=House,Disco,Beatdown\n",
      "\n",
      "WI_WSUM_2021_04_15_T01_54_20.mp3,song=In Rural Virginia; Watching Glowing Lights Crawl from the Dark Corners of the Room,artist=Ricky Eat Acid,album=Three Love Songs,styles=Ambient,Experimental,House\n",
      "\n",
      "WI_WSUM_2021_04_15_T11_07_31.mp3,song=Porcelain,artist=Moby,album=Porcelain,styles=House,Downtempo\n",
      "\n",
      "WI_WSUM_2021_04_15_T14_46_39.mp3,song=When I Kissed The Teacher,artist=ABBA,album=More ABBA Gold,styles=Europop,Disco\n"
     ]
    }
   ],
   "source": [
    "with open(station_dict['WI_WSUM']['txtpath'], \"r\") as file_object:\n",
    "    Lines = file_object.readlines()\n",
    "    cleanLines = []\n",
    "    txtheader = [0,1,2]\n",
    "    for i in range(len(Lines)):\n",
    "        if i not in txtheader:\n",
    "            cleanLines.append(Lines[i])\n",
    "    \n",
    "for line in cleanLines:\n",
    "    print(line)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breaking down how each element of the .txt file track play logs will be parsed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ambient', 'Experimental', 'House']"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to parse genre:\n",
    "\n",
    "genresplit1 = cleanLines[3].split(\"styles=\")[1]\n",
    "genrecomma = genresplit1.split('\\n')[0]\n",
    "genrelist = genrecomma.split(',')\n",
    "genrelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Three Love Songs'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to parse album:\n",
    "\n",
    "stuffbeforegenre = cleanLines[3].split(\",styles\")[0]\n",
    "albumparse = stuffbeforegenre.split('album=')[1]\n",
    "albumparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ricky Eat Acid'"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to parse artist:\n",
    "\n",
    "stuffbeforealbum = stuffbeforegenre.split(\",album=\")[0]\n",
    "artistparse = stuffbeforealbum.split(\",artist=\")[1]\n",
    "artistparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In Rural Virginia; Watching Glowing Lights Crawl from the Dark Corners of the Room'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to parse song\n",
    "\n",
    "stuffbeforeartist = stuffbeforealbum.split(\",artist=\")[0]\n",
    "songparse = stuffbeforeartist.split(\",song=\")[1]\n",
    "songparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WI_WSUM_2021_04_15_T01_54_20.mp3'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to parse mp3 filename components:\n",
    "\n",
    "mp3filename = stuffbeforeartist.split(\",song=\")[0]\n",
    "mp3filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WI', 'WSUM', '2021', '04', '15', 'T01', '54', '20']"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp3_components = mp3filename.split('_')\n",
    "mp3_components[-1] = mp3_components[-1].split('.mp3')[0]\n",
    "mp3_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asigning vars to each mp3_component list item:\n",
    "\n",
    "stateabrev = mp3_components[0]\n",
    "radiocallsgn = mp3_components[1]\n",
    "captureyear = mp3_components[2]\n",
    "capturemonth = mp3_components[3]\n",
    "captureday = mp3_components[4]\n",
    "capturehour = mp3_components[5].split('T')[1]\n",
    "captureminute = mp3_components[6]\n",
    "capturesecond = mp3_components[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genrelist = genrecomma.split(',')\n",
    "            genrecommastr = \",\".join(genrelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATE : WI\n",
      "CALLSIGN : WSUM\n",
      "SONG NAME : In Rural Virginia; Watching Glowing Lights Crawl from the Dark Corners of the Room\n",
      "ARTIST NAME : Ricky Eat Acid\n",
      "ALBUM NAME : Three Love Songs\n",
      "STYLES : Ambient,Experimental,House\n",
      "YEAR OF CAPTURE : 2021\n",
      "MONTH OF CAPTURE: 04\n",
      "DAY OF CAPTURE : 15\n",
      "HOUR OF CAPTURE : 01\n",
      "MINUTE OF CAPTURE : 54\n",
      "SECOND OF CAPTURE : 20\n"
     ]
    }
   ],
   "source": [
    "# Demonstrating / printing all of the variables parsed from the above functions:\n",
    "\n",
    "print('STATE :',stateabrev)\n",
    "print('CALLSIGN :',radiocallsgn)\n",
    "print('SONG NAME :',songparse)\n",
    "print('ARTIST NAME :',artistparse)\n",
    "print('ALBUM NAME :',albumparse)\n",
    "print('STYLES :',genrecomma)\n",
    "print('YEAR OF CAPTURE :',captureyear)\n",
    "print('MONTH OF CAPTURE:',capturemonth)\n",
    "print('DAY OF CAPTURE :',captureday)\n",
    "print('HOUR OF CAPTURE :',capturehour)\n",
    "print('MINUTE OF CAPTURE :',captureminute)\n",
    "print('SECOND OF CAPTURE :',capturesecond)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating over every station .txt and creating a CSV containing the song play log of that station. The fields of the CSV are those in the above cell. The CSV is named based on the day the cell is run, so if the function is run two times in one day, it will overwrite the previous output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*~*~~~~~**~~~~~~~~~~~~~~**~*~*\n",
      "Sucessfully printed track play log CSVs for all stations.\n",
      "All CSVs outputted to respective station folders.\n",
      "This batch of CSVs have the extension: 2021_05_06.csv\n",
      "*~*~~~~~**~~~~~~~~~~~~~~**~*~*\n"
     ]
    }
   ],
   "source": [
    "TrackPlayLogDict = {}\n",
    "\n",
    "for station in sortedstations:\n",
    "    \n",
    "    timerightnow = datetime.datetime.now()\n",
    "    YMD_rightnow = timerightnow.strftime(\"%Y_%m_%d\")\n",
    "    \n",
    "    TrackPlayLogDict[station] = {}\n",
    "    tracklogCSVpath = os.path.join(station_dict[station]['folderpath'],\n",
    "                                   station +\n",
    "                                   \"_TrackLog_\" +\n",
    "                                   YMD_rightnow +\n",
    "                                   \".csv\")\n",
    "    \n",
    "    \n",
    "    with open(station_dict[station]['txtpath'], \"r\") as file_object:\n",
    "        Lines = file_object.readlines()\n",
    "        cleanLines = []\n",
    "        txtheader = [0,1,2]\n",
    "        for i in range(len(Lines)):\n",
    "            if i not in txtheader:\n",
    "                cleanLines.append(Lines[i])\n",
    "        \n",
    "    with open(tracklogCSVpath,'w',newline='') as csvfile:\n",
    "        fieldnames = ['stateabrev',\n",
    "                      'radiocallsgn',\n",
    "                      'trackname',\n",
    "                      'trackartist',\n",
    "                      'trackalbum',\n",
    "                      'trackstyles',\n",
    "                      'trackmp3filename',\n",
    "                      'captureyear',\n",
    "                      'capturemonth',\n",
    "                      'captureday',\n",
    "                      'capturehour',\n",
    "                      'captureminute',\n",
    "                      'capturesecond']\n",
    "        \n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        \n",
    "        for trackplaystring in cleanLines:\n",
    "            \n",
    "            genresplit1 = trackplaystring.split(\"styles=\")[1]\n",
    "            genrecomma = genresplit1.split('\\n')[0]\n",
    "            genrelist = genrecomma.split(',')\n",
    "            genrecommastr = \",\".join(genrelist)\n",
    "            \n",
    "            stuffbeforegenre = trackplaystring.split(\",styles\")[0]\n",
    "            albumparse = stuffbeforegenre.split('album=')[1]\n",
    "            \n",
    "            stuffbeforealbum = stuffbeforegenre.split(\",album=\")[0]\n",
    "            artistparse = stuffbeforealbum.split(\",artist=\")[1]\n",
    "\n",
    "            stuffbeforeartist = stuffbeforealbum.split(\",artist=\")[0]\n",
    "            songparse = stuffbeforeartist.split(\",song=\")[1]\n",
    "            \n",
    "            mp3filename = stuffbeforeartist.split(\",song=\")[0]\n",
    "            \n",
    "            mp3_components = mp3filename.split('_')\n",
    "            mp3_components[-1] = mp3_components[-1].split('.mp3')[0]\n",
    "            \n",
    "            stateabrev = mp3_components[0]\n",
    "            radiocallsgn = mp3_components[1]\n",
    "            captureyear = mp3_components[2]\n",
    "            capturemonth = mp3_components[3]\n",
    "            captureday = mp3_components[4]\n",
    "            capturehour = mp3_components[5].split('T')[1]\n",
    "            captureminute = mp3_components[6]\n",
    "            capturesecond = mp3_components[7]\n",
    "            \n",
    "            writer.writerow({\n",
    "                'stateabrev' : stateabrev,\n",
    "                'radiocallsgn' : radiocallsgn,\n",
    "                'trackname' : songparse,\n",
    "                'trackartist' : artistparse,\n",
    "                'trackalbum' : albumparse,\n",
    "                'trackstyles' : genrecommastr,\n",
    "                'trackmp3filename' : mp3filename,\n",
    "                'captureyear' : captureyear,\n",
    "                'capturemonth' : capturemonth,\n",
    "                'captureday' : captureday,\n",
    "                'capturehour' : capturehour,\n",
    "                'captureminute' : captureminute,\n",
    "                'capturesecond' : capturesecond\n",
    "            })\n",
    "print(\"*~*~~~~~**~~~~~~~~~~~~~~**~*~*\\n\"\n",
    "      \"Sucessfully printed track play log CSVs for all stations.\"+\n",
    "      \"\\nAll CSVs outputted to respective station folders.\"+\n",
    "      f\"\\nThis batch of CSVs have the extension: {YMD_rightnow}.csv\"+\n",
    "      \"\\n*~*~~~~~**~~~~~~~~~~~~~~**~*~*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrating what a TrackLog CSV would look like for a given staton :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/michaelfelzan/Desktop/5572 RADIO GARDEN/RadioTestRun/STATIONS/CA_KALX/CA_KALX_TrackLog_2021_05_06.csv'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "May6_KALX_log = os.path.join(station_dict['CA_KALX']['folderpath'],\n",
    "                             \"CA_KALX_TrackLog_2021_05_06.csv\")\n",
    "May6_KALX_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stateabrev</th>\n",
       "      <th>radiocallsgn</th>\n",
       "      <th>trackname</th>\n",
       "      <th>trackartist</th>\n",
       "      <th>trackalbum</th>\n",
       "      <th>trackstyles</th>\n",
       "      <th>trackmp3filename</th>\n",
       "      <th>captureyear</th>\n",
       "      <th>captureday</th>\n",
       "      <th>capturehour</th>\n",
       "      <th>captureminute</th>\n",
       "      <th>capturesecond</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>CA</td>\n",
       "      <td>KALX</td>\n",
       "      <td>Finally (12\" Choice Mix)</td>\n",
       "      <td>CeCe Peniston</td>\n",
       "      <td>Grand House Classics 1</td>\n",
       "      <td>House,Deep House,Garage House</td>\n",
       "      <td>CA_KALX_2021_04_15_T00_17_08.mp3</td>\n",
       "      <td>2021</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "      <td>KALX</td>\n",
       "      <td>Le coeur grenadine</td>\n",
       "      <td>Laurent Voulzy</td>\n",
       "      <td>Le coeur grenadine</td>\n",
       "      <td>Chanson</td>\n",
       "      <td>CA_KALX_2021_04_15_T01_34_13.mp3</td>\n",
       "      <td>2021</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>CA</td>\n",
       "      <td>KALX</td>\n",
       "      <td>Aviateur</td>\n",
       "      <td>VÃ©ronique Jannot</td>\n",
       "      <td>Aviateur</td>\n",
       "      <td>Synth-pop,Chanson,Italo-Disco</td>\n",
       "      <td>CA_KALX_2021_04_15_T01_38_12.mp3</td>\n",
       "      <td>2021</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>CA</td>\n",
       "      <td>KALX</td>\n",
       "      <td>Deaf</td>\n",
       "      <td>Just Mustard</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Shoegaze</td>\n",
       "      <td>CA_KALX_2021_04_15_T10_37_23.mp3</td>\n",
       "      <td>2021</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>37</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>CA</td>\n",
       "      <td>KALX</td>\n",
       "      <td>The Pull</td>\n",
       "      <td>Microphones</td>\n",
       "      <td>It Was Hot, We Stayed in the Water</td>\n",
       "      <td>Lo-Fi</td>\n",
       "      <td>CA_KALX_2021_04_15_T10_51_33.mp3</td>\n",
       "      <td>2021</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>51</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>CA</td>\n",
       "      <td>KALX</td>\n",
       "      <td>Here Comes The Sun</td>\n",
       "      <td>Richie Havens</td>\n",
       "      <td>Live At The Cellar Door and at the Santa Monic...</td>\n",
       "      <td>Folk Rock,Acoustic</td>\n",
       "      <td>CA_KALX_2021_04_15_T14_03_16.mp3</td>\n",
       "      <td>2021</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>CA</td>\n",
       "      <td>KALX</td>\n",
       "      <td>Lovin's for Fools</td>\n",
       "      <td>Front Country</td>\n",
       "      <td>Sake of the Sound</td>\n",
       "      <td>Bluegrass,Folk</td>\n",
       "      <td>CA_KALX_2021_04_15_T21_00_08.mp3</td>\n",
       "      <td>2021</td>\n",
       "      <td>15</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>CA</td>\n",
       "      <td>KALX</td>\n",
       "      <td>Single Saturday Night</td>\n",
       "      <td>Cole Swindell</td>\n",
       "      <td>Single Saturday Night</td>\n",
       "      <td>Country</td>\n",
       "      <td>CA_KALX_2021_04_16_T00_52_26.mp3</td>\n",
       "      <td>2021</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>CA</td>\n",
       "      <td>KALX</td>\n",
       "      <td>Bad Case</td>\n",
       "      <td>Lukas Nelson &amp; Promise of the Real</td>\n",
       "      <td>Turn Off The News (Build A Garden)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA_KALX_2021_04_29_T11_31_05.mp3</td>\n",
       "      <td>2021</td>\n",
       "      <td>29</td>\n",
       "      <td>11</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>CA</td>\n",
       "      <td>KALX</td>\n",
       "      <td>I Never Cared For You</td>\n",
       "      <td>Willie Nelson</td>\n",
       "      <td>A Horse Called Music</td>\n",
       "      <td>Country</td>\n",
       "      <td>CA_KALX_2021_04_29_T13_19_17.mp3</td>\n",
       "      <td>2021</td>\n",
       "      <td>29</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>CA</td>\n",
       "      <td>KALX</td>\n",
       "      <td>Freight Train Boogie</td>\n",
       "      <td>Doc &amp; Merle Watson</td>\n",
       "      <td>Elementary Doctor Watson</td>\n",
       "      <td>Country</td>\n",
       "      <td>CA_KALX_2021_05_06_T14_15_23.mp3</td>\n",
       "      <td>2021</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stateabrev radiocallsgn                 trackname  \\\n",
       "0          CA         KALX  Finally (12\" Choice Mix)   \n",
       "1          CA         KALX        Le coeur grenadine   \n",
       "2          CA         KALX                  Aviateur   \n",
       "3          CA         KALX                      Deaf   \n",
       "4          CA         KALX                  The Pull   \n",
       "5          CA         KALX        Here Comes The Sun   \n",
       "6          CA         KALX         Lovin's for Fools   \n",
       "7          CA         KALX     Single Saturday Night   \n",
       "8          CA         KALX                  Bad Case   \n",
       "9          CA         KALX     I Never Cared For You   \n",
       "10         CA         KALX      Freight Train Boogie   \n",
       "\n",
       "                           trackartist  \\\n",
       "0                        CeCe Peniston   \n",
       "1                       Laurent Voulzy   \n",
       "2                     VÃ©ronique Jannot   \n",
       "3                         Just Mustard   \n",
       "4                          Microphones   \n",
       "5                        Richie Havens   \n",
       "6                        Front Country   \n",
       "7                        Cole Swindell   \n",
       "8   Lukas Nelson & Promise of the Real   \n",
       "9                        Willie Nelson   \n",
       "10                  Doc & Merle Watson   \n",
       "\n",
       "                                           trackalbum  \\\n",
       "0                              Grand House Classics 1   \n",
       "1                                  Le coeur grenadine   \n",
       "2                                            Aviateur   \n",
       "3                                           Wednesday   \n",
       "4                  It Was Hot, We Stayed in the Water   \n",
       "5   Live At The Cellar Door and at the Santa Monic...   \n",
       "6                                   Sake of the Sound   \n",
       "7                               Single Saturday Night   \n",
       "8                  Turn Off The News (Build A Garden)   \n",
       "9                                A Horse Called Music   \n",
       "10                           Elementary Doctor Watson   \n",
       "\n",
       "                      trackstyles                  trackmp3filename  \\\n",
       "0   House,Deep House,Garage House  CA_KALX_2021_04_15_T00_17_08.mp3   \n",
       "1                         Chanson  CA_KALX_2021_04_15_T01_34_13.mp3   \n",
       "2   Synth-pop,Chanson,Italo-Disco  CA_KALX_2021_04_15_T01_38_12.mp3   \n",
       "3                        Shoegaze  CA_KALX_2021_04_15_T10_37_23.mp3   \n",
       "4                           Lo-Fi  CA_KALX_2021_04_15_T10_51_33.mp3   \n",
       "5              Folk Rock,Acoustic  CA_KALX_2021_04_15_T14_03_16.mp3   \n",
       "6                  Bluegrass,Folk  CA_KALX_2021_04_15_T21_00_08.mp3   \n",
       "7                         Country  CA_KALX_2021_04_16_T00_52_26.mp3   \n",
       "8                             NaN  CA_KALX_2021_04_29_T11_31_05.mp3   \n",
       "9                         Country  CA_KALX_2021_04_29_T13_19_17.mp3   \n",
       "10                        Country  CA_KALX_2021_05_06_T14_15_23.mp3   \n",
       "\n",
       "    captureyear  captureday  capturehour  captureminute  capturesecond  \n",
       "0          2021          15            0             17              8  \n",
       "1          2021          15            1             34             13  \n",
       "2          2021          15            1             38             12  \n",
       "3          2021          15           10             37             23  \n",
       "4          2021          15           10             51             33  \n",
       "5          2021          15           14              3             16  \n",
       "6          2021          15           21              0              8  \n",
       "7          2021          16            0             52             26  \n",
       "8          2021          29           11             31              5  \n",
       "9          2021          29           13             19             17  \n",
       "10         2021           6           14             15             23  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "may6_kalx_df = pd.read_csv(May6_KALX_log)\n",
    "may6_kalx_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
