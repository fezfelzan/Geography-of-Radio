{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import io\n",
    "from io import BytesIO\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "from csv import reader\n",
    "import requests\n",
    "import pycurl\n",
    "import certifi\n",
    "import time\n",
    "from datetime import datetime, date, timedelta\n",
    "from acrcloud.recognizer import ACRCloudRecognizer\n",
    "from acrcloud.recognizer import ACRCloudRecognizeType\n",
    "from bs4 import BeautifulSoup\n",
    "import shutil\n",
    "from shutil import copyfile\n",
    "import pydub\n",
    "from pydub.playback import play\n",
    "from pydub import AudioSegment\n",
    "import ffmpeg\n",
    "from functools import partial\n",
    "from itertools import repeat\n",
    "from itertools import product\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool, freeze_support\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "workindir = r'/Users/michaelfelzan/Desktop/GEO FM'\n",
    "\n",
    "\n",
    "acrcloud_accesskey = '4554490a1c83c19ea6745ed6bfbbea7d'\n",
    "acrcloud_secretkey = 'HcoVKztgUltoNAwlPxpWoIJzt86HoKk9KTiByPTl'\n",
    "\n",
    "acrcloud_config = {\n",
    "    'host':'identify-eu-west-1.acrcloud.com',\n",
    "    'access_key': acrcloud_accesskey,\n",
    "    'access_secret': acrcloud_secretkey,\n",
    "    'recognize_type': ACRCloudRecognizeType.ACR_OPT_REC_AUDIO, # could be 'humming audio' as well\n",
    "    'debug':False,\n",
    "    'timeout':5 # seconds\n",
    "}\n",
    "\n",
    "ACR_recognizer = ACRCloudRecognizer(acrcloud_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_key = 'gQylLmyvGPfyGEvmFyRx'\n",
    "client_secret = 'KJnItkPttweOtFSkqwAiTTCWJsOnIobH'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'/Users/michaelfelzan/Desktop/Geography-of-Radio/Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/michaelfelzan/Desktop/Geography-of-Radio/Data'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MASTER_CSV.csv',\n",
       " 'PLACES_DescendingCountriesCSV.csv',\n",
       " '.DS_Store',\n",
       " 'WashingtonStations_filled.csv',\n",
       " 'sample_mp3_1.mp3',\n",
       " 'sample_mp3_2.mp3',\n",
       " 'WashingtonStations_OnlyFM.csv',\n",
       " 'us_4.csv',\n",
       " 'WASH STATIONS',\n",
       " 'US_STATIONS_3.csv',\n",
       " 'fatal_error_wash.txt',\n",
       " 'US_STATIONS.csv',\n",
       " 'WashStationInfoTables']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>CityState</th>\n",
       "      <th>City</th>\n",
       "      <th>StateAbv</th>\n",
       "      <th>StationName</th>\n",
       "      <th>RG_ID</th>\n",
       "      <th>RG_LC</th>\n",
       "      <th>CS</th>\n",
       "      <th>RG_URL</th>\n",
       "      <th>URL</th>\n",
       "      <th>CityCords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>United States</td>\n",
       "      <td>Los Angeles CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101 Smooth Jazz</td>\n",
       "      <td>zFDSxGwY</td>\n",
       "      <td>/listen/-101-smooth-jazz/zFDSxGwY</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>https://radio.garden/api/ara/content/listen/zF...</td>\n",
       "      <td>https://streaming.live365.com/b22139_128mp3</td>\n",
       "      <td>[-118.24368, 34.052235]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>United States</td>\n",
       "      <td>Los Angeles CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113FM</td>\n",
       "      <td>4KJ_uzy0</td>\n",
       "      <td>/listen/radio-113fm/4KJ_uzy0</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>https://radio.garden/api/ara/content/listen/4K...</td>\n",
       "      <td>http://113fm-edge1.cdnstream.com/1730_128</td>\n",
       "      <td>[-118.24368, 34.052235]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>United States</td>\n",
       "      <td>Los Angeles CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.5 FM KCSN</td>\n",
       "      <td>SsUyqJaN</td>\n",
       "      <td>/listen/kcsn/SsUyqJaN</td>\n",
       "      <td>KCSN</td>\n",
       "      <td>https://radio.garden/api/ara/content/listen/Ss...</td>\n",
       "      <td>http://130.166.82.184:8000/;</td>\n",
       "      <td>[-118.24368, 34.052235]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>United States</td>\n",
       "      <td>Los Angeles CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9128.live</td>\n",
       "      <td>hacyg6SN</td>\n",
       "      <td>/listen/radio-9128-live/hacyg6SN</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>https://radio.garden/api/ara/content/listen/ha...</td>\n",
       "      <td>https://streams.radio.co/s0aa1e6f4a/listen</td>\n",
       "      <td>[-118.24368, 34.052235]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>United States</td>\n",
       "      <td>Los Angeles CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.5 Flex FM</td>\n",
       "      <td>t4dqOINA</td>\n",
       "      <td>/listen/radio-98-5-flex-fm/t4dqOINA</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>https://radio.garden/api/ara/content/listen/t4...</td>\n",
       "      <td>https://streaming.live365.com/a23768</td>\n",
       "      <td>[-118.24368, 34.052235]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Country       CityState  City  StateAbv      StationName     RG_ID  \\\n",
       "0  United States  Los Angeles CA   NaN       NaN  101 Smooth Jazz  zFDSxGwY   \n",
       "1  United States  Los Angeles CA   NaN       NaN            113FM  4KJ_uzy0   \n",
       "2  United States  Los Angeles CA   NaN       NaN     88.5 FM KCSN  SsUyqJaN   \n",
       "3  United States  Los Angeles CA   NaN       NaN        9128.live  hacyg6SN   \n",
       "4  United States  Los Angeles CA   NaN       NaN     98.5 Flex FM  t4dqOINA   \n",
       "\n",
       "                                 RG_LC    CS  \\\n",
       "0    /listen/-101-smooth-jazz/zFDSxGwY  xxxx   \n",
       "1         /listen/radio-113fm/4KJ_uzy0  xxxx   \n",
       "2                /listen/kcsn/SsUyqJaN  KCSN   \n",
       "3     /listen/radio-9128-live/hacyg6SN  xxxx   \n",
       "4  /listen/radio-98-5-flex-fm/t4dqOINA  xxxx   \n",
       "\n",
       "                                              RG_URL  \\\n",
       "0  https://radio.garden/api/ara/content/listen/zF...   \n",
       "1  https://radio.garden/api/ara/content/listen/4K...   \n",
       "2  https://radio.garden/api/ara/content/listen/Ss...   \n",
       "3  https://radio.garden/api/ara/content/listen/ha...   \n",
       "4  https://radio.garden/api/ara/content/listen/t4...   \n",
       "\n",
       "                                           URL                CityCords  \n",
       "0  https://streaming.live365.com/b22139_128mp3  [-118.24368, 34.052235]  \n",
       "1    http://113fm-edge1.cdnstream.com/1730_128  [-118.24368, 34.052235]  \n",
       "2                 http://130.166.82.184:8000/;  [-118.24368, 34.052235]  \n",
       "3   https://streams.radio.co/s0aa1e6f4a/listen  [-118.24368, 34.052235]  \n",
       "4         https://streaming.live365.com/a23768  [-118.24368, 34.052235]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us3_df = pd.read_csv('US_STATIONS_3.csv')\n",
    "us3_df.head()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEXT CELL IS A ONE-TIME RUN TO CREATE A CSV :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('us_4.csv','w',newline='') as csvfile:\n",
    "    fieldnames = ['Country',\n",
    "                  'CityState',\n",
    "                  'City',\n",
    "                  'StateAbv',\n",
    "                  'StationName',\n",
    "                  'RG_ID',\n",
    "                  'RG_LC',\n",
    "                  'CS',\n",
    "                  'RG_URL',\n",
    "                  'URL',\n",
    "                  'CityCords']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    \n",
    "    with open('US_STATIONS_3.csv', 'r') as read_obj:\n",
    "        csv_reader = reader(read_obj)\n",
    "        header = next(csv_reader)\n",
    "        if header != None:\n",
    "            for row in csv_reader:\n",
    "                iter_citystate = row[1]\n",
    "                iter_split = iter_citystate.split()\n",
    "                stateabv = iter_split[-1]\n",
    "                citywspace = iter_citystate.split(stateabv)[0]\n",
    "                isod_city = citywspace[:-1]\n",
    "                \n",
    "                writer.writerow({\n",
    "                    'Country' : row[0],\n",
    "                    'CityState' : row[1],\n",
    "                    'City' : isod_city,\n",
    "                    'StateAbv' : stateabv,\n",
    "                    'StationName' : row[4],\n",
    "                    'RG_ID' : row[5],\n",
    "                    'RG_LC' : row[6],\n",
    "                    'CS' : row[7],\n",
    "                    'RG_URL' : row[8],\n",
    "                    'URL' : row[9],\n",
    "                    'CityCords' : row[10]\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "WA_FM_CSV = r'/Users/michaelfelzan/Desktop/Geography-of-Radio/Data/WashingtonStations_OnlyFM.csv'\n",
    "\n",
    "source_CSV = WA_FM_CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_wash_infoget = r'/Users/michaelfelzan/Desktop/GEO FM/FailedWashStationsInfoGetter.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RadioTowerInfoGetter(callsign):\n",
    "    \"\"\"Function that requests the HTML of\n",
    "    the radio-locator.com webpage for whatever \n",
    "    radio station callsign is inputted into the function.\n",
    "    \n",
    "    The function parses the HTML to return a dictionary\n",
    "    containing the radio stations ERP, lat/long,\n",
    "    HAAT, HAGL, and HASL.\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    callsign : str\n",
    "        Name of station callsign (eg. KEXP)\n",
    "    \"\"\"\n",
    "    print(f\"Attempting to gather info from:  {callsign}...\")\n",
    "    \n",
    "    radiolocheaders = {\n",
    "        'sec-ch-ua' : '\"Google Chrome\";v=\"89\", \"Chromium\";v=\"89\", \";Not A Brand\";v=\"99\"',\n",
    "        'sec-ch-ua-mobile' : '?0',\n",
    "        'Upgrade-Insecure-Requests' : '1',\n",
    "        'User-Agent' : 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.114 Safari/537.36'\n",
    "    }\n",
    "    locatorURL_1 = f'https://radio-locator.com/cgi-bin/url?call={callsign}&service=FM'\n",
    "    locatorURL_2 = f'https://radio-locator.com/cgi-bin/finder?call={callsign}&x=0&y=0&sr=Y&s=C'\n",
    "    \n",
    "    radiolocreq = requests.get(locatorURL_1,\n",
    "                               headers=radiolocheaders)\n",
    "    stationHTML = radiolocreq.content.decode('utf-8')\n",
    "    stationsoup = BeautifulSoup(stationHTML)\n",
    "    techvalues = stationsoup.find_all(\"td\",\n",
    "                                      class_='tech_value')\n",
    "    \n",
    "    if techvalues == []:\n",
    "        print(f\"No radio tower info could be retrieved for station {callsign}\")       \n",
    "        print(\"Trying other request URL...waiting 20 seconds before retry...\")\n",
    "        time.sleep(20)\n",
    "        radiolocreq = requests.get(locatorURL_2,\n",
    "                                   headers=radiolocheaders)\n",
    "        stationHTML = radiolocreq.content.decode('utf-8')\n",
    "        stationsoup = BeautifulSoup(stationHTML)\n",
    "        techvalues = stationsoup.find_all(\"td\",\n",
    "                                          class_='tech_value')\n",
    "        if techvalues == []:\n",
    "            print(\"Second URL method failed. Stationed logged in 'fails' .txt\")\n",
    "            with open(failed_wash_infoget, \"a+\") as file_object:\n",
    "                file_object.seek(0)\n",
    "                data = file_object.read(100)\n",
    "                if len(data) > 0 :\n",
    "                    file_object.write(\"\\n\")\n",
    "                file_object.write(f\"{callsign}\")\n",
    "                \n",
    "            return False\n",
    "        \n",
    "        else:\n",
    "            ERP = []\n",
    "            coords = []\n",
    "            heights = []\n",
    "            # Parsing the HTML:\n",
    "            for item in techvalues:\n",
    "                for characters in item:\n",
    "                    for sub in characters:\n",
    "                        if '\" N' in sub:\n",
    "                            coords.append(sub)\n",
    "                if 'Watts' in characters:\n",
    "                    ERP.append(characters)\n",
    "                elif 'meters' in characters:\n",
    "                    heights.append(characters)\n",
    "                else:\n",
    "                    pass\n",
    "    \n",
    "            try:\n",
    "                itercoords = coords[0]\n",
    "            except:\n",
    "                print(\"This station didn't have coords data\")\n",
    "                itercoords = 'no_data'\n",
    "            try:\n",
    "                iterERP = ERP[0]\n",
    "            except:\n",
    "                print(\"This station didn't have ERP data\")\n",
    "                iterERP = 'no_data'\n",
    "            try:\n",
    "                iterHAAT = heights[0]\n",
    "            except:\n",
    "                print(\"This station didn't have HAAT data\")\n",
    "                iterHAAT = 'no_data'\n",
    "            try:\n",
    "                iterHAGL = heights[1]\n",
    "            except:\n",
    "                print(\"This station didn't have HAGL data\")\n",
    "                iterHAGL = 'no_data'\n",
    "            try:\n",
    "                iterHASL = heights[2]\n",
    "            except:\n",
    "                print(\"This station didn't have HASL data\")\n",
    "                iterHASL = 'no_data'\n",
    "    \n",
    "            towerinfo = {\n",
    "                'ERP' : iterERP,\n",
    "                'Coords' : itercoords,\n",
    "                'HAAT' : iterHAAT,\n",
    "                'Height Above Ground Level' : iterHAGL,\n",
    "                'Height Above Sea Level' : iterHASL\n",
    "            }\n",
    "    \n",
    "            return towerinfo\n",
    "    \n",
    "    else:\n",
    "        ERP = []\n",
    "        coords = []\n",
    "        heights = []\n",
    "        # Parsing the HTML:\n",
    "        for item in techvalues:\n",
    "            for characters in item:\n",
    "                for sub in characters:\n",
    "                    if '\" N' in sub:\n",
    "                        coords.append(sub)\n",
    "            if 'Watts' in characters:\n",
    "                ERP.append(characters)\n",
    "            elif 'meters' in characters:\n",
    "                heights.append(characters)\n",
    "            else:\n",
    "                pass\n",
    "    \n",
    "        try:\n",
    "            itercoords = coords[0]\n",
    "        except:\n",
    "            print(\"This station didn't have coords data\")\n",
    "            itercoords = 'no_data'\n",
    "        try:\n",
    "            iterERP = ERP[0]\n",
    "        except:\n",
    "            print(\"This station didn't have ERP data\")\n",
    "            iterERP = 'no_data'\n",
    "        try:\n",
    "            iterHAAT = heights[0]\n",
    "        except:\n",
    "            print(\"This station didn't have HAAT data\")\n",
    "            iterHAAT = 'no_data'\n",
    "        try:\n",
    "            iterHAGL = heights[1]\n",
    "        except:\n",
    "            print(\"This station didn't have HAGL data\")\n",
    "            iterHAGL = 'no_data'\n",
    "        try:\n",
    "            iterHASL = heights[2]\n",
    "        except:\n",
    "            print(\"This station didn't have HASL data\")\n",
    "            iterHASL = 'no_data'\n",
    "    \n",
    "        towerinfo = {\n",
    "            'ERP' : iterERP,\n",
    "            'Coords' : itercoords,\n",
    "            'HAAT' : iterHAAT,\n",
    "            'Height Above Ground Level' : iterHAGL,\n",
    "            'Height Above Sea Level' : iterHASL\n",
    "        }\n",
    "    \n",
    "        towerinfo = {\n",
    "            'ERP' : iterERP,\n",
    "            'Coords' : itercoords,\n",
    "            'HAAT' : iterHAAT,\n",
    "            'Height Above Ground Level' : iterHAGL,\n",
    "            'Height Above Sea Level' : iterHASL\n",
    "        }\n",
    "    \n",
    "        return towerinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StationInfoTxtWriter(stationfolderpath, call_sign):\n",
    "    \"\"\"Function that writes the dictionary return\n",
    "    from RadioTowerInfoGetter() for a station \n",
    "    to a .txt file in that station's corresponding\n",
    "    folder (only if the RadioTowerInfoGetter()\n",
    "    successfully returns tower info).\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    stationfoldername : str\n",
    "        Name of a radio stations folder (eg. CA_KALX)\n",
    "    \"\"\"\n",
    "    towerinfodict = RadioTowerInfoGetter(call_sign)\n",
    "    if towerinfodict == False:\n",
    "        #print(\"yes, it failed\")\n",
    "        pass\n",
    "    else:\n",
    "        infofilename = os.path.join(stationfolderpath,\n",
    "                                    f\"{call_sign}_towerinfo.txt\")\n",
    "        textyfile = open(infofilename,\n",
    "                    \"w+\")\n",
    "        textyfile.write(\"{\\n\")\n",
    "        for k in towerinfodict.keys():\n",
    "            textyfile.write(\"'{}':'{}'\\n\".format(k, towerinfodict[k]))\n",
    "        textyfile.write(\"}\")\n",
    "        textyfile.close()\n",
    "        print(f\"Sucessfully wrote {call_sign}_towerinfo.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dms_to_dd(d, m, s):\n",
    "    \"\"\"Function that converts degrees minutes seconds\n",
    "    into decimal degrees.\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    d : str (tho doesnt matter--converted to float in function)\n",
    "        degree\n",
    "    m : str (tho doesnt matter--converted to float in function)\n",
    "        minutes\n",
    "    s : str (tho doesnt matter--converted to float in function)\n",
    "        seconds\n",
    "    \"\"\"\n",
    "    dd = d + float(m)/60 + float(s)/3600\n",
    "    return round(dd, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DMS_Isolator(dms_string):\n",
    "    \"\"\"function that isolates the degree, minute, and second \n",
    "    components  of the DMS return from the StationInfoTxtWriter(),\n",
    "    so that they may be separately inputted into the\n",
    "    dms_to_dd() function parameters\n",
    "    \"\"\"\n",
    "    degree = dms_string.split(\"°\")[0]\n",
    "    minutefirstsplit = dms_string.split(\"'\")[0]\n",
    "    minute = minutefirstsplit.split(\"° \")[1]\n",
    "    secondfirstsplit = dms_string.split('\"')[0]\n",
    "    second = secondfirstsplit.split(\"' \")[1]\n",
    "    \n",
    "    return [degree,minute,second]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Station:\n",
    "    def __init__(self, sourceCSV, callsign):\n",
    "        self.sourceCSV = sourceCSV\n",
    "        self.callsign = callsign\n",
    "        \n",
    "        with open(sourceCSV, 'r') as read_obj:\n",
    "            csv_reader = reader(read_obj)\n",
    "            header = next(csv_reader)\n",
    "            if header != None:\n",
    "                for row in csv_reader:\n",
    "                    if row[7] == callsign:\n",
    "                        st_country = row[0]\n",
    "                        st_city = row[2]\n",
    "                        st_state = row[3]\n",
    "                        st_url = row[10]\n",
    "                        st_citycords = row[11]\n",
    "                        \n",
    "        self.country = st_country\n",
    "        self.city = st_city\n",
    "        self.state = st_state\n",
    "        self.url = st_url\n",
    "        self.citycords = st_citycords\n",
    "    \n",
    "    def Sampler(self, url, outpathname):\n",
    "        audio_input = ffmpeg.input(url)\n",
    "        audio_output = ffmpeg.output(audio_input,\n",
    "                                     outpathname,\n",
    "                                     **{'b:a': '128k'},\n",
    "                                     ss=35,\n",
    "                                     t=10)\n",
    "        #print(audio_output)\n",
    "        try:\n",
    "            audio_output.run()\n",
    "        except:\n",
    "            print(\"Error - Sampler could not work on URL stream. Skipping station.\")\n",
    "            return False\n",
    "    \n",
    "    def RouteToACRCloud(self, mp3):\n",
    "        \"\"\"Function that routes an mp3 file (path) to the\n",
    "        ACRCloud API, in order to return the song name info.\n",
    "        \n",
    "        Parameters\n",
    "        ------------\n",
    "        mp3 : str\n",
    "            Name of mp3 file (path)\n",
    "            \"\"\"\n",
    "        buf = open(mp3,'rb').read()\n",
    "        # start second will be 0; will record sampled mp3 for 10 seconds\n",
    "        songread_output = ACR_recognizer.recognize_by_filebuffer(buf, 0)\n",
    "        return songread_output\n",
    "    \n",
    "    \n",
    "    def RollRadio(self, url, callsign):\n",
    "        timerightnow = datetime.now()\n",
    "        formattedtime = timerightnow.strftime(\"%Y_%m_%d_T%H_%M_%S\")\n",
    "        \n",
    "        input_stream = url\n",
    "        input_mp3name = f'{callsign}'+f'{formattedtime}'+'.mp3'\n",
    "        itersongpath = os.path.join(r'/Users/michaelfelzan/Desktop/GEO FM',\n",
    "                                    input_mp3name)\n",
    "        \n",
    "        print(f'~~Now recording... {input_stream}')\n",
    "        samplerreturn = self.Sampler(url, itersongpath)\n",
    "        err = True\n",
    "        if samplerreturn == False:\n",
    "            pass\n",
    "        else:\n",
    "            acrcloud_output = self.RouteToACRCloud(itersongpath)\n",
    "            songread_dict = json.loads(acrcloud_output)\n",
    "    \n",
    "            if songread_dict['status']['msg'] == 'No result':\n",
    "                print(f'No ACR return from {input_mp3name}')\n",
    "                pass\n",
    "            elif songread_dict['status']['msg'] == 'May Be Mute':\n",
    "                print(f'No ACR return from {input_mp3name}')\n",
    "                pass\n",
    "            elif songread_dict['status']['msg'] == 'Decode Audio Error':\n",
    "                print(f'No ACR return from {input_mp3name}')\n",
    "                pass\n",
    "            elif songread_dict['status']['msg'] == 'requests limit exceeded, please upgrade your account':\n",
    "                print('ACRCLOUD REQUESTS LIMITS EXCEEDED, STOP PROGRAM')\n",
    "                pass\n",
    "            else:\n",
    "                try:\n",
    "                    songtitle = songread_dict['metadata']['music'][0]['title']\n",
    "                except:\n",
    "                    print(\"Error in 'Title' ACR return metadata...skipping station\")\n",
    "                    err = False\n",
    "                if err == False:\n",
    "                    pass\n",
    "                else:\n",
    "                    try:\n",
    "                        songartist = songread_dict['metadata']['music'][0]['artists'][0]['name']\n",
    "                    except:\n",
    "                        print(\"Error in 'Artist' ACR return metadata...skipping station\")\n",
    "                        err = False\n",
    "                    if err == False:\n",
    "                        pass\n",
    "                    else:\n",
    "                        try:\n",
    "                            songalbum = songread_dict['metadata']['music'][0]['album']['name']\n",
    "                        except:\n",
    "                            print(\"Error in 'Album' ACR return metadata...skipping station\")\n",
    "                            err = False\n",
    "                            pass\n",
    "                if err == False:\n",
    "                    pass\n",
    "                else:\n",
    "                    ACR_return = f'{input_mp3name} ~ song : {songtitle} by {songartist} from album {songalbum}'\n",
    "    \n",
    "                    percent20song = songtitle+'%20'+songartist+'%20'+songalbum\n",
    "                    discogs_input = percent20song.replace(\" \", \"%20\")\n",
    "                    discogs_req = ('https://api.discogs.com/database/search?q=' + \n",
    "                               discogs_input + \n",
    "                               '&key=' + \n",
    "                               client_key + \n",
    "                               '&secret=' +\n",
    "                               client_secret)\n",
    "                    discogs_req_obj = requests.get(discogs_req)\n",
    "                    discogs_songinfo_dict = json.loads(discogs_req_obj.content.decode('utf-8'))\n",
    "        \n",
    "                    if discogs_songinfo_dict['results'] == []:\n",
    "                        print(f'No Discogs return from {input_mp3name}')\n",
    "                        pass\n",
    "                    else:\n",
    "                        try:\n",
    "                            style_list = discogs_songinfo_dict['results'][0]['style']\n",
    "                        except:\n",
    "                            style_list = 'no_data'\n",
    "                        try:\n",
    "                            genre_list = discogs_songinfo_dict['results'][0]['genre']\n",
    "                        except:\n",
    "                            genre_list = 'no_data'\n",
    "                        \n",
    "                        if style_list == 'no_data':\n",
    "                            syleliststring = 'no_data'\n",
    "                        else:\n",
    "                            styleliststring = ','.join(style_list)\n",
    "                        if genre_list == 'no_data':\n",
    "                            genreliststring  = 'no_data'\n",
    "                        else:\n",
    "                            genreliststring = ','.join(genre_list)\n",
    "            \n",
    "                        Discogs_return = f'Discogs returned the genre(s): {styleliststring}'\n",
    "                \n",
    "                        parent_dir = r'/Users/michaelfelzan/Desktop/GEO FM/WASH STATIONS'\n",
    "                \n",
    "                        itertextpath = os.path.join(parent_dir,\n",
    "                                                    callsign,\n",
    "                                                    f'{callsign}.txt')\n",
    "            \n",
    "                        with open(itertextpath, \"a+\") as file_object:\n",
    "                            file_object.seek(0)\n",
    "                            data = file_object.read(100)\n",
    "                            if len(data) > 0 :\n",
    "                                file_object.write(\"\\n\")\n",
    "                            file_object.write((input_mp3name+\n",
    "                                               ','+\n",
    "                                               'song='+songtitle+','+\n",
    "                                               'artist='+songartist+','+\n",
    "                                               'album='+songalbum+','+\n",
    "                                               ####'genres='+genreliststring+','+\n",
    "                                               'styles='+styleliststring))\n",
    "                \n",
    "                        print(f\"Returned:{[ACR_return,Discogs_return]}\")\n",
    "                \n",
    "                os.remove(itersongpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kexptower = RadioTowerInfoGetter('KMRE')\n",
    "kexptower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kkxatower = RadioTowerInfoGetter('KKXA')\n",
    "kkxatower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fails_txt = r'/Users/michaelfelzan/Desktop/GEO FM/FailedWashStationsInfoGetter.txt'\n",
    "fails_list = []\n",
    "\n",
    "with open(fails_txt, \"r\") as a_file:\n",
    "    for line in a_file:\n",
    "        stripped_line = line.strip()\n",
    "        fails_list.append(stripped_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['KOWA', 'KORE', 'KVSH']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fails_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-time use code for deleting all text files !! :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parent_dir = r'/Users/michaelfelzan/Desktop/GEO FM/WASH STATIONS'\n",
    "\n",
    "#for washcallsign in list_of_wash_callsigns:\n",
    "    #iter_station = Station(WA_FM_CSV, washcallsign)\n",
    "    #itertextpath = os.path.join(parent_dir,\n",
    "                               #washcallsign,\n",
    "                               #f'{washcallsign}.txt')\n",
    "    #os.remove(itertextpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating 'list_of_wash_callsigns;' appending all names of Washington callsigns to list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_wash_callsigns = []\n",
    "\n",
    "with open(source_CSV, 'r') as read_obj:\n",
    "    csv_reader = reader(read_obj)\n",
    "    header = next(csv_reader)\n",
    "    if header != None:\n",
    "        for row in csv_reader:\n",
    "            iter_callsign = row[7]\n",
    "            list_of_wash_callsigns.append(iter_callsign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Making folder directories for all Washington callsigns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for washcallsign in list_of_wash_callsigns:\n",
    "    iter_station = Station(WA_FM_CSV, washcallsign)\n",
    "    # Directory \n",
    "    directory_name = iter_station.callsign\n",
    "    \n",
    "    # Parent Directory path\n",
    "    parent_dir = r'/Users/michaelfelzan/Desktop/GEO FM/WASH STATIONS'\n",
    "    \n",
    "    # Path \n",
    "    foldpath = os.path.join(parent_dir, directory_name)\n",
    "\n",
    "    # Create the directory \n",
    "    os.mkdir(foldpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating .txt files for all Washington callsigns in correct format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for washcallsign in list_of_wash_callsigns:\n",
    "    itertextpath = os.path.join(parent_dir,\n",
    "                               washcallsign,\n",
    "                               f'{washcallsign}.txt')\n",
    "    #print(itertextpath)\n",
    "    \n",
    "    with open(itertextpath, \"w\") as f:\n",
    "        f.write(f'{washcallsign}')\n",
    "    \n",
    "    \n",
    "for washcallsign in list_of_wash_callsigns:\n",
    "    iter_station = Station(WA_FM_CSV,\n",
    "                           washcallsign)\n",
    "    itertextpath = os.path.join(parent_dir,\n",
    "                               washcallsign,\n",
    "                               f'{washcallsign}.txt')\n",
    "    with open(itertextpath, \"a+\") as file_object:\n",
    "        file_object.seek(0)\n",
    "        # If file is not empty then append '\\n'\n",
    "        data = file_object.read(100)\n",
    "        if len(data) > 0 :\n",
    "            file_object.write(\"\\n\")\n",
    "        # Append text at the end of file\n",
    "        file_object.write(f\"stream={iter_station.url}\")\n",
    "        file_object.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_of_wash_callsigns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEGX = Station(WA_FM_CSV, 'KEGX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEGX.RollRadio(KEGX.url, KEGX.callsign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = r'/Users/michaelfelzan/Desktop/GEO FM/WASH STATIONS'\n",
    "\n",
    "for cs in fails_list:\n",
    "    \n",
    "    iterfoldpathy = os.path.join(parent_dir,\n",
    "                                cs)\n",
    "    # StationInfoTxtWriter(stationfolderpath, call_sign):\n",
    "    StationInfoTxtWriter(iterfoldpathy,\n",
    "                         cs)\n",
    "    time.sleep(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = r'/Users/michaelfelzan/Desktop/GEO FM/WASH STATIONS'\n",
    "os.chdir(parent_dir)\n",
    "wash_callsign_folds = []\n",
    "for thing in os.listdir():\n",
    "    if thing == '.DS_Store':\n",
    "        pass\n",
    "    else:\n",
    "        wash_callsign_folds.append(thing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['KPBX',\n",
       " 'KHUH',\n",
       " 'KACS',\n",
       " 'KYRS',\n",
       " 'KXDD',\n",
       " 'KZAX',\n",
       " 'KMRE',\n",
       " 'KFAE',\n",
       " 'KUKN',\n",
       " 'KOSW',\n",
       " 'KTQA',\n",
       " 'KBCS',\n",
       " 'KZTM',\n",
       " 'KEZE',\n",
       " 'KPLW',\n",
       " 'KROH',\n",
       " 'KGHI',\n",
       " 'KUPS',\n",
       " 'KIEV',\n",
       " 'KSQM',\n",
       " 'KAOS',\n",
       " 'KMIH',\n",
       " 'KPBZ',\n",
       " 'KTAH',\n",
       " 'KEFA',\n",
       " 'KSER',\n",
       " 'KNKX',\n",
       " 'KUOW',\n",
       " 'KIRO',\n",
       " 'KGRG',\n",
       " 'KEWU',\n",
       " 'KDDS',\n",
       " 'KWCW',\n",
       " 'KNHC',\n",
       " 'KEXP',\n",
       " 'KZZU',\n",
       " 'KZQM',\n",
       " 'KUGS',\n",
       " 'KPTZ',\n",
       " 'KBFG',\n",
       " 'KXLY',\n",
       " 'KODX',\n",
       " 'KGHP',\n",
       " 'KING',\n",
       " 'KYYO',\n",
       " 'KEGX',\n",
       " 'KCMS']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wash_callsign_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/michaelfelzan/Desktop/GEO FM'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(r'/Users/michaelfelzan/Desktop/GEO FM')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'37.699469101964276'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream = os.popen('node fezCC.js 4.7 211 \"250\" \"-\" 60 \"0\"')\n",
    "output = (stream.read()).split('\\n')[0]\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cs in wash_callsign_folds:\n",
    "    pathtostationfold = os.path.join(parent_dir,\n",
    "                                    cs)\n",
    "    #itercallsign = station.split(\"_\")[1]\n",
    "    #stateabv = station.split(\"_\")[0]\n",
    "    pathtotowertxt = os.path.join(pathtostationfold,\n",
    "                            f'{cs}_towerinfo.txt')\n",
    "    pathtotxt = os.path.join(pathtostationfold,\n",
    "                             f'{cs}.txt')\n",
    "    newinfocsv = os.path.join(pathtostationfold,\n",
    "                             f'{cs}_INFO.csv')\n",
    "    stationfolditems = os.listdir(pathtostationfold)\n",
    "    fullpathitems = []\n",
    "    for item in stationfolditems:\n",
    "        fullpathitems.append(os.path.join(pathtostationfold,\n",
    "                                         item))\n",
    "    if pathtotowertxt in fullpathitems:\n",
    "        with open(pathtotowertxt) as foo:\n",
    "            txtz = foo.readlines()\n",
    "            for item in txtz:\n",
    "                \n",
    "                if 'ERP' in item:\n",
    "                    wattsfirstsplit = item.split(\":'\")[1]\n",
    "                    watts = wattsfirstsplit.split(\" Watts\")[0]\n",
    "                    kilowatts = (float(watts.replace(',','')))/1000\n",
    "                    \n",
    "                elif 'Coords' in item:\n",
    "                    coordsfirstsplit = item.split(\":'\")[1]\n",
    "                    lat_dms = coordsfirstsplit.split(\",\")[0]\n",
    "                    long_dms = (coordsfirstsplit.split(\", \")[1])[:-2]\n",
    "                    \n",
    "                    lat_dms_list = DMS_Isolator(lat_dms)\n",
    "                    long_dms_list = DMS_Isolator(long_dms)\n",
    "                    \n",
    "                    lat_dd = dms_to_dd(float(lat_dms_list[0]),\n",
    "                                       float(lat_dms_list[1]),\n",
    "                                       float(lat_dms_list[2]))\n",
    "                    long_dd = dms_to_dd(float(long_dms_list[0]),\n",
    "                                        float(long_dms_list[1]),\n",
    "                                        float(long_dms_list[2]))\n",
    "                    negative_longdd = long_dd*-1\n",
    "                    \n",
    "                elif 'HAAT' in item:\n",
    "                    HAATfirstsplit = item.split(\":'\")[1]\n",
    "                    HAAT_clean = HAATfirstsplit.split(\" meters\")[0]\n",
    "                    HAAT_float = float(HAAT_clean)\n",
    "        \n",
    "                    stream_param = f'node fezCC.js {kilowatts} {HAAT_float} \"250\" \"-\" 60 \"0\"'\n",
    "                    stream = os.popen(stream_param)\n",
    "                    BUFF60DIST = (stream.read()).split('\\n')[0]\n",
    "                \n",
    "        with open(newinfocsv,'w',newline='') as csvfile:\n",
    "            fieldnames = ['CALLSIGN',\n",
    "                          'LAT',\n",
    "                          'LONG',\n",
    "                          'ERP',\n",
    "                          'HAAT',\n",
    "                          '60dBu_DIST']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            writer.writerow({\n",
    "                'CALLSIGN': cs,\n",
    "                'LAT' : lat_dd,\n",
    "                'LONG' : negative_longdd,\n",
    "                'ERP' : kilowatts,\n",
    "                'HAAT' : HAAT_clean,\n",
    "                '60dBu_DIST' : BUFF60DIST\n",
    "            })\n",
    "                \n",
    "    else:\n",
    "        print(f'tower info .txt does not exist for {cs}')\n",
    "        pass\n",
    "\n",
    "print(\"\\n     *~*~~~~~**~~~~~~~~~~~~~~**~*~*\\n\"+\n",
    "      \"Successfully wrote all other station tower info CSVs.\"+\n",
    "      \"\\nCSVs outputted to respective station folders.\"\n",
    "      \"\\n   *~*~~~~~**~~~~~~~~~~~~~~**~*~*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationinfopath = os.path.join(r'/Users/michaelfelzan/Desktop/GEO FM',\n",
    "                               \"WashStationInfoTables\")\n",
    "os.mkdir(stationinfopath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COPYING FILES TO StationInfoTables FOLDER\n",
    "\n",
    "for cs in wash_callsign_folds:\n",
    "    pathtostationfold = os.path.join(parent_dir,\n",
    "                                    cs,)\n",
    "    newinfocsv = os.path.join(pathtostationfold,\n",
    "                             f'{cs}_INFO.csv')\n",
    "    stationfolditems = os.listdir(pathtostationfold)\n",
    "    fullpathitems = []\n",
    "    for item in stationfolditems:\n",
    "        fullpathitems.append(os.path.join(pathtostationfold,\n",
    "                                         item))\n",
    "    if newinfocsv in fullpathitems:\n",
    "        copyfile(newinfocsv,\n",
    "                 os.path.join(r'/Users/michaelfelzan/Desktop/GEO FM',\n",
    "                              \"WashStationInfoTables\",\n",
    "                              f'{cs}_INFO.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathtofold = r'/Users/michaelfelzan/Desktop/GEO FM/WashStationInfoTables'\n",
    "INFOconcatCSV = os.path.join(pathtofold,\n",
    "                             \"WASHSTATIONINFOconcat.csv\") \n",
    "allFiles = glob.glob(pathtofold + \"/*.csv\")\n",
    "allFiles.sort()\n",
    "with open(INFOconcatCSV, 'wb') as outfile:\n",
    "        for i, fname in enumerate(allFiles):\n",
    "            with open(fname, 'rb') as infile:\n",
    "                if i != 0:\n",
    "                    infile.readline()  # Throw away header on all but first file\n",
    "            # Block copy rest of file from input to output without parsing\n",
    "                shutil.copyfileobj(infile, outfile)\n",
    "\n",
    "print(\"     *~*~~~~~**~~~~~~~~~~~~~~**~*~*\\n\"\n",
    "      \"All station tower info CSVs (that exist) have\"+\n",
    "      \"\\n      been successfully merged together\"\n",
    "      \"\\n  *~*~~~~~**~~~~~~~~~~~~~~**~*~*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CALLSIGN</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LONG</th>\n",
       "      <th>ERP</th>\n",
       "      <th>HAAT</th>\n",
       "      <th>60dBu_DIST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>KACS</td>\n",
       "      <td>46.730556</td>\n",
       "      <td>-123.025833</td>\n",
       "      <td>6.000</td>\n",
       "      <td>57.00</td>\n",
       "      <td>21.947963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>KAOS</td>\n",
       "      <td>47.015833</td>\n",
       "      <td>-122.917222</td>\n",
       "      <td>1.250</td>\n",
       "      <td>74.00</td>\n",
       "      <td>16.686530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>KBCS</td>\n",
       "      <td>47.543889</td>\n",
       "      <td>-122.109167</td>\n",
       "      <td>1.800</td>\n",
       "      <td>389.00</td>\n",
       "      <td>40.247137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>KBFG</td>\n",
       "      <td>47.667500</td>\n",
       "      <td>-122.355000</td>\n",
       "      <td>0.009</td>\n",
       "      <td>95.94</td>\n",
       "      <td>5.546802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>KCMS</td>\n",
       "      <td>47.544167</td>\n",
       "      <td>-122.108333</td>\n",
       "      <td>54.000</td>\n",
       "      <td>385.00</td>\n",
       "      <td>72.279685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>KDDS</td>\n",
       "      <td>47.312500</td>\n",
       "      <td>-123.372222</td>\n",
       "      <td>64.000</td>\n",
       "      <td>742.00</td>\n",
       "      <td>92.461470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>KEFA</td>\n",
       "      <td>47.382778</td>\n",
       "      <td>-120.293333</td>\n",
       "      <td>0.100</td>\n",
       "      <td>-71.00</td>\n",
       "      <td>5.636485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>KEGX</td>\n",
       "      <td>46.099167</td>\n",
       "      <td>-119.128889</td>\n",
       "      <td>100.000</td>\n",
       "      <td>424.40</td>\n",
       "      <td>81.532897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>KEWU</td>\n",
       "      <td>47.578611</td>\n",
       "      <td>-117.298333</td>\n",
       "      <td>10.000</td>\n",
       "      <td>429.00</td>\n",
       "      <td>57.879066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>KEXP</td>\n",
       "      <td>47.615833</td>\n",
       "      <td>-122.308889</td>\n",
       "      <td>4.700</td>\n",
       "      <td>211.00</td>\n",
       "      <td>37.699469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>KEZE</td>\n",
       "      <td>47.725833</td>\n",
       "      <td>-117.169444</td>\n",
       "      <td>8.200</td>\n",
       "      <td>365.00</td>\n",
       "      <td>52.411102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>KFAE</td>\n",
       "      <td>46.095000</td>\n",
       "      <td>-119.195833</td>\n",
       "      <td>100.000</td>\n",
       "      <td>350.00</td>\n",
       "      <td>76.082001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>KGHI</td>\n",
       "      <td>46.919444</td>\n",
       "      <td>-123.955278</td>\n",
       "      <td>1.900</td>\n",
       "      <td>18.00</td>\n",
       "      <td>11.860072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>KGHP</td>\n",
       "      <td>47.240556</td>\n",
       "      <td>-122.772222</td>\n",
       "      <td>1.350</td>\n",
       "      <td>61.00</td>\n",
       "      <td>15.402396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>KGRG</td>\n",
       "      <td>47.256111</td>\n",
       "      <td>-122.219722</td>\n",
       "      <td>0.230</td>\n",
       "      <td>116.00</td>\n",
       "      <td>13.549143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>KHUH</td>\n",
       "      <td>47.613056</td>\n",
       "      <td>-122.305000</td>\n",
       "      <td>0.015</td>\n",
       "      <td>78.00</td>\n",
       "      <td>5.677022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>KIEV</td>\n",
       "      <td>45.656111</td>\n",
       "      <td>-122.385556</td>\n",
       "      <td>0.100</td>\n",
       "      <td>30.00</td>\n",
       "      <td>5.636485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>KING</td>\n",
       "      <td>47.503611</td>\n",
       "      <td>-121.975833</td>\n",
       "      <td>66.000</td>\n",
       "      <td>707.00</td>\n",
       "      <td>91.525059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>KIRO</td>\n",
       "      <td>47.503611</td>\n",
       "      <td>-121.975833</td>\n",
       "      <td>52.000</td>\n",
       "      <td>729.00</td>\n",
       "      <td>89.847959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>KMIH</td>\n",
       "      <td>47.572222</td>\n",
       "      <td>-122.219167</td>\n",
       "      <td>0.030</td>\n",
       "      <td>69.00</td>\n",
       "      <td>6.308638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>KMRE</td>\n",
       "      <td>48.747500</td>\n",
       "      <td>-122.479167</td>\n",
       "      <td>0.100</td>\n",
       "      <td>-13.49</td>\n",
       "      <td>5.636485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>KNHC</td>\n",
       "      <td>47.542778</td>\n",
       "      <td>-122.108056</td>\n",
       "      <td>8.500</td>\n",
       "      <td>372.00</td>\n",
       "      <td>53.157927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>KNKX</td>\n",
       "      <td>47.503611</td>\n",
       "      <td>-121.975833</td>\n",
       "      <td>64.000</td>\n",
       "      <td>707.00</td>\n",
       "      <td>91.207351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>KODX</td>\n",
       "      <td>47.659167</td>\n",
       "      <td>-122.312222</td>\n",
       "      <td>0.038</td>\n",
       "      <td>48.50</td>\n",
       "      <td>5.608430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>KOSW</td>\n",
       "      <td>46.984167</td>\n",
       "      <td>-124.153889</td>\n",
       "      <td>0.076</td>\n",
       "      <td>35.23</td>\n",
       "      <td>5.651727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>KPBX</td>\n",
       "      <td>47.570278</td>\n",
       "      <td>-117.084444</td>\n",
       "      <td>56.000</td>\n",
       "      <td>725.00</td>\n",
       "      <td>90.470883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>KPBZ</td>\n",
       "      <td>47.813333</td>\n",
       "      <td>-117.507500</td>\n",
       "      <td>0.550</td>\n",
       "      <td>329.70</td>\n",
       "      <td>28.409386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>KPLW</td>\n",
       "      <td>47.323333</td>\n",
       "      <td>-120.234444</td>\n",
       "      <td>7.000</td>\n",
       "      <td>424.00</td>\n",
       "      <td>54.193125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>KPTZ</td>\n",
       "      <td>48.128056</td>\n",
       "      <td>-122.828889</td>\n",
       "      <td>2.200</td>\n",
       "      <td>102.00</td>\n",
       "      <td>22.779632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>KROH</td>\n",
       "      <td>48.015833</td>\n",
       "      <td>-122.926111</td>\n",
       "      <td>1.150</td>\n",
       "      <td>456.00</td>\n",
       "      <td>39.510279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>KSER</td>\n",
       "      <td>48.024167</td>\n",
       "      <td>-122.112500</td>\n",
       "      <td>5.800</td>\n",
       "      <td>92.00</td>\n",
       "      <td>26.994633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>KSQM</td>\n",
       "      <td>48.083333</td>\n",
       "      <td>-123.267222</td>\n",
       "      <td>2.050</td>\n",
       "      <td>-62.00</td>\n",
       "      <td>12.075181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>KTAH</td>\n",
       "      <td>47.221389</td>\n",
       "      <td>-122.469722</td>\n",
       "      <td>0.016</td>\n",
       "      <td>69.11</td>\n",
       "      <td>5.429665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>KTQA</td>\n",
       "      <td>47.239167</td>\n",
       "      <td>-122.446111</td>\n",
       "      <td>0.019</td>\n",
       "      <td>69.00</td>\n",
       "      <td>5.659309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>KUGS</td>\n",
       "      <td>48.735556</td>\n",
       "      <td>-122.482778</td>\n",
       "      <td>0.810</td>\n",
       "      <td>137.00</td>\n",
       "      <td>20.608062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>KUKN</td>\n",
       "      <td>46.162778</td>\n",
       "      <td>-122.854722</td>\n",
       "      <td>0.700</td>\n",
       "      <td>256.00</td>\n",
       "      <td>26.620990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>KUOW</td>\n",
       "      <td>47.615833</td>\n",
       "      <td>-122.308889</td>\n",
       "      <td>100.000</td>\n",
       "      <td>224.00</td>\n",
       "      <td>66.029465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>KUPS</td>\n",
       "      <td>47.263056</td>\n",
       "      <td>-122.478056</td>\n",
       "      <td>0.100</td>\n",
       "      <td>70.00</td>\n",
       "      <td>8.638738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>KWCW</td>\n",
       "      <td>46.069444</td>\n",
       "      <td>-118.331944</td>\n",
       "      <td>0.160</td>\n",
       "      <td>-16.00</td>\n",
       "      <td>6.340287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>KXDD</td>\n",
       "      <td>46.513056</td>\n",
       "      <td>-120.402500</td>\n",
       "      <td>100.000</td>\n",
       "      <td>245.00</td>\n",
       "      <td>67.828095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>KXLY</td>\n",
       "      <td>47.921667</td>\n",
       "      <td>-117.114444</td>\n",
       "      <td>37.000</td>\n",
       "      <td>914.00</td>\n",
       "      <td>91.897985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>KYRS</td>\n",
       "      <td>48.180556</td>\n",
       "      <td>-117.987500</td>\n",
       "      <td>6.800</td>\n",
       "      <td>876.00</td>\n",
       "      <td>72.624184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>KYYO</td>\n",
       "      <td>47.085556</td>\n",
       "      <td>-123.189444</td>\n",
       "      <td>11.000</td>\n",
       "      <td>321.00</td>\n",
       "      <td>52.353900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>KZAX</td>\n",
       "      <td>48.747500</td>\n",
       "      <td>-122.479167</td>\n",
       "      <td>0.100</td>\n",
       "      <td>-17.49</td>\n",
       "      <td>5.636485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>KZQM</td>\n",
       "      <td>48.125833</td>\n",
       "      <td>-123.117222</td>\n",
       "      <td>6.000</td>\n",
       "      <td>22.00</td>\n",
       "      <td>15.752658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>KZTM</td>\n",
       "      <td>46.975000</td>\n",
       "      <td>-123.140556</td>\n",
       "      <td>70.000</td>\n",
       "      <td>668.00</td>\n",
       "      <td>90.709301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>KZZU</td>\n",
       "      <td>47.595000</td>\n",
       "      <td>-117.299167</td>\n",
       "      <td>81.000</td>\n",
       "      <td>634.00</td>\n",
       "      <td>90.941259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CALLSIGN        LAT        LONG      ERP    HAAT  60dBu_DIST\n",
       "0      KACS  46.730556 -123.025833    6.000   57.00   21.947963\n",
       "1      KAOS  47.015833 -122.917222    1.250   74.00   16.686530\n",
       "2      KBCS  47.543889 -122.109167    1.800  389.00   40.247137\n",
       "3      KBFG  47.667500 -122.355000    0.009   95.94    5.546802\n",
       "4      KCMS  47.544167 -122.108333   54.000  385.00   72.279685\n",
       "5      KDDS  47.312500 -123.372222   64.000  742.00   92.461470\n",
       "6      KEFA  47.382778 -120.293333    0.100  -71.00    5.636485\n",
       "7      KEGX  46.099167 -119.128889  100.000  424.40   81.532897\n",
       "8      KEWU  47.578611 -117.298333   10.000  429.00   57.879066\n",
       "9      KEXP  47.615833 -122.308889    4.700  211.00   37.699469\n",
       "10     KEZE  47.725833 -117.169444    8.200  365.00   52.411102\n",
       "11     KFAE  46.095000 -119.195833  100.000  350.00   76.082001\n",
       "12     KGHI  46.919444 -123.955278    1.900   18.00   11.860072\n",
       "13     KGHP  47.240556 -122.772222    1.350   61.00   15.402396\n",
       "14     KGRG  47.256111 -122.219722    0.230  116.00   13.549143\n",
       "15     KHUH  47.613056 -122.305000    0.015   78.00    5.677022\n",
       "16     KIEV  45.656111 -122.385556    0.100   30.00    5.636485\n",
       "17     KING  47.503611 -121.975833   66.000  707.00   91.525059\n",
       "18     KIRO  47.503611 -121.975833   52.000  729.00   89.847959\n",
       "19     KMIH  47.572222 -122.219167    0.030   69.00    6.308638\n",
       "20     KMRE  48.747500 -122.479167    0.100  -13.49    5.636485\n",
       "21     KNHC  47.542778 -122.108056    8.500  372.00   53.157927\n",
       "22     KNKX  47.503611 -121.975833   64.000  707.00   91.207351\n",
       "23     KODX  47.659167 -122.312222    0.038   48.50    5.608430\n",
       "24     KOSW  46.984167 -124.153889    0.076   35.23    5.651727\n",
       "25     KPBX  47.570278 -117.084444   56.000  725.00   90.470883\n",
       "26     KPBZ  47.813333 -117.507500    0.550  329.70   28.409386\n",
       "27     KPLW  47.323333 -120.234444    7.000  424.00   54.193125\n",
       "28     KPTZ  48.128056 -122.828889    2.200  102.00   22.779632\n",
       "29     KROH  48.015833 -122.926111    1.150  456.00   39.510279\n",
       "30     KSER  48.024167 -122.112500    5.800   92.00   26.994633\n",
       "31     KSQM  48.083333 -123.267222    2.050  -62.00   12.075181\n",
       "32     KTAH  47.221389 -122.469722    0.016   69.11    5.429665\n",
       "33     KTQA  47.239167 -122.446111    0.019   69.00    5.659309\n",
       "34     KUGS  48.735556 -122.482778    0.810  137.00   20.608062\n",
       "35     KUKN  46.162778 -122.854722    0.700  256.00   26.620990\n",
       "36     KUOW  47.615833 -122.308889  100.000  224.00   66.029465\n",
       "37     KUPS  47.263056 -122.478056    0.100   70.00    8.638738\n",
       "38     KWCW  46.069444 -118.331944    0.160  -16.00    6.340287\n",
       "39     KXDD  46.513056 -120.402500  100.000  245.00   67.828095\n",
       "40     KXLY  47.921667 -117.114444   37.000  914.00   91.897985\n",
       "41     KYRS  48.180556 -117.987500    6.800  876.00   72.624184\n",
       "42     KYYO  47.085556 -123.189444   11.000  321.00   52.353900\n",
       "43     KZAX  48.747500 -122.479167    0.100  -17.49    5.636485\n",
       "44     KZQM  48.125833 -123.117222    6.000   22.00   15.752658\n",
       "45     KZTM  46.975000 -123.140556   70.000  668.00   90.709301\n",
       "46     KZZU  47.595000 -117.299167   81.000  634.00   90.941259"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wash_stn_info_concat = os.path.join(r'/Users/michaelfelzan/Desktop/GEO FM',\n",
    "                                    \"WashStationInfoTables\",\n",
    "                                    \"WASHSTATIONINFOconcat.csv\")\n",
    "\n",
    "wash_stn_info_df = pd.read_csv(wash_stn_info_concat)\n",
    "wash_stn_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#while True:\n",
    "    #for cs in wash_callsign_folds:\n",
    "        #iter_satysh = Station(WA_FM_CSV, cs)\n",
    "        #iter_satysh.RollRadio(iter_satysh.url,\n",
    "                             # iter_satysh.callsign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "KACS = Station(WA_FM_CSV, 'KACS')\n",
    "KZZU = Station(WA_FM_CSV, 'KZZU')\n",
    "KEXP = Station(WA_FM_CSV, 'KEXP')\n",
    "KYRS = Station(WA_FM_CSV, 'KYRS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~Now recording... https://kexp-mp3-128.streamguys1.com/kexp128.mp3\n",
      "~~Now recording... https://15373.live.streamtheworld.com/KZZUFMAAC_SC\n",
      "~~Now recording... https://www.ophanim.net:8444/s/7170\n",
      "Error - Sampler could not work on URL stream. Skipping station.\n",
      "~~Now recording... https://ic2.sslstream.com/kacs-fm\n",
      "No ACR return from KACS2021_10_27_T12_38_10.mp3\n",
      "Returned:[\"KEXP2021_10_27_T12_38_08.mp3 ~ song : Less Yes's, More No's by Busdriver from album RoadKill Overcoat\", 'Discogs returned the genre(s): Abstract']\n",
      "No ACR return from KZZU2021_10_27_T12_38_08.mp3\n"
     ]
    }
   ],
   "source": [
    "def multi_run_wrapper(args):\n",
    "    return RadioRoller(*args)\n",
    "def RadioRoller(url, callsign):\n",
    "    return (globals()[f'{callsign}']).RollRadio(globals()[f'{callsign}'].url,\n",
    "                                               globals()[f'{callsign}'].callsign)\n",
    "if __name__ == \"__main__\":\n",
    "    pool = Pool(3)\n",
    "    startcycletime = datetime.time(datetime.now())\n",
    "    timecounter = 0\n",
    "    while timecounter < 899:\n",
    "        pool.map(multi_run_wrapper,[(KEXP.url,KEXP.callsign),\n",
    "                                    (KZZU.url,KZZU.callsign),\n",
    "                                    (KYRS.url,KYRS.callsign),\n",
    "                                    (KACS.url,KACS.callsign)])\n",
    "        endcycletime = datetime.time(datetime.now())\n",
    "        runduration = datetime.combine(date.today(), endcycletime) - datetime.combine(date.today(), startcycletime)\n",
    "        rundur_sec = runduration.seconds\n",
    "        if rundur_sec < 300:\n",
    "            time.sleep(300 - rundur_sec)\n",
    "            timecounter += 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
